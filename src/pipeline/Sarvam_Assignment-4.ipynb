{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Overall Semantic Chunking Logic: A top -> down approach"
      ],
      "metadata": {
        "id": "rcO2PaNrjEwY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Why a Top -> Down Chunking Strategy Is Preferable for Semantic Segmentation"
      ],
      "metadata": {
        "id": "hh1PNqo7jQu7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "During the course of this assignment, multiple approaches to semantic chunking were explored. An initially appealing strategy was a bottom -> up approach, in which small units (words or short segments) are progressively merged to form larger chunks. However, deeper analysis revealed that a top -> down approach, which begins with the entire audio and recursively partitions it into smaller chunks until all of them are <15 seconds in length, might be more suitable for preserving semantic context and producing coherent segments."
      ],
      "metadata": {
        "id": "otWPVZejk3Gx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Context as a First-Class Signal"
      ],
      "metadata": {
        "id": "kFppdUp2k58-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Semantic chunking is not merely about dividing audio into manageable lengths; it is about identifying meaningful conceptual boundaries. Such boundaries are inherently contextual: whether a transition is semantic depends not only on local text, but also on its relationship to surrounding content.\n",
        "A top -> down approach naturally treats context as a global signal. At each split, both sides of a candidate cut are evaluated in the presence of their broader temporal neighborhood. This enables semantic decisions to be informed by:\n",
        "what preceded the cut,\n",
        "what follows it,\n",
        "and how each side relates to its respective context.\n",
        "In contrast, a bottom -> up approach constructs chunks incrementally from local units. Once early merges are made, the algorithm loses access to the original global structure. Context is implicitly baked into earlier decisions and cannot be revisited or corrected later."
      ],
      "metadata": {
        "id": "dLsJDwIqlFX5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Moving-Window Context in Top -> Down Splitting"
      ],
      "metadata": {
        "id": "0MNlC3VFlNpp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A major advantage of top -> down chunking is the ability to use a moving context window when evaluating candidate splits.\n",
        "At any stage, a large chunk can be split,\n",
        "embedding the left and right sub-chunks, and more importantly:\n",
        "\n",
        "We can use the extra embeddings from the **extended left and right neighbours** and scoring the split based on semantic contrast and internal coherence.\n",
        "Because the parent chunk still exists as a coherent whole, these embeddings are computed against meaningful, contiguous context. The algorithm can ask questions such as:\n",
        "\n",
        "\n",
        "“Is this split a real conceptual transition, or just a change in phrasing inside the same idea?”\n",
        "\n",
        "\n",
        "This form of contextual reasoning is difficult to replicate in bottom -> up systems, where context must be approximated from previously merged fragments that may not align with true semantic units."
      ],
      "metadata": {
        "id": "JUDYq2dGlYBu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installing Dependencies"
      ],
      "metadata": {
        "id": "N5TsUYE-NH7C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. First, install the core foundations with strict version caps\n",
        "!pip install -q \\\n",
        "    \"numpy<2.1.0\" \\\n",
        "    \"pandas==2.2.2\" \\\n",
        "    \"protobuf<5.0.0\" \\\n",
        "    \"huggingface-hub<1.0\" \\\n",
        "    \"pillow<12.0\" \\\n",
        "    \"fsspec<=2025.3.0\"\n",
        "\n",
        "# 2. Then install your tools (PyTorch and Pyannote)\n",
        "!pip install -q \\\n",
        "    \"torch==2.5.1\" \\\n",
        "    \"torchvision==0.20.1\" \\\n",
        "    \"torchaudio==2.5.1\" \\\n",
        "    pyannote.audio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "p13EuIRYwutj",
        "outputId": "9f8035af-85e0-4803-e2ee-f862b2d10d19"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/294.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "opentelemetry-proto 1.37.0 requires protobuf<7.0,>=5.0, but you have protobuf 4.25.8 which is incompatible.\n",
            "ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.9/44.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.4/906.4 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m136.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m98.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m116.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m118.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.6/209.6 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.8/897.8 kB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m846.0/846.0 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.5/58.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.4/51.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.8/127.8 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m864.1/864.1 kB\u001b[0m \u001b[31m57.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m65.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.7/404.7 kB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.5/849.5 kB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m788.2/788.2 kB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for julius (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pyannote.audio\n",
        "print(f\"NumPy version: {np.__version__}\")\n",
        "print(\"Pyannote imported successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "O7PA8_5JyjQB",
        "outputId": "f3a21e7a-c8d2-4de4-8ad6-3d1c22140317"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NumPy version: 2.0.2\n",
            "Pyannote imported successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6y4Q97EzQcWX",
        "outputId": "f42a65de-a3a0-4851-acde-0d98e1cbe1e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  gyp javascript-common libc-ares2 libjs-events libjs-highlight.js\n",
            "  libjs-inherits libjs-is-typedarray libjs-psl libjs-source-map\n",
            "  libjs-sprintf-js libjs-typedarray-to-buffer libnode-dev libnode72\n",
            "  libnotify-bin libnotify4 libuv1-dev node-abab node-abbrev node-agent-base\n",
            "  node-ansi-regex node-ansi-styles node-ansistyles node-aproba node-archy\n",
            "  node-are-we-there-yet node-argparse node-arrify node-asap node-asynckit\n",
            "  node-balanced-match node-brace-expansion node-builtins node-cacache\n",
            "  node-chalk node-chownr node-clean-yaml-object node-cli-table node-clone\n",
            "  node-color-convert node-color-name node-colors node-columnify\n",
            "  node-combined-stream node-commander node-console-control-strings\n",
            "  node-copy-concurrently node-core-util-is node-coveralls node-cssom\n",
            "  node-cssstyle node-debug node-decompress-response node-defaults\n",
            "  node-delayed-stream node-delegates node-depd node-diff node-encoding\n",
            "  node-end-of-stream node-err-code node-escape-string-regexp node-esprima\n",
            "  node-events node-fancy-log node-fetch node-foreground-child node-form-data\n",
            "  node-fs-write-stream-atomic node-fs.realpath node-function-bind node-gauge\n",
            "  node-get-stream node-glob node-got node-graceful-fs node-growl node-gyp\n",
            "  node-has-flag node-has-unicode node-hosted-git-info node-https-proxy-agent\n",
            "  node-iconv-lite node-iferr node-imurmurhash node-indent-string node-inflight\n",
            "  node-inherits node-ini node-ip node-ip-regex node-is-buffer\n",
            "  node-is-plain-obj node-is-typedarray node-isarray node-isexe node-js-yaml\n",
            "  node-jsdom node-json-buffer node-json-parse-better-errors node-jsonparse\n",
            "  node-kind-of node-lcov-parse node-lodash-packages node-log-driver\n",
            "  node-lowercase-keys node-lru-cache node-mime node-mime-types\n",
            "  node-mimic-response node-minimatch node-minimist node-minipass node-mkdirp\n",
            "  node-move-concurrently node-ms node-mute-stream node-negotiator node-nopt\n",
            "  node-normalize-package-data node-npm-bundled node-npm-package-arg\n",
            "  node-npmlog node-object-assign node-once node-opener node-osenv\n",
            "  node-p-cancelable node-p-map node-path-is-absolute node-process-nextick-args\n",
            "  node-promise-inflight node-promise-retry node-promzard node-psl node-pump\n",
            "  node-punycode node-quick-lru node-read node-read-package-json\n",
            "  node-readable-stream node-resolve node-retry node-rimraf node-run-queue\n",
            "  node-safe-buffer node-semver node-set-blocking node-signal-exit node-slash\n",
            "  node-slice-ansi node-source-map node-source-map-support node-spdx-correct\n",
            "  node-spdx-exceptions node-spdx-expression-parse node-spdx-license-ids\n",
            "  node-sprintf-js node-ssri node-stack-utils node-stealthy-require\n",
            "  node-string-decoder node-string-width node-strip-ansi node-supports-color\n",
            "  node-tap node-tap-mocha-reporter node-tap-parser node-tar node-text-table\n",
            "  node-time-stamp node-tmatch node-tough-cookie node-typedarray-to-buffer\n",
            "  node-unique-filename node-universalify node-util-deprecate\n",
            "  node-validate-npm-package-license node-validate-npm-package-name\n",
            "  node-wcwidth.js node-webidl-conversions node-whatwg-fetch node-which\n",
            "  node-wide-align node-wrappy node-write-file-atomic node-ws node-yallist\n",
            "  nodejs-doc\n",
            "Suggested packages:\n",
            "  apache2 | lighttpd | httpd libjs-angularjs gnome-shell | notification-daemon\n",
            "  node-nyc\n",
            "The following NEW packages will be installed:\n",
            "  gyp javascript-common libc-ares2 libjs-events libjs-highlight.js\n",
            "  libjs-inherits libjs-is-typedarray libjs-psl libjs-source-map\n",
            "  libjs-sprintf-js libjs-typedarray-to-buffer libnode-dev libnode72\n",
            "  libnotify-bin libnotify4 libuv1-dev node-abab node-abbrev node-agent-base\n",
            "  node-ansi-regex node-ansi-styles node-ansistyles node-aproba node-archy\n",
            "  node-are-we-there-yet node-argparse node-arrify node-asap node-asynckit\n",
            "  node-balanced-match node-brace-expansion node-builtins node-cacache\n",
            "  node-chalk node-chownr node-clean-yaml-object node-cli-table node-clone\n",
            "  node-color-convert node-color-name node-colors node-columnify\n",
            "  node-combined-stream node-commander node-console-control-strings\n",
            "  node-copy-concurrently node-core-util-is node-coveralls node-cssom\n",
            "  node-cssstyle node-debug node-decompress-response node-defaults\n",
            "  node-delayed-stream node-delegates node-depd node-diff node-encoding\n",
            "  node-end-of-stream node-err-code node-escape-string-regexp node-esprima\n",
            "  node-events node-fancy-log node-fetch node-foreground-child node-form-data\n",
            "  node-fs-write-stream-atomic node-fs.realpath node-function-bind node-gauge\n",
            "  node-get-stream node-glob node-got node-graceful-fs node-growl node-gyp\n",
            "  node-has-flag node-has-unicode node-hosted-git-info node-https-proxy-agent\n",
            "  node-iconv-lite node-iferr node-imurmurhash node-indent-string node-inflight\n",
            "  node-inherits node-ini node-ip node-ip-regex node-is-buffer\n",
            "  node-is-plain-obj node-is-typedarray node-isarray node-isexe node-js-yaml\n",
            "  node-jsdom node-json-buffer node-json-parse-better-errors node-jsonparse\n",
            "  node-kind-of node-lcov-parse node-lodash-packages node-log-driver\n",
            "  node-lowercase-keys node-lru-cache node-mime node-mime-types\n",
            "  node-mimic-response node-minimatch node-minimist node-minipass node-mkdirp\n",
            "  node-move-concurrently node-ms node-mute-stream node-negotiator node-nopt\n",
            "  node-normalize-package-data node-npm-bundled node-npm-package-arg\n",
            "  node-npmlog node-object-assign node-once node-opener node-osenv\n",
            "  node-p-cancelable node-p-map node-path-is-absolute node-process-nextick-args\n",
            "  node-promise-inflight node-promise-retry node-promzard node-psl node-pump\n",
            "  node-punycode node-quick-lru node-read node-read-package-json\n",
            "  node-readable-stream node-resolve node-retry node-rimraf node-run-queue\n",
            "  node-safe-buffer node-semver node-set-blocking node-signal-exit node-slash\n",
            "  node-slice-ansi node-source-map node-source-map-support node-spdx-correct\n",
            "  node-spdx-exceptions node-spdx-expression-parse node-spdx-license-ids\n",
            "  node-sprintf-js node-ssri node-stack-utils node-stealthy-require\n",
            "  node-string-decoder node-string-width node-strip-ansi node-supports-color\n",
            "  node-tap node-tap-mocha-reporter node-tap-parser node-tar node-text-table\n",
            "  node-time-stamp node-tmatch node-tough-cookie node-typedarray-to-buffer\n",
            "  node-unique-filename node-universalify node-util-deprecate\n",
            "  node-validate-npm-package-license node-validate-npm-package-name\n",
            "  node-wcwidth.js node-webidl-conversions node-whatwg-fetch node-which\n",
            "  node-wide-align node-wrappy node-write-file-atomic node-ws node-yallist\n",
            "  nodejs nodejs-doc npm\n",
            "0 upgraded, 190 newly installed, 0 to remove and 41 not upgraded.\n",
            "Need to get 18.8 MB of archives.\n",
            "After this operation, 90.4 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 gyp all 0.1+20210831gitd6c5dd5-5 [238 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 javascript-common all 11+nmu1 [5,936 B]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libjs-events all 3.3.0+~3.0.0-2 [9,734 B]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libjs-highlight.js all 9.18.5+dfsg1-1 [367 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libjs-is-typedarray all 1.0.0-4 [3,804 B]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libjs-psl all 1.8.0+ds-6 [76.3 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libjs-sprintf-js all 1.1.2+ds1+~1.1.2-1 [12.8 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libjs-typedarray-to-buffer all 4.0.0-2 [4,658 B]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libuv1-dev amd64 1.43.0-1ubuntu0.1 [130 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libc-ares2 amd64 1.18.1-1ubuntu0.22.04.3 [45.1 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libnode72 amd64 12.22.9~dfsg-1ubuntu3.6 [10.8 MB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libnode-dev amd64 12.22.9~dfsg-1ubuntu3.6 [609 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libnotify4 amd64 0.7.9-3ubuntu5.22.04.1 [20.3 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libnotify-bin amd64 0.7.9-3ubuntu5.22.04.1 [7,560 B]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 nodejs amd64 12.22.9~dfsg-1ubuntu3.6 [122 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-abab all 2.0.5-2 [6,578 B]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-ms all 2.1.3+~cs0.7.31-2 [5,782 B]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-debug all 4.3.2+~cs4.1.7-1 [17.6 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-yallist all 4.0.0+~4.0.1-1 [8,322 B]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-lru-cache all 6.0.0+~5.1.1-1 [11.3 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-semver all 7.3.5+~7.3.8-1 [41.5 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-agent-base all 6.0.2+~cs5.4.2-1 [17.9 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-ansi-regex all 5.0.1-1 [4,984 B]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-ansistyles all 0.1.3-5 [4,546 B]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-aproba all 2.0.0-2 [5,620 B]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-delegates all 1.0.0-3 [4,280 B]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libjs-inherits all 2.0.4-4 [3,468 B]\n",
            "Get:28 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-inherits all 2.0.4-4 [3,010 B]\n",
            "Get:29 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-core-util-is all 1.0.3-1 [4,066 B]\n",
            "Get:30 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-safe-buffer all 5.2.1+~cs2.1.2-2 [15.7 kB]\n",
            "Get:31 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-string-decoder all 1.3.0-5 [7,046 B]\n",
            "Get:32 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-process-nextick-args all 2.0.1-2 [3,730 B]\n",
            "Get:33 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-util-deprecate all 1.0.2-3 [4,202 B]\n",
            "Get:34 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-isarray all 2.0.5-3 [3,934 B]\n",
            "Get:35 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-readable-stream all 3.6.0+~cs3.0.0-1 [32.6 kB]\n",
            "Get:36 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-are-we-there-yet all 3.0.0+~1.1.0-1 [8,920 B]\n",
            "Get:37 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-arrify all 2.0.1-2 [3,610 B]\n",
            "Get:38 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-asap all 2.0.6+~2.0.0-1 [14.4 kB]\n",
            "Get:39 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-asynckit all 0.4.0-4 [10.6 kB]\n",
            "Get:40 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-builtins all 4.0.0-1 [3,860 B]\n",
            "Get:41 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-chownr all 2.0.0-1 [4,404 B]\n",
            "Get:42 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-fs.realpath all 1.0.0-2 [6,106 B]\n",
            "Get:43 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-wrappy all 1.0.2-2 [3,658 B]\n",
            "Get:44 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-once all 1.4.0-4 [4,708 B]\n",
            "Get:45 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-inflight all 1.0.6-2 [3,940 B]\n",
            "Get:46 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-balanced-match all 2.0.0-1 [4,910 B]\n",
            "Get:47 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-brace-expansion all 2.0.1-1 [7,458 B]\n",
            "Get:48 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-minimatch all 3.1.1+~3.0.5-1 [16.9 kB]\n",
            "Get:49 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-path-is-absolute all 2.0.0-2 [4,062 B]\n",
            "Get:50 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-glob all 7.2.1+~cs7.6.15-1 [131 kB]\n",
            "Get:51 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-graceful-fs all 4.2.4+repack-1 [12.5 kB]\n",
            "Get:52 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-mkdirp all 1.0.4+~1.0.2-1 [11.4 kB]\n",
            "Get:53 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-iferr all 1.0.2+~1.0.2-1 [4,610 B]\n",
            "Get:54 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-imurmurhash all 0.1.4+dfsg+~0.1.1-1 [8,510 B]\n",
            "Get:55 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-fs-write-stream-atomic all 1.0.10-5 [5,256 B]\n",
            "Get:56 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-rimraf all 3.0.2-1 [10.1 kB]\n",
            "Get:57 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-run-queue all 2.0.0-2 [5,092 B]\n",
            "Get:58 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-copy-concurrently all 1.0.5-8 [7,118 B]\n",
            "Get:59 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-move-concurrently all 1.0.1-4 [5,120 B]\n",
            "Get:60 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-escape-string-regexp all 4.0.0-2 [4,328 B]\n",
            "Get:61 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-indent-string all 4.0.0-2 [4,122 B]\n",
            "Get:62 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-p-map all 4.0.0+~3.1.0+~3.0.1-1 [8,058 B]\n",
            "Get:63 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-promise-inflight all 1.0.1+~1.0.0-1 [4,896 B]\n",
            "Get:64 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-ssri all 8.0.1-2 [19.6 kB]\n",
            "Get:65 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-unique-filename all 1.1.1+ds-1 [3,832 B]\n",
            "Get:66 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-cacache all 15.0.5+~cs13.9.21-3 [34.9 kB]\n",
            "Get:67 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-clean-yaml-object all 0.1.0-5 [4,718 B]\n",
            "Get:68 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-clone all 2.1.2-3 [8,344 B]\n",
            "Get:69 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-color-name all 1.1.4+~1.1.1-2 [6,076 B]\n",
            "Get:70 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-color-convert all 2.0.1-1 [10.2 kB]\n",
            "Get:71 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-colors all 1.4.0-3 [12.3 kB]\n",
            "Get:72 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-strip-ansi all 6.0.1-1 [4,184 B]\n",
            "Get:73 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-defaults all 1.0.3+~1.0.3-1 [4,288 B]\n",
            "Get:74 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-wcwidth.js all 1.0.2-1 [7,278 B]\n",
            "Get:75 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-columnify all 1.5.4+~1.5.1-1 [12.6 kB]\n",
            "Get:76 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-console-control-strings all 1.1.0-2 [5,428 B]\n",
            "Get:77 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-growl all 1.10.5-4 [7,064 B]\n",
            "Get:78 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-sprintf-js all 1.1.2+ds1+~1.1.2-1 [3,916 B]\n",
            "Get:79 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-argparse all 2.0.1-2 [33.2 kB]\n",
            "Get:80 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-esprima all 4.0.1+ds+~4.0.3-2 [69.3 kB]\n",
            "Get:81 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-js-yaml all 4.1.0+dfsg+~4.0.5-6 [62.7 kB]\n",
            "Get:82 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-lcov-parse all 1.0.0+20170612git80d039574ed9-5 [5,084 B]\n",
            "Get:83 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-log-driver all 1.2.7+git+20180219+bba1761737-7 [5,436 B]\n",
            "Get:84 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-is-plain-obj all 3.0.0-2 [3,994 B]\n",
            "Get:85 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-is-buffer all 2.0.5-2 [4,128 B]\n",
            "Get:86 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-kind-of all 6.0.3+dfsg-2 [8,628 B]\n",
            "Get:87 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-minimist all 1.2.5+~cs5.3.2-1 [9,434 B]\n",
            "Get:88 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-cssom all 0.4.4-3 [14.1 kB]\n",
            "Get:89 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-cssstyle all 2.3.0-2 [30.3 kB]\n",
            "Get:90 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-delayed-stream all 1.0.0-5 [5,464 B]\n",
            "Get:91 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-combined-stream all 1.0.8+~1.0.3-1 [7,432 B]\n",
            "Get:92 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-mime all 3.0.0+dfsg+~cs3.96.1-1 [38.1 kB]\n",
            "Get:93 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-mime-types all 2.1.33-1 [6,944 B]\n",
            "Get:94 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-form-data all 3.0.1-1 [13.4 kB]\n",
            "Get:95 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-events all 3.3.0+~3.0.0-2 [3,090 B]\n",
            "Get:96 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-https-proxy-agent all 5.0.0+~cs8.0.0-3 [16.4 kB]\n",
            "Get:97 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-iconv-lite all 0.6.3-2 [167 kB]\n",
            "Get:98 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-lodash-packages all 4.17.21+dfsg+~cs8.31.198.20210220-5 [166 kB]\n",
            "Get:99 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-stealthy-require all 1.1.1-5 [7,176 B]\n",
            "Get:100 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-punycode all 2.1.1-5 [9,902 B]\n",
            "Get:101 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-psl all 1.8.0+ds-6 [39.6 kB]\n",
            "Get:102 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-universalify all 2.0.0-3 [4,266 B]\n",
            "Get:103 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-tough-cookie all 4.0.0-2 [31.7 kB]\n",
            "Get:104 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-webidl-conversions all 7.0.0~1.1.0+~cs15.1.20180823-2 [27.5 kB]\n",
            "Get:105 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-commander all 9.0.0-2 [48.0 kB]\n",
            "Get:106 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-mute-stream all 0.0.8+~0.0.1-1 [6,448 B]\n",
            "Get:107 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-read all 1.0.7-3 [5,478 B]\n",
            "Get:108 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-ws all 8.5.0+~cs13.3.3-2 [49.5 kB]\n",
            "Get:109 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-jsdom all 19.0.0+~cs90.11.27-1 [446 kB]\n",
            "Get:110 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-fetch all 2.6.7+~2.5.12-1 [27.1 kB]\n",
            "Get:111 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-coveralls all 3.1.1-1 [14.2 kB]\n",
            "Get:112 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-mimic-response all 3.1.0-7 [5,430 B]\n",
            "Get:113 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-decompress-response all 6.0.0-2 [4,656 B]\n",
            "Get:114 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-diff all 5.0.0~dfsg+~5.0.1-3 [77.4 kB]\n",
            "Get:115 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-err-code all 2.0.3+dfsg-3 [4,918 B]\n",
            "Get:116 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-time-stamp all 2.2.0-1 [5,984 B]\n",
            "Get:117 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-fancy-log all 1.3.3+~cs1.3.1-2 [8,102 B]\n",
            "Get:118 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-signal-exit all 3.0.6+~3.0.1-1 [7,000 B]\n",
            "Get:119 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-foreground-child all 2.0.0-3 [5,542 B]\n",
            "Get:120 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-function-bind all 1.1.1+repacked+~1.0.3-1 [5,244 B]\n",
            "Get:121 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-has-unicode all 2.0.1-4 [3,948 B]\n",
            "Get:122 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-ansi-styles all 4.3.0+~4.2.0-1 [8,968 B]\n",
            "Get:123 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-slice-ansi all 5.0.0+~cs9.0.0-4 [8,044 B]\n",
            "Get:124 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-string-width all 4.2.3+~cs13.2.3-1 [11.4 kB]\n",
            "Get:125 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-wide-align all 1.1.3-4 [4,228 B]\n",
            "Get:126 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-gauge all 4.0.2-1 [16.3 kB]\n",
            "Get:127 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-end-of-stream all 1.4.4+~1.4.1-1 [5,340 B]\n",
            "Get:128 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-pump all 3.0.0-5 [5,160 B]\n",
            "Get:129 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-get-stream all 6.0.1-1 [7,324 B]\n",
            "Get:130 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-lowercase-keys all 2.0.0-2 [3,754 B]\n",
            "Get:131 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-json-buffer all 3.0.1-1 [3,812 B]\n",
            "Get:132 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-p-cancelable all 2.1.1-1 [7,358 B]\n",
            "Get:133 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-quick-lru all 5.1.1-1 [5,532 B]\n",
            "Get:134 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-got all 11.8.3+~cs58.7.37-1 [122 kB]\n",
            "Get:135 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-has-flag all 4.0.0-2 [4,228 B]\n",
            "Get:136 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-hosted-git-info all 4.0.2-1 [9,006 B]\n",
            "Get:137 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-ip all 1.1.5+~1.1.0-1 [8,140 B]\n",
            "Get:138 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-ip-regex all 4.3.0+~4.1.1-1 [5,254 B]\n",
            "Get:139 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-is-typedarray all 1.0.0-4 [2,072 B]\n",
            "Get:140 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-isexe all 2.0.0+~2.0.1-4 [6,102 B]\n",
            "Get:141 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-json-parse-better-errors all 1.0.2+~cs3.3.1-1 [7,328 B]\n",
            "Get:142 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-encoding all 0.1.13-2 [4,366 B]\n",
            "Get:143 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-jsonparse all 1.3.1-10 [8,060 B]\n",
            "Get:144 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-minipass all 3.1.6+~cs8.7.18-1 [32.9 kB]\n",
            "Get:145 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-npm-bundled all 1.1.2-1 [6,228 B]\n",
            "Get:146 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-osenv all 0.1.5+~0.1.0-1 [5,896 B]\n",
            "Get:147 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-validate-npm-package-name all 3.0.0-4 [5,058 B]\n",
            "Get:148 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-npm-package-arg all 8.1.5-1 [8,132 B]\n",
            "Get:149 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-object-assign all 4.1.1-6 [4,754 B]\n",
            "Get:150 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-opener all 1.5.2+~1.4.0-1 [6,000 B]\n",
            "Get:151 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-retry all 0.13.1+~0.12.1-1 [11.5 kB]\n",
            "Get:152 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-promise-retry all 2.0.1-2 [5,010 B]\n",
            "Get:153 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-promzard all 0.3.0-2 [6,888 B]\n",
            "Get:154 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-set-blocking all 2.0.0-2 [3,766 B]\n",
            "Get:155 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-slash all 3.0.0-2 [3,922 B]\n",
            "Get:156 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libjs-source-map all 0.7.0++dfsg2+really.0.6.1-9 [93.9 kB]\n",
            "Get:157 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-source-map all 0.7.0++dfsg2+really.0.6.1-9 [33.6 kB]\n",
            "Get:158 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-source-map-support all 0.5.21+ds+~0.5.4-1 [14.2 kB]\n",
            "Get:159 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-spdx-license-ids all 3.0.11-1 [7,306 B]\n",
            "Get:160 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-spdx-exceptions all 2.3.0-2 [3,978 B]\n",
            "Get:161 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-spdx-expression-parse all 3.0.1+~3.0.1-1 [7,658 B]\n",
            "Get:162 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-spdx-correct all 3.1.1-2 [5,476 B]\n",
            "Get:163 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-stack-utils all 2.0.5+~2.0.1-1 [9,368 B]\n",
            "Get:164 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-supports-color all 8.1.1+~8.1.1-1 [7,048 B]\n",
            "Get:165 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-tap-parser all 7.0.0+ds1-6 [19.4 kB]\n",
            "Get:166 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-tap-mocha-reporter all 3.0.7+ds-2 [39.2 kB]\n",
            "Get:167 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-text-table all 0.2.0-4 [4,762 B]\n",
            "Get:168 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-tmatch all 5.0.0-4 [6,002 B]\n",
            "Get:169 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-typedarray-to-buffer all 4.0.0-2 [2,242 B]\n",
            "Get:170 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-validate-npm-package-license all 3.0.4-2 [4,252 B]\n",
            "Get:171 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-whatwg-fetch all 3.6.2-5 [15.0 kB]\n",
            "Get:172 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-write-file-atomic all 3.0.3+~3.0.2-1 [7,690 B]\n",
            "Get:173 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 nodejs-doc all 12.22.9~dfsg-1ubuntu3.6 [2,411 kB]\n",
            "Get:174 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-abbrev all 1.1.1+~1.1.2-1 [5,784 B]\n",
            "Get:175 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-archy all 1.0.0-4 [4,728 B]\n",
            "Get:176 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-chalk all 4.1.2-1 [15.9 kB]\n",
            "Get:177 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-cli-table all 0.3.11+~cs0.13.3-1 [23.2 kB]\n",
            "Get:178 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-depd all 2.0.0-2 [10.5 kB]\n",
            "Get:179 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-nopt all 5.0.0-2 [11.3 kB]\n",
            "Get:180 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-npmlog all 6.0.1+~4.1.4-1 [9,968 B]\n",
            "Get:181 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-tar all 6.1.11+ds1+~cs6.0.6-1 [38.8 kB]\n",
            "Get:182 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-which all 2.0.2+~cs1.3.2-2 [7,374 B]\n",
            "Get:183 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-gyp all 8.4.1-1 [34.7 kB]\n",
            "Get:184 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-ini all 2.0.1-1 [6,528 B]\n",
            "Get:185 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-negotiator all 0.6.2+~0.6.1-1 [10.3 kB]\n",
            "Get:186 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-resolve all 1.20.0+~cs5.27.9-1 [20.7 kB]\n",
            "Get:187 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-normalize-package-data all 3.0.3+~2.4.1-1 [12.8 kB]\n",
            "Get:188 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-read-package-json all 4.1.1-1 [10.4 kB]\n",
            "Get:189 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-tap all 12.0.1+ds-4 [43.6 kB]\n",
            "Get:190 http://archive.ubuntu.com/ubuntu jammy/universe amd64 npm all 8.5.1~ds-1 [894 kB]\n",
            "Fetched 18.8 MB in 10s (1,917 kB/s)\n",
            "Extracting templates from packages: 100%\n",
            "Selecting previously unselected package gyp.\n",
            "(Reading database ... 121689 files and directories currently installed.)\n",
            "Preparing to unpack .../000-gyp_0.1+20210831gitd6c5dd5-5_all.deb ...\n",
            "Unpacking gyp (0.1+20210831gitd6c5dd5-5) ...\n",
            "Selecting previously unselected package javascript-common.\n",
            "Preparing to unpack .../001-javascript-common_11+nmu1_all.deb ...\n",
            "Unpacking javascript-common (11+nmu1) ...\n",
            "Selecting previously unselected package libjs-events.\n",
            "Preparing to unpack .../002-libjs-events_3.3.0+~3.0.0-2_all.deb ...\n",
            "Unpacking libjs-events (3.3.0+~3.0.0-2) ...\n",
            "Selecting previously unselected package libjs-highlight.js.\n",
            "Preparing to unpack .../003-libjs-highlight.js_9.18.5+dfsg1-1_all.deb ...\n",
            "Unpacking libjs-highlight.js (9.18.5+dfsg1-1) ...\n",
            "Selecting previously unselected package libjs-is-typedarray.\n",
            "Preparing to unpack .../004-libjs-is-typedarray_1.0.0-4_all.deb ...\n",
            "Unpacking libjs-is-typedarray (1.0.0-4) ...\n",
            "Selecting previously unselected package libjs-psl.\n",
            "Preparing to unpack .../005-libjs-psl_1.8.0+ds-6_all.deb ...\n",
            "Unpacking libjs-psl (1.8.0+ds-6) ...\n",
            "Selecting previously unselected package libjs-sprintf-js.\n",
            "Preparing to unpack .../006-libjs-sprintf-js_1.1.2+ds1+~1.1.2-1_all.deb ...\n",
            "Unpacking libjs-sprintf-js (1.1.2+ds1+~1.1.2-1) ...\n",
            "Selecting previously unselected package libjs-typedarray-to-buffer.\n",
            "Preparing to unpack .../007-libjs-typedarray-to-buffer_4.0.0-2_all.deb ...\n",
            "Unpacking libjs-typedarray-to-buffer (4.0.0-2) ...\n",
            "Selecting previously unselected package libuv1-dev:amd64.\n",
            "Preparing to unpack .../008-libuv1-dev_1.43.0-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking libuv1-dev:amd64 (1.43.0-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libc-ares2:amd64.\n",
            "Preparing to unpack .../009-libc-ares2_1.18.1-1ubuntu0.22.04.3_amd64.deb ...\n",
            "Unpacking libc-ares2:amd64 (1.18.1-1ubuntu0.22.04.3) ...\n",
            "Selecting previously unselected package libnode72:amd64.\n",
            "Preparing to unpack .../010-libnode72_12.22.9~dfsg-1ubuntu3.6_amd64.deb ...\n",
            "Unpacking libnode72:amd64 (12.22.9~dfsg-1ubuntu3.6) ...\n",
            "Selecting previously unselected package libnode-dev.\n",
            "Preparing to unpack .../011-libnode-dev_12.22.9~dfsg-1ubuntu3.6_amd64.deb ...\n",
            "Unpacking libnode-dev (12.22.9~dfsg-1ubuntu3.6) ...\n",
            "Selecting previously unselected package libnotify4:amd64.\n",
            "Preparing to unpack .../012-libnotify4_0.7.9-3ubuntu5.22.04.1_amd64.deb ...\n",
            "Unpacking libnotify4:amd64 (0.7.9-3ubuntu5.22.04.1) ...\n",
            "Selecting previously unselected package libnotify-bin.\n",
            "Preparing to unpack .../013-libnotify-bin_0.7.9-3ubuntu5.22.04.1_amd64.deb ...\n",
            "Unpacking libnotify-bin (0.7.9-3ubuntu5.22.04.1) ...\n",
            "Selecting previously unselected package nodejs.\n",
            "Preparing to unpack .../014-nodejs_12.22.9~dfsg-1ubuntu3.6_amd64.deb ...\n",
            "Unpacking nodejs (12.22.9~dfsg-1ubuntu3.6) ...\n",
            "Selecting previously unselected package node-abab.\n",
            "Preparing to unpack .../015-node-abab_2.0.5-2_all.deb ...\n",
            "Unpacking node-abab (2.0.5-2) ...\n",
            "Selecting previously unselected package node-ms.\n",
            "Preparing to unpack .../016-node-ms_2.1.3+~cs0.7.31-2_all.deb ...\n",
            "Unpacking node-ms (2.1.3+~cs0.7.31-2) ...\n",
            "Selecting previously unselected package node-debug.\n",
            "Preparing to unpack .../017-node-debug_4.3.2+~cs4.1.7-1_all.deb ...\n",
            "Unpacking node-debug (4.3.2+~cs4.1.7-1) ...\n",
            "Selecting previously unselected package node-yallist.\n",
            "Preparing to unpack .../018-node-yallist_4.0.0+~4.0.1-1_all.deb ...\n",
            "Unpacking node-yallist (4.0.0+~4.0.1-1) ...\n",
            "Selecting previously unselected package node-lru-cache.\n",
            "Preparing to unpack .../019-node-lru-cache_6.0.0+~5.1.1-1_all.deb ...\n",
            "Unpacking node-lru-cache (6.0.0+~5.1.1-1) ...\n",
            "Selecting previously unselected package node-semver.\n",
            "Preparing to unpack .../020-node-semver_7.3.5+~7.3.8-1_all.deb ...\n",
            "Unpacking node-semver (7.3.5+~7.3.8-1) ...\n",
            "Selecting previously unselected package node-agent-base.\n",
            "Preparing to unpack .../021-node-agent-base_6.0.2+~cs5.4.2-1_all.deb ...\n",
            "Unpacking node-agent-base (6.0.2+~cs5.4.2-1) ...\n",
            "Selecting previously unselected package node-ansi-regex.\n",
            "Preparing to unpack .../022-node-ansi-regex_5.0.1-1_all.deb ...\n",
            "Unpacking node-ansi-regex (5.0.1-1) ...\n",
            "Selecting previously unselected package node-ansistyles.\n",
            "Preparing to unpack .../023-node-ansistyles_0.1.3-5_all.deb ...\n",
            "Unpacking node-ansistyles (0.1.3-5) ...\n",
            "Selecting previously unselected package node-aproba.\n",
            "Preparing to unpack .../024-node-aproba_2.0.0-2_all.deb ...\n",
            "Unpacking node-aproba (2.0.0-2) ...\n",
            "Selecting previously unselected package node-delegates.\n",
            "Preparing to unpack .../025-node-delegates_1.0.0-3_all.deb ...\n",
            "Unpacking node-delegates (1.0.0-3) ...\n",
            "Selecting previously unselected package libjs-inherits.\n",
            "Preparing to unpack .../026-libjs-inherits_2.0.4-4_all.deb ...\n",
            "Unpacking libjs-inherits (2.0.4-4) ...\n",
            "Selecting previously unselected package node-inherits.\n",
            "Preparing to unpack .../027-node-inherits_2.0.4-4_all.deb ...\n",
            "Unpacking node-inherits (2.0.4-4) ...\n",
            "Selecting previously unselected package node-core-util-is.\n",
            "Preparing to unpack .../028-node-core-util-is_1.0.3-1_all.deb ...\n",
            "Unpacking node-core-util-is (1.0.3-1) ...\n",
            "Selecting previously unselected package node-safe-buffer.\n",
            "Preparing to unpack .../029-node-safe-buffer_5.2.1+~cs2.1.2-2_all.deb ...\n",
            "Unpacking node-safe-buffer (5.2.1+~cs2.1.2-2) ...\n",
            "Selecting previously unselected package node-string-decoder.\n",
            "Preparing to unpack .../030-node-string-decoder_1.3.0-5_all.deb ...\n",
            "Unpacking node-string-decoder (1.3.0-5) ...\n",
            "Selecting previously unselected package node-process-nextick-args.\n",
            "Preparing to unpack .../031-node-process-nextick-args_2.0.1-2_all.deb ...\n",
            "Unpacking node-process-nextick-args (2.0.1-2) ...\n",
            "Selecting previously unselected package node-util-deprecate.\n",
            "Preparing to unpack .../032-node-util-deprecate_1.0.2-3_all.deb ...\n",
            "Unpacking node-util-deprecate (1.0.2-3) ...\n",
            "Selecting previously unselected package node-isarray.\n",
            "Preparing to unpack .../033-node-isarray_2.0.5-3_all.deb ...\n",
            "Unpacking node-isarray (2.0.5-3) ...\n",
            "Selecting previously unselected package node-readable-stream.\n",
            "Preparing to unpack .../034-node-readable-stream_3.6.0+~cs3.0.0-1_all.deb ...\n",
            "Unpacking node-readable-stream (3.6.0+~cs3.0.0-1) ...\n",
            "Selecting previously unselected package node-are-we-there-yet.\n",
            "Preparing to unpack .../035-node-are-we-there-yet_3.0.0+~1.1.0-1_all.deb ...\n",
            "Unpacking node-are-we-there-yet (3.0.0+~1.1.0-1) ...\n",
            "Selecting previously unselected package node-arrify.\n",
            "Preparing to unpack .../036-node-arrify_2.0.1-2_all.deb ...\n",
            "Unpacking node-arrify (2.0.1-2) ...\n",
            "Selecting previously unselected package node-asap.\n",
            "Preparing to unpack .../037-node-asap_2.0.6+~2.0.0-1_all.deb ...\n",
            "Unpacking node-asap (2.0.6+~2.0.0-1) ...\n",
            "Selecting previously unselected package node-asynckit.\n",
            "Preparing to unpack .../038-node-asynckit_0.4.0-4_all.deb ...\n",
            "Unpacking node-asynckit (0.4.0-4) ...\n",
            "Selecting previously unselected package node-builtins.\n",
            "Preparing to unpack .../039-node-builtins_4.0.0-1_all.deb ...\n",
            "Unpacking node-builtins (4.0.0-1) ...\n",
            "Selecting previously unselected package node-chownr.\n",
            "Preparing to unpack .../040-node-chownr_2.0.0-1_all.deb ...\n",
            "Unpacking node-chownr (2.0.0-1) ...\n",
            "Selecting previously unselected package node-fs.realpath.\n",
            "Preparing to unpack .../041-node-fs.realpath_1.0.0-2_all.deb ...\n",
            "Unpacking node-fs.realpath (1.0.0-2) ...\n",
            "Selecting previously unselected package node-wrappy.\n",
            "Preparing to unpack .../042-node-wrappy_1.0.2-2_all.deb ...\n",
            "Unpacking node-wrappy (1.0.2-2) ...\n",
            "Selecting previously unselected package node-once.\n",
            "Preparing to unpack .../043-node-once_1.4.0-4_all.deb ...\n",
            "Unpacking node-once (1.4.0-4) ...\n",
            "Selecting previously unselected package node-inflight.\n",
            "Preparing to unpack .../044-node-inflight_1.0.6-2_all.deb ...\n",
            "Unpacking node-inflight (1.0.6-2) ...\n",
            "Selecting previously unselected package node-balanced-match.\n",
            "Preparing to unpack .../045-node-balanced-match_2.0.0-1_all.deb ...\n",
            "Unpacking node-balanced-match (2.0.0-1) ...\n",
            "Selecting previously unselected package node-brace-expansion.\n",
            "Preparing to unpack .../046-node-brace-expansion_2.0.1-1_all.deb ...\n",
            "Unpacking node-brace-expansion (2.0.1-1) ...\n",
            "Selecting previously unselected package node-minimatch.\n",
            "Preparing to unpack .../047-node-minimatch_3.1.1+~3.0.5-1_all.deb ...\n",
            "Unpacking node-minimatch (3.1.1+~3.0.5-1) ...\n",
            "Selecting previously unselected package node-path-is-absolute.\n",
            "Preparing to unpack .../048-node-path-is-absolute_2.0.0-2_all.deb ...\n",
            "Unpacking node-path-is-absolute (2.0.0-2) ...\n",
            "Selecting previously unselected package node-glob.\n",
            "Preparing to unpack .../049-node-glob_7.2.1+~cs7.6.15-1_all.deb ...\n",
            "Unpacking node-glob (7.2.1+~cs7.6.15-1) ...\n",
            "Selecting previously unselected package node-graceful-fs.\n",
            "Preparing to unpack .../050-node-graceful-fs_4.2.4+repack-1_all.deb ...\n",
            "Unpacking node-graceful-fs (4.2.4+repack-1) ...\n",
            "Selecting previously unselected package node-mkdirp.\n",
            "Preparing to unpack .../051-node-mkdirp_1.0.4+~1.0.2-1_all.deb ...\n",
            "Unpacking node-mkdirp (1.0.4+~1.0.2-1) ...\n",
            "Selecting previously unselected package node-iferr.\n",
            "Preparing to unpack .../052-node-iferr_1.0.2+~1.0.2-1_all.deb ...\n",
            "Unpacking node-iferr (1.0.2+~1.0.2-1) ...\n",
            "Selecting previously unselected package node-imurmurhash.\n",
            "Preparing to unpack .../053-node-imurmurhash_0.1.4+dfsg+~0.1.1-1_all.deb ...\n",
            "Unpacking node-imurmurhash (0.1.4+dfsg+~0.1.1-1) ...\n",
            "Selecting previously unselected package node-fs-write-stream-atomic.\n",
            "Preparing to unpack .../054-node-fs-write-stream-atomic_1.0.10-5_all.deb ...\n",
            "Unpacking node-fs-write-stream-atomic (1.0.10-5) ...\n",
            "Selecting previously unselected package node-rimraf.\n",
            "Preparing to unpack .../055-node-rimraf_3.0.2-1_all.deb ...\n",
            "Unpacking node-rimraf (3.0.2-1) ...\n",
            "Selecting previously unselected package node-run-queue.\n",
            "Preparing to unpack .../056-node-run-queue_2.0.0-2_all.deb ...\n",
            "Unpacking node-run-queue (2.0.0-2) ...\n",
            "Selecting previously unselected package node-copy-concurrently.\n",
            "Preparing to unpack .../057-node-copy-concurrently_1.0.5-8_all.deb ...\n",
            "Unpacking node-copy-concurrently (1.0.5-8) ...\n",
            "Selecting previously unselected package node-move-concurrently.\n",
            "Preparing to unpack .../058-node-move-concurrently_1.0.1-4_all.deb ...\n",
            "Unpacking node-move-concurrently (1.0.1-4) ...\n",
            "Selecting previously unselected package node-escape-string-regexp.\n",
            "Preparing to unpack .../059-node-escape-string-regexp_4.0.0-2_all.deb ...\n",
            "Unpacking node-escape-string-regexp (4.0.0-2) ...\n",
            "Selecting previously unselected package node-indent-string.\n",
            "Preparing to unpack .../060-node-indent-string_4.0.0-2_all.deb ...\n",
            "Unpacking node-indent-string (4.0.0-2) ...\n",
            "Selecting previously unselected package node-p-map.\n",
            "Preparing to unpack .../061-node-p-map_4.0.0+~3.1.0+~3.0.1-1_all.deb ...\n",
            "Unpacking node-p-map (4.0.0+~3.1.0+~3.0.1-1) ...\n",
            "Selecting previously unselected package node-promise-inflight.\n",
            "Preparing to unpack .../062-node-promise-inflight_1.0.1+~1.0.0-1_all.deb ...\n",
            "Unpacking node-promise-inflight (1.0.1+~1.0.0-1) ...\n",
            "Selecting previously unselected package node-ssri.\n",
            "Preparing to unpack .../063-node-ssri_8.0.1-2_all.deb ...\n",
            "Unpacking node-ssri (8.0.1-2) ...\n",
            "Selecting previously unselected package node-unique-filename.\n",
            "Preparing to unpack .../064-node-unique-filename_1.1.1+ds-1_all.deb ...\n",
            "Unpacking node-unique-filename (1.1.1+ds-1) ...\n",
            "Selecting previously unselected package node-cacache.\n",
            "Preparing to unpack .../065-node-cacache_15.0.5+~cs13.9.21-3_all.deb ...\n",
            "Unpacking node-cacache (15.0.5+~cs13.9.21-3) ...\n",
            "Selecting previously unselected package node-clean-yaml-object.\n",
            "Preparing to unpack .../066-node-clean-yaml-object_0.1.0-5_all.deb ...\n",
            "Unpacking node-clean-yaml-object (0.1.0-5) ...\n",
            "Selecting previously unselected package node-clone.\n",
            "Preparing to unpack .../067-node-clone_2.1.2-3_all.deb ...\n",
            "Unpacking node-clone (2.1.2-3) ...\n",
            "Selecting previously unselected package node-color-name.\n",
            "Preparing to unpack .../068-node-color-name_1.1.4+~1.1.1-2_all.deb ...\n",
            "Unpacking node-color-name (1.1.4+~1.1.1-2) ...\n",
            "Selecting previously unselected package node-color-convert.\n",
            "Preparing to unpack .../069-node-color-convert_2.0.1-1_all.deb ...\n",
            "Unpacking node-color-convert (2.0.1-1) ...\n",
            "Selecting previously unselected package node-colors.\n",
            "Preparing to unpack .../070-node-colors_1.4.0-3_all.deb ...\n",
            "Unpacking node-colors (1.4.0-3) ...\n",
            "Selecting previously unselected package node-strip-ansi.\n",
            "Preparing to unpack .../071-node-strip-ansi_6.0.1-1_all.deb ...\n",
            "Unpacking node-strip-ansi (6.0.1-1) ...\n",
            "Selecting previously unselected package node-defaults.\n",
            "Preparing to unpack .../072-node-defaults_1.0.3+~1.0.3-1_all.deb ...\n",
            "Unpacking node-defaults (1.0.3+~1.0.3-1) ...\n",
            "Selecting previously unselected package node-wcwidth.js.\n",
            "Preparing to unpack .../073-node-wcwidth.js_1.0.2-1_all.deb ...\n",
            "Unpacking node-wcwidth.js (1.0.2-1) ...\n",
            "Selecting previously unselected package node-columnify.\n",
            "Preparing to unpack .../074-node-columnify_1.5.4+~1.5.1-1_all.deb ...\n",
            "Unpacking node-columnify (1.5.4+~1.5.1-1) ...\n",
            "Selecting previously unselected package node-console-control-strings.\n",
            "Preparing to unpack .../075-node-console-control-strings_1.1.0-2_all.deb ...\n",
            "Unpacking node-console-control-strings (1.1.0-2) ...\n",
            "Selecting previously unselected package node-growl.\n",
            "Preparing to unpack .../076-node-growl_1.10.5-4_all.deb ...\n",
            "Unpacking node-growl (1.10.5-4) ...\n",
            "Selecting previously unselected package node-sprintf-js.\n",
            "Preparing to unpack .../077-node-sprintf-js_1.1.2+ds1+~1.1.2-1_all.deb ...\n",
            "Unpacking node-sprintf-js (1.1.2+ds1+~1.1.2-1) ...\n",
            "Selecting previously unselected package node-argparse.\n",
            "Preparing to unpack .../078-node-argparse_2.0.1-2_all.deb ...\n",
            "Unpacking node-argparse (2.0.1-2) ...\n",
            "Selecting previously unselected package node-esprima.\n",
            "Preparing to unpack .../079-node-esprima_4.0.1+ds+~4.0.3-2_all.deb ...\n",
            "Unpacking node-esprima (4.0.1+ds+~4.0.3-2) ...\n",
            "Selecting previously unselected package node-js-yaml.\n",
            "Preparing to unpack .../080-node-js-yaml_4.1.0+dfsg+~4.0.5-6_all.deb ...\n",
            "Unpacking node-js-yaml (4.1.0+dfsg+~4.0.5-6) ...\n",
            "Selecting previously unselected package node-lcov-parse.\n",
            "Preparing to unpack .../081-node-lcov-parse_1.0.0+20170612git80d039574ed9-5_all.deb ...\n",
            "Unpacking node-lcov-parse (1.0.0+20170612git80d039574ed9-5) ...\n",
            "Selecting previously unselected package node-log-driver.\n",
            "Preparing to unpack .../082-node-log-driver_1.2.7+git+20180219+bba1761737-7_all.deb ...\n",
            "Unpacking node-log-driver (1.2.7+git+20180219+bba1761737-7) ...\n",
            "Selecting previously unselected package node-is-plain-obj.\n",
            "Preparing to unpack .../083-node-is-plain-obj_3.0.0-2_all.deb ...\n",
            "Unpacking node-is-plain-obj (3.0.0-2) ...\n",
            "Selecting previously unselected package node-is-buffer.\n",
            "Preparing to unpack .../084-node-is-buffer_2.0.5-2_all.deb ...\n",
            "Unpacking node-is-buffer (2.0.5-2) ...\n",
            "Selecting previously unselected package node-kind-of.\n",
            "Preparing to unpack .../085-node-kind-of_6.0.3+dfsg-2_all.deb ...\n",
            "Unpacking node-kind-of (6.0.3+dfsg-2) ...\n",
            "Selecting previously unselected package node-minimist.\n",
            "Preparing to unpack .../086-node-minimist_1.2.5+~cs5.3.2-1_all.deb ...\n",
            "Unpacking node-minimist (1.2.5+~cs5.3.2-1) ...\n",
            "Selecting previously unselected package node-cssom.\n",
            "Preparing to unpack .../087-node-cssom_0.4.4-3_all.deb ...\n",
            "Unpacking node-cssom (0.4.4-3) ...\n",
            "Selecting previously unselected package node-cssstyle.\n",
            "Preparing to unpack .../088-node-cssstyle_2.3.0-2_all.deb ...\n",
            "Unpacking node-cssstyle (2.3.0-2) ...\n",
            "Selecting previously unselected package node-delayed-stream.\n",
            "Preparing to unpack .../089-node-delayed-stream_1.0.0-5_all.deb ...\n",
            "Unpacking node-delayed-stream (1.0.0-5) ...\n",
            "Selecting previously unselected package node-combined-stream.\n",
            "Preparing to unpack .../090-node-combined-stream_1.0.8+~1.0.3-1_all.deb ...\n",
            "Unpacking node-combined-stream (1.0.8+~1.0.3-1) ...\n",
            "Selecting previously unselected package node-mime.\n",
            "Preparing to unpack .../091-node-mime_3.0.0+dfsg+~cs3.96.1-1_all.deb ...\n",
            "Unpacking node-mime (3.0.0+dfsg+~cs3.96.1-1) ...\n",
            "Selecting previously unselected package node-mime-types.\n",
            "Preparing to unpack .../092-node-mime-types_2.1.33-1_all.deb ...\n",
            "Unpacking node-mime-types (2.1.33-1) ...\n",
            "Selecting previously unselected package node-form-data.\n",
            "Preparing to unpack .../093-node-form-data_3.0.1-1_all.deb ...\n",
            "Unpacking node-form-data (3.0.1-1) ...\n",
            "Selecting previously unselected package node-events.\n",
            "Preparing to unpack .../094-node-events_3.3.0+~3.0.0-2_all.deb ...\n",
            "Unpacking node-events (3.3.0+~3.0.0-2) ...\n",
            "Selecting previously unselected package node-https-proxy-agent.\n",
            "Preparing to unpack .../095-node-https-proxy-agent_5.0.0+~cs8.0.0-3_all.deb ...\n",
            "Unpacking node-https-proxy-agent (5.0.0+~cs8.0.0-3) ...\n",
            "Selecting previously unselected package node-iconv-lite.\n",
            "Preparing to unpack .../096-node-iconv-lite_0.6.3-2_all.deb ...\n",
            "Unpacking node-iconv-lite (0.6.3-2) ...\n",
            "Selecting previously unselected package node-lodash-packages.\n",
            "Preparing to unpack .../097-node-lodash-packages_4.17.21+dfsg+~cs8.31.198.20210220-5_all.deb ...\n",
            "Unpacking node-lodash-packages (4.17.21+dfsg+~cs8.31.198.20210220-5) ...\n",
            "Selecting previously unselected package node-stealthy-require.\n",
            "Preparing to unpack .../098-node-stealthy-require_1.1.1-5_all.deb ...\n",
            "Unpacking node-stealthy-require (1.1.1-5) ...\n",
            "Selecting previously unselected package node-punycode.\n",
            "Preparing to unpack .../099-node-punycode_2.1.1-5_all.deb ...\n",
            "Unpacking node-punycode (2.1.1-5) ...\n",
            "Selecting previously unselected package node-psl.\n",
            "Preparing to unpack .../100-node-psl_1.8.0+ds-6_all.deb ...\n",
            "Unpacking node-psl (1.8.0+ds-6) ...\n",
            "Selecting previously unselected package node-universalify.\n",
            "Preparing to unpack .../101-node-universalify_2.0.0-3_all.deb ...\n",
            "Unpacking node-universalify (2.0.0-3) ...\n",
            "Selecting previously unselected package node-tough-cookie.\n",
            "Preparing to unpack .../102-node-tough-cookie_4.0.0-2_all.deb ...\n",
            "Unpacking node-tough-cookie (4.0.0-2) ...\n",
            "Selecting previously unselected package node-webidl-conversions.\n",
            "Preparing to unpack .../103-node-webidl-conversions_7.0.0~1.1.0+~cs15.1.20180823-2_all.deb ...\n",
            "Unpacking node-webidl-conversions (7.0.0~1.1.0+~cs15.1.20180823-2) ...\n",
            "Selecting previously unselected package node-commander.\n",
            "Preparing to unpack .../104-node-commander_9.0.0-2_all.deb ...\n",
            "Unpacking node-commander (9.0.0-2) ...\n",
            "Selecting previously unselected package node-mute-stream.\n",
            "Preparing to unpack .../105-node-mute-stream_0.0.8+~0.0.1-1_all.deb ...\n",
            "Unpacking node-mute-stream (0.0.8+~0.0.1-1) ...\n",
            "Selecting previously unselected package node-read.\n",
            "Preparing to unpack .../106-node-read_1.0.7-3_all.deb ...\n",
            "Unpacking node-read (1.0.7-3) ...\n",
            "Selecting previously unselected package node-ws.\n",
            "Preparing to unpack .../107-node-ws_8.5.0+~cs13.3.3-2_all.deb ...\n",
            "Unpacking node-ws (8.5.0+~cs13.3.3-2) ...\n",
            "Selecting previously unselected package node-jsdom.\n",
            "Preparing to unpack .../108-node-jsdom_19.0.0+~cs90.11.27-1_all.deb ...\n",
            "Unpacking node-jsdom (19.0.0+~cs90.11.27-1) ...\n",
            "Selecting previously unselected package node-fetch.\n",
            "Preparing to unpack .../109-node-fetch_2.6.7+~2.5.12-1_all.deb ...\n",
            "Unpacking node-fetch (2.6.7+~2.5.12-1) ...\n",
            "Selecting previously unselected package node-coveralls.\n",
            "Preparing to unpack .../110-node-coveralls_3.1.1-1_all.deb ...\n",
            "Unpacking node-coveralls (3.1.1-1) ...\n",
            "Selecting previously unselected package node-mimic-response.\n",
            "Preparing to unpack .../111-node-mimic-response_3.1.0-7_all.deb ...\n",
            "Unpacking node-mimic-response (3.1.0-7) ...\n",
            "Selecting previously unselected package node-decompress-response.\n",
            "Preparing to unpack .../112-node-decompress-response_6.0.0-2_all.deb ...\n",
            "Unpacking node-decompress-response (6.0.0-2) ...\n",
            "Selecting previously unselected package node-diff.\n",
            "Preparing to unpack .../113-node-diff_5.0.0~dfsg+~5.0.1-3_all.deb ...\n",
            "Unpacking node-diff (5.0.0~dfsg+~5.0.1-3) ...\n",
            "Selecting previously unselected package node-err-code.\n",
            "Preparing to unpack .../114-node-err-code_2.0.3+dfsg-3_all.deb ...\n",
            "Unpacking node-err-code (2.0.3+dfsg-3) ...\n",
            "Selecting previously unselected package node-time-stamp.\n",
            "Preparing to unpack .../115-node-time-stamp_2.2.0-1_all.deb ...\n",
            "Unpacking node-time-stamp (2.2.0-1) ...\n",
            "Selecting previously unselected package node-fancy-log.\n",
            "Preparing to unpack .../116-node-fancy-log_1.3.3+~cs1.3.1-2_all.deb ...\n",
            "Unpacking node-fancy-log (1.3.3+~cs1.3.1-2) ...\n",
            "Selecting previously unselected package node-signal-exit.\n",
            "Preparing to unpack .../117-node-signal-exit_3.0.6+~3.0.1-1_all.deb ...\n",
            "Unpacking node-signal-exit (3.0.6+~3.0.1-1) ...\n",
            "Selecting previously unselected package node-foreground-child.\n",
            "Preparing to unpack .../118-node-foreground-child_2.0.0-3_all.deb ...\n",
            "Unpacking node-foreground-child (2.0.0-3) ...\n",
            "Selecting previously unselected package node-function-bind.\n",
            "Preparing to unpack .../119-node-function-bind_1.1.1+repacked+~1.0.3-1_all.deb ...\n",
            "Unpacking node-function-bind (1.1.1+repacked+~1.0.3-1) ...\n",
            "Selecting previously unselected package node-has-unicode.\n",
            "Preparing to unpack .../120-node-has-unicode_2.0.1-4_all.deb ...\n",
            "Unpacking node-has-unicode (2.0.1-4) ...\n",
            "Selecting previously unselected package node-ansi-styles.\n",
            "Preparing to unpack .../121-node-ansi-styles_4.3.0+~4.2.0-1_all.deb ...\n",
            "Unpacking node-ansi-styles (4.3.0+~4.2.0-1) ...\n",
            "Selecting previously unselected package node-slice-ansi.\n",
            "Preparing to unpack .../122-node-slice-ansi_5.0.0+~cs9.0.0-4_all.deb ...\n",
            "Unpacking node-slice-ansi (5.0.0+~cs9.0.0-4) ...\n",
            "Selecting previously unselected package node-string-width.\n",
            "Preparing to unpack .../123-node-string-width_4.2.3+~cs13.2.3-1_all.deb ...\n",
            "Unpacking node-string-width (4.2.3+~cs13.2.3-1) ...\n",
            "Selecting previously unselected package node-wide-align.\n",
            "Preparing to unpack .../124-node-wide-align_1.1.3-4_all.deb ...\n",
            "Unpacking node-wide-align (1.1.3-4) ...\n",
            "Selecting previously unselected package node-gauge.\n",
            "Preparing to unpack .../125-node-gauge_4.0.2-1_all.deb ...\n",
            "Unpacking node-gauge (4.0.2-1) ...\n",
            "Selecting previously unselected package node-end-of-stream.\n",
            "Preparing to unpack .../126-node-end-of-stream_1.4.4+~1.4.1-1_all.deb ...\n",
            "Unpacking node-end-of-stream (1.4.4+~1.4.1-1) ...\n",
            "Selecting previously unselected package node-pump.\n",
            "Preparing to unpack .../127-node-pump_3.0.0-5_all.deb ...\n",
            "Unpacking node-pump (3.0.0-5) ...\n",
            "Selecting previously unselected package node-get-stream.\n",
            "Preparing to unpack .../128-node-get-stream_6.0.1-1_all.deb ...\n",
            "Unpacking node-get-stream (6.0.1-1) ...\n",
            "Selecting previously unselected package node-lowercase-keys.\n",
            "Preparing to unpack .../129-node-lowercase-keys_2.0.0-2_all.deb ...\n",
            "Unpacking node-lowercase-keys (2.0.0-2) ...\n",
            "Selecting previously unselected package node-json-buffer.\n",
            "Preparing to unpack .../130-node-json-buffer_3.0.1-1_all.deb ...\n",
            "Unpacking node-json-buffer (3.0.1-1) ...\n",
            "Selecting previously unselected package node-p-cancelable.\n",
            "Preparing to unpack .../131-node-p-cancelable_2.1.1-1_all.deb ...\n",
            "Unpacking node-p-cancelable (2.1.1-1) ...\n",
            "Selecting previously unselected package node-quick-lru.\n",
            "Preparing to unpack .../132-node-quick-lru_5.1.1-1_all.deb ...\n",
            "Unpacking node-quick-lru (5.1.1-1) ...\n",
            "Selecting previously unselected package node-got.\n",
            "Preparing to unpack .../133-node-got_11.8.3+~cs58.7.37-1_all.deb ...\n",
            "Unpacking node-got (11.8.3+~cs58.7.37-1) ...\n",
            "Selecting previously unselected package node-has-flag.\n",
            "Preparing to unpack .../134-node-has-flag_4.0.0-2_all.deb ...\n",
            "Unpacking node-has-flag (4.0.0-2) ...\n",
            "Selecting previously unselected package node-hosted-git-info.\n",
            "Preparing to unpack .../135-node-hosted-git-info_4.0.2-1_all.deb ...\n",
            "Unpacking node-hosted-git-info (4.0.2-1) ...\n",
            "Selecting previously unselected package node-ip.\n",
            "Preparing to unpack .../136-node-ip_1.1.5+~1.1.0-1_all.deb ...\n",
            "Unpacking node-ip (1.1.5+~1.1.0-1) ...\n",
            "Selecting previously unselected package node-ip-regex.\n",
            "Preparing to unpack .../137-node-ip-regex_4.3.0+~4.1.1-1_all.deb ...\n",
            "Unpacking node-ip-regex (4.3.0+~4.1.1-1) ...\n",
            "Selecting previously unselected package node-is-typedarray.\n",
            "Preparing to unpack .../138-node-is-typedarray_1.0.0-4_all.deb ...\n",
            "Unpacking node-is-typedarray (1.0.0-4) ...\n",
            "Selecting previously unselected package node-isexe.\n",
            "Preparing to unpack .../139-node-isexe_2.0.0+~2.0.1-4_all.deb ...\n",
            "Unpacking node-isexe (2.0.0+~2.0.1-4) ...\n",
            "Selecting previously unselected package node-json-parse-better-errors.\n",
            "Preparing to unpack .../140-node-json-parse-better-errors_1.0.2+~cs3.3.1-1_all.deb ...\n",
            "Unpacking node-json-parse-better-errors (1.0.2+~cs3.3.1-1) ...\n",
            "Selecting previously unselected package node-encoding.\n",
            "Preparing to unpack .../141-node-encoding_0.1.13-2_all.deb ...\n",
            "Unpacking node-encoding (0.1.13-2) ...\n",
            "Selecting previously unselected package node-jsonparse.\n",
            "Preparing to unpack .../142-node-jsonparse_1.3.1-10_all.deb ...\n",
            "Unpacking node-jsonparse (1.3.1-10) ...\n",
            "Selecting previously unselected package node-minipass.\n",
            "Preparing to unpack .../143-node-minipass_3.1.6+~cs8.7.18-1_all.deb ...\n",
            "Unpacking node-minipass (3.1.6+~cs8.7.18-1) ...\n",
            "Selecting previously unselected package node-npm-bundled.\n",
            "Preparing to unpack .../144-node-npm-bundled_1.1.2-1_all.deb ...\n",
            "Unpacking node-npm-bundled (1.1.2-1) ...\n",
            "Selecting previously unselected package node-osenv.\n",
            "Preparing to unpack .../145-node-osenv_0.1.5+~0.1.0-1_all.deb ...\n",
            "Unpacking node-osenv (0.1.5+~0.1.0-1) ...\n",
            "Selecting previously unselected package node-validate-npm-package-name.\n",
            "Preparing to unpack .../146-node-validate-npm-package-name_3.0.0-4_all.deb ...\n",
            "Unpacking node-validate-npm-package-name (3.0.0-4) ...\n",
            "Selecting previously unselected package node-npm-package-arg.\n",
            "Preparing to unpack .../147-node-npm-package-arg_8.1.5-1_all.deb ...\n",
            "Unpacking node-npm-package-arg (8.1.5-1) ...\n",
            "Selecting previously unselected package node-object-assign.\n",
            "Preparing to unpack .../148-node-object-assign_4.1.1-6_all.deb ...\n",
            "Unpacking node-object-assign (4.1.1-6) ...\n",
            "Selecting previously unselected package node-opener.\n",
            "Preparing to unpack .../149-node-opener_1.5.2+~1.4.0-1_all.deb ...\n",
            "Unpacking node-opener (1.5.2+~1.4.0-1) ...\n",
            "Selecting previously unselected package node-retry.\n",
            "Preparing to unpack .../150-node-retry_0.13.1+~0.12.1-1_all.deb ...\n",
            "Unpacking node-retry (0.13.1+~0.12.1-1) ...\n",
            "Selecting previously unselected package node-promise-retry.\n",
            "Preparing to unpack .../151-node-promise-retry_2.0.1-2_all.deb ...\n",
            "Unpacking node-promise-retry (2.0.1-2) ...\n",
            "Selecting previously unselected package node-promzard.\n",
            "Preparing to unpack .../152-node-promzard_0.3.0-2_all.deb ...\n",
            "Unpacking node-promzard (0.3.0-2) ...\n",
            "Selecting previously unselected package node-set-blocking.\n",
            "Preparing to unpack .../153-node-set-blocking_2.0.0-2_all.deb ...\n",
            "Unpacking node-set-blocking (2.0.0-2) ...\n",
            "Selecting previously unselected package node-slash.\n",
            "Preparing to unpack .../154-node-slash_3.0.0-2_all.deb ...\n",
            "Unpacking node-slash (3.0.0-2) ...\n",
            "Selecting previously unselected package libjs-source-map.\n",
            "Preparing to unpack .../155-libjs-source-map_0.7.0++dfsg2+really.0.6.1-9_all.deb ...\n",
            "Unpacking libjs-source-map (0.7.0++dfsg2+really.0.6.1-9) ...\n",
            "Selecting previously unselected package node-source-map.\n",
            "Preparing to unpack .../156-node-source-map_0.7.0++dfsg2+really.0.6.1-9_all.deb ...\n",
            "Unpacking node-source-map (0.7.0++dfsg2+really.0.6.1-9) ...\n",
            "Selecting previously unselected package node-source-map-support.\n",
            "Preparing to unpack .../157-node-source-map-support_0.5.21+ds+~0.5.4-1_all.deb ...\n",
            "Unpacking node-source-map-support (0.5.21+ds+~0.5.4-1) ...\n",
            "Selecting previously unselected package node-spdx-license-ids.\n",
            "Preparing to unpack .../158-node-spdx-license-ids_3.0.11-1_all.deb ...\n",
            "Unpacking node-spdx-license-ids (3.0.11-1) ...\n",
            "Selecting previously unselected package node-spdx-exceptions.\n",
            "Preparing to unpack .../159-node-spdx-exceptions_2.3.0-2_all.deb ...\n",
            "Unpacking node-spdx-exceptions (2.3.0-2) ...\n",
            "Selecting previously unselected package node-spdx-expression-parse.\n",
            "Preparing to unpack .../160-node-spdx-expression-parse_3.0.1+~3.0.1-1_all.deb ...\n",
            "Unpacking node-spdx-expression-parse (3.0.1+~3.0.1-1) ...\n",
            "Selecting previously unselected package node-spdx-correct.\n",
            "Preparing to unpack .../161-node-spdx-correct_3.1.1-2_all.deb ...\n",
            "Unpacking node-spdx-correct (3.1.1-2) ...\n",
            "Selecting previously unselected package node-stack-utils.\n",
            "Preparing to unpack .../162-node-stack-utils_2.0.5+~2.0.1-1_all.deb ...\n",
            "Unpacking node-stack-utils (2.0.5+~2.0.1-1) ...\n",
            "Selecting previously unselected package node-supports-color.\n",
            "Preparing to unpack .../163-node-supports-color_8.1.1+~8.1.1-1_all.deb ...\n",
            "Unpacking node-supports-color (8.1.1+~8.1.1-1) ...\n",
            "Selecting previously unselected package node-tap-parser.\n",
            "Preparing to unpack .../164-node-tap-parser_7.0.0+ds1-6_all.deb ...\n",
            "Unpacking node-tap-parser (7.0.0+ds1-6) ...\n",
            "Selecting previously unselected package node-tap-mocha-reporter.\n",
            "Preparing to unpack .../165-node-tap-mocha-reporter_3.0.7+ds-2_all.deb ...\n",
            "Unpacking node-tap-mocha-reporter (3.0.7+ds-2) ...\n",
            "Selecting previously unselected package node-text-table.\n",
            "Preparing to unpack .../166-node-text-table_0.2.0-4_all.deb ...\n",
            "Unpacking node-text-table (0.2.0-4) ...\n",
            "Selecting previously unselected package node-tmatch.\n",
            "Preparing to unpack .../167-node-tmatch_5.0.0-4_all.deb ...\n",
            "Unpacking node-tmatch (5.0.0-4) ...\n",
            "Selecting previously unselected package node-typedarray-to-buffer.\n",
            "Preparing to unpack .../168-node-typedarray-to-buffer_4.0.0-2_all.deb ...\n",
            "Unpacking node-typedarray-to-buffer (4.0.0-2) ...\n",
            "Selecting previously unselected package node-validate-npm-package-license.\n",
            "Preparing to unpack .../169-node-validate-npm-package-license_3.0.4-2_all.deb ...\n",
            "Unpacking node-validate-npm-package-license (3.0.4-2) ...\n",
            "Selecting previously unselected package node-whatwg-fetch.\n",
            "Preparing to unpack .../170-node-whatwg-fetch_3.6.2-5_all.deb ...\n",
            "Unpacking node-whatwg-fetch (3.6.2-5) ...\n",
            "Selecting previously unselected package node-write-file-atomic.\n",
            "Preparing to unpack .../171-node-write-file-atomic_3.0.3+~3.0.2-1_all.deb ...\n",
            "Unpacking node-write-file-atomic (3.0.3+~3.0.2-1) ...\n",
            "Selecting previously unselected package nodejs-doc.\n",
            "Preparing to unpack .../172-nodejs-doc_12.22.9~dfsg-1ubuntu3.6_all.deb ...\n",
            "Unpacking nodejs-doc (12.22.9~dfsg-1ubuntu3.6) ...\n",
            "Selecting previously unselected package node-abbrev.\n",
            "Preparing to unpack .../173-node-abbrev_1.1.1+~1.1.2-1_all.deb ...\n",
            "Unpacking node-abbrev (1.1.1+~1.1.2-1) ...\n",
            "Selecting previously unselected package node-archy.\n",
            "Preparing to unpack .../174-node-archy_1.0.0-4_all.deb ...\n",
            "Unpacking node-archy (1.0.0-4) ...\n",
            "Selecting previously unselected package node-chalk.\n",
            "Preparing to unpack .../175-node-chalk_4.1.2-1_all.deb ...\n",
            "Unpacking node-chalk (4.1.2-1) ...\n",
            "Selecting previously unselected package node-cli-table.\n",
            "Preparing to unpack .../176-node-cli-table_0.3.11+~cs0.13.3-1_all.deb ...\n",
            "Unpacking node-cli-table (0.3.11+~cs0.13.3-1) ...\n",
            "Selecting previously unselected package node-depd.\n",
            "Preparing to unpack .../177-node-depd_2.0.0-2_all.deb ...\n",
            "Unpacking node-depd (2.0.0-2) ...\n",
            "Selecting previously unselected package node-nopt.\n",
            "Preparing to unpack .../178-node-nopt_5.0.0-2_all.deb ...\n",
            "Unpacking node-nopt (5.0.0-2) ...\n",
            "Selecting previously unselected package node-npmlog.\n",
            "Preparing to unpack .../179-node-npmlog_6.0.1+~4.1.4-1_all.deb ...\n",
            "Unpacking node-npmlog (6.0.1+~4.1.4-1) ...\n",
            "Selecting previously unselected package node-tar.\n",
            "Preparing to unpack .../180-node-tar_6.1.11+ds1+~cs6.0.6-1_all.deb ...\n",
            "Unpacking node-tar (6.1.11+ds1+~cs6.0.6-1) ...\n",
            "Selecting previously unselected package node-which.\n",
            "Preparing to unpack .../181-node-which_2.0.2+~cs1.3.2-2_all.deb ...\n",
            "Unpacking node-which (2.0.2+~cs1.3.2-2) ...\n",
            "Selecting previously unselected package node-gyp.\n",
            "Preparing to unpack .../182-node-gyp_8.4.1-1_all.deb ...\n",
            "Unpacking node-gyp (8.4.1-1) ...\n",
            "Selecting previously unselected package node-ini.\n",
            "Preparing to unpack .../183-node-ini_2.0.1-1_all.deb ...\n",
            "Unpacking node-ini (2.0.1-1) ...\n",
            "Selecting previously unselected package node-negotiator.\n",
            "Preparing to unpack .../184-node-negotiator_0.6.2+~0.6.1-1_all.deb ...\n",
            "Unpacking node-negotiator (0.6.2+~0.6.1-1) ...\n",
            "Selecting previously unselected package node-resolve.\n",
            "Preparing to unpack .../185-node-resolve_1.20.0+~cs5.27.9-1_all.deb ...\n",
            "Unpacking node-resolve (1.20.0+~cs5.27.9-1) ...\n",
            "Selecting previously unselected package node-normalize-package-data.\n",
            "Preparing to unpack .../186-node-normalize-package-data_3.0.3+~2.4.1-1_all.deb ...\n",
            "Unpacking node-normalize-package-data (3.0.3+~2.4.1-1) ...\n",
            "Selecting previously unselected package node-read-package-json.\n",
            "Preparing to unpack .../187-node-read-package-json_4.1.1-1_all.deb ...\n",
            "Unpacking node-read-package-json (4.1.1-1) ...\n",
            "Selecting previously unselected package node-tap.\n",
            "Preparing to unpack .../188-node-tap_12.0.1+ds-4_all.deb ...\n",
            "Unpacking node-tap (12.0.1+ds-4) ...\n",
            "Selecting previously unselected package npm.\n",
            "Preparing to unpack .../189-npm_8.5.1~ds-1_all.deb ...\n",
            "Unpacking npm (8.5.1~ds-1) ...\n",
            "Setting up node-delayed-stream (1.0.0-5) ...\n",
            "Setting up javascript-common (11+nmu1) ...\n",
            "Setting up libuv1-dev:amd64 (1.43.0-1ubuntu0.1) ...\n",
            "Setting up node-fs.realpath (1.0.0-2) ...\n",
            "Setting up node-diff (5.0.0~dfsg+~5.0.1-3) ...\n",
            "Setting up node-abbrev (1.1.1+~1.1.2-1) ...\n",
            "Setting up libjs-sprintf-js (1.1.2+ds1+~1.1.2-1) ...\n",
            "Setting up node-yallist (4.0.0+~4.0.1-1) ...\n",
            "Setting up libjs-inherits (2.0.4-4) ...\n",
            "Setting up node-p-cancelable (2.1.1-1) ...\n",
            "Setting up node-ansi-regex (5.0.1-1) ...\n",
            "Setting up node-slash (3.0.0-2) ...\n",
            "Setting up node-util-deprecate (1.0.2-3) ...\n",
            "Setting up node-retry (0.13.1+~0.12.1-1) ...\n",
            "Setting up node-arrify (2.0.1-2) ...\n",
            "Setting up node-ansistyles (0.1.3-5) ...\n",
            "Setting up node-delegates (1.0.0-3) ...\n",
            "Setting up node-depd (2.0.0-2) ...\n",
            "Setting up node-isexe (2.0.0+~2.0.1-4) ...\n",
            "Setting up node-jsonparse (1.3.1-10) ...\n",
            "Setting up node-escape-string-regexp (4.0.0-2) ...\n",
            "Setting up libjs-source-map (0.7.0++dfsg2+really.0.6.1-9) ...\n",
            "Setting up node-negotiator (0.6.2+~0.6.1-1) ...\n",
            "Setting up node-color-name (1.1.4+~1.1.1-2) ...\n",
            "Setting up libc-ares2:amd64 (1.18.1-1ubuntu0.22.04.3) ...\n",
            "Setting up node-indent-string (4.0.0-2) ...\n",
            "Setting up libnode72:amd64 (12.22.9~dfsg-1ubuntu3.6) ...\n",
            "Setting up node-function-bind (1.1.1+repacked+~1.0.3-1) ...\n",
            "Setting up node-p-map (4.0.0+~3.1.0+~3.0.1-1) ...\n",
            "Setting up node-iferr (1.0.2+~1.0.2-1) ...\n",
            "Setting up node-chownr (2.0.0-1) ...\n",
            "Setting up node-has-flag (4.0.0-2) ...\n",
            "Setting up node-lodash-packages (4.17.21+dfsg+~cs8.31.198.20210220-5) ...\n",
            "Setting up libjs-psl (1.8.0+ds-6) ...\n",
            "Setting up node-asap (2.0.6+~2.0.0-1) ...\n",
            "Setting up node-inherits (2.0.4-4) ...\n",
            "Setting up node-path-is-absolute (2.0.0-2) ...\n",
            "Setting up node-universalify (2.0.0-3) ...\n",
            "Setting up node-ini (2.0.1-1) ...\n",
            "Setting up node-safe-buffer (5.2.1+~cs2.1.2-2) ...\n",
            "Setting up node-promise-inflight (1.0.1+~1.0.0-1) ...\n",
            "Setting up node-json-parse-better-errors (1.0.2+~cs3.3.1-1) ...\n",
            "Setting up node-sprintf-js (1.1.2+ds1+~1.1.2-1) ...\n",
            "Setting up node-tmatch (5.0.0-4) ...\n",
            "Setting up node-err-code (2.0.3+dfsg-3) ...\n",
            "Setting up node-balanced-match (2.0.0-1) ...\n",
            "Setting up node-brace-expansion (2.0.1-1) ...\n",
            "Setting up libnotify4:amd64 (0.7.9-3ubuntu5.22.04.1) ...\n",
            "Setting up node-spdx-exceptions (2.3.0-2) ...\n",
            "Setting up node-set-blocking (2.0.0-2) ...\n",
            "Setting up node-npm-bundled (1.1.2-1) ...\n",
            "Setting up node-signal-exit (3.0.6+~3.0.1-1) ...\n",
            "Setting up node-source-map (0.7.0++dfsg2+really.0.6.1-9) ...\n",
            "Setting up node-wrappy (1.0.2-2) ...\n",
            "Setting up node-text-table (0.2.0-4) ...\n",
            "Setting up node-asynckit (0.4.0-4) ...\n",
            "Setting up node-ip (1.1.5+~1.1.0-1) ...\n",
            "Setting up node-quick-lru (5.1.1-1) ...\n",
            "Setting up libnotify-bin (0.7.9-3ubuntu5.22.04.1) ...\n",
            "Setting up node-mute-stream (0.0.8+~0.0.1-1) ...\n",
            "Setting up node-mimic-response (3.1.0-7) ...\n",
            "Setting up node-commander (9.0.0-2) ...\n",
            "Setting up node-whatwg-fetch (3.6.2-5) ...\n",
            "Setting up libjs-typedarray-to-buffer (4.0.0-2) ...\n",
            "Setting up libjs-highlight.js (9.18.5+dfsg1-1) ...\n",
            "Setting up node-clean-yaml-object (0.1.0-5) ...\n",
            "Setting up node-ip-regex (4.3.0+~4.1.1-1) ...\n",
            "Setting up node-stealthy-require (1.1.1-5) ...\n",
            "Setting up node-spdx-license-ids (3.0.11-1) ...\n",
            "Setting up node-string-decoder (1.3.0-5) ...\n",
            "Setting up node-time-stamp (2.2.0-1) ...\n",
            "Setting up libjs-events (3.3.0+~3.0.0-2) ...\n",
            "Setting up node-core-util-is (1.0.3-1) ...\n",
            "Setting up node-minimatch (3.1.1+~3.0.5-1) ...\n",
            "Setting up node-imurmurhash (0.1.4+dfsg+~0.1.1-1) ...\n",
            "Setting up node-foreground-child (2.0.0-3) ...\n",
            "Setting up node-read (1.0.7-3) ...\n",
            "Setting up node-is-buffer (2.0.5-2) ...\n",
            "Setting up node-color-convert (2.0.1-1) ...\n",
            "Setting up node-webidl-conversions (7.0.0~1.1.0+~cs15.1.20180823-2) ...\n",
            "Setting up node-isarray (2.0.5-3) ...\n",
            "Setting up node-osenv (0.1.5+~0.1.0-1) ...\n",
            "Setting up node-is-plain-obj (3.0.0-2) ...\n",
            "Setting up libjs-is-typedarray (1.0.0-4) ...\n",
            "Setting up node-lowercase-keys (2.0.0-2) ...\n",
            "Setting up node-decompress-response (6.0.0-2) ...\n",
            "Setting up node-process-nextick-args (2.0.1-2) ...\n",
            "Setting up node-has-unicode (2.0.1-4) ...\n",
            "Setting up gyp (0.1+20210831gitd6c5dd5-5) ...\n",
            "Setting up node-readable-stream (3.6.0+~cs3.0.0-1) ...\n",
            "Setting up node-lru-cache (6.0.0+~5.1.1-1) ...\n",
            "Setting up node-promise-retry (2.0.1-2) ...\n",
            "Setting up node-supports-color (8.1.1+~8.1.1-1) ...\n",
            "Setting up node-once (1.4.0-4) ...\n",
            "Setting up libnode-dev (12.22.9~dfsg-1ubuntu3.6) ...\n",
            "Setting up node-resolve (1.20.0+~cs5.27.9-1) ...\n",
            "Setting up node-are-we-there-yet (3.0.0+~1.1.0-1) ...\n",
            "Setting up node-kind-of (6.0.3+dfsg-2) ...\n",
            "Setting up node-growl (1.10.5-4) ...\n",
            "Setting up nodejs (12.22.9~dfsg-1ubuntu3.6) ...\n",
            "update-alternatives: using /usr/bin/nodejs to provide /usr/bin/js (js) in auto mode\n",
            "Setting up node-minimist (1.2.5+~cs5.3.2-1) ...\n",
            "Setting up node-abab (2.0.5-2) ...\n",
            "Setting up node-argparse (2.0.1-2) ...\n",
            "Setting up node-fancy-log (1.3.3+~cs1.3.1-2) ...\n",
            "Setting up node-clone (2.1.2-3) ...\n",
            "Setting up node-promzard (0.3.0-2) ...\n",
            "Setting up node-mime (3.0.0+dfsg+~cs3.96.1-1) ...\n",
            "Setting up node-source-map-support (0.5.21+ds+~0.5.4-1) ...\n",
            "Setting up node-iconv-lite (0.6.3-2) ...\n",
            "Setting up node-combined-stream (1.0.8+~1.0.3-1) ...\n",
            "Setting up node-unique-filename (1.1.1+ds-1) ...\n",
            "Setting up node-ansi-styles (4.3.0+~4.2.0-1) ...\n",
            "Setting up node-mime-types (2.1.33-1) ...\n",
            "Setting up node-lcov-parse (1.0.0+20170612git80d039574ed9-5) ...\n",
            "Setting up node-cssom (0.4.4-3) ...\n",
            "Setting up node-form-data (3.0.1-1) ...\n",
            "Setting up node-strip-ansi (6.0.1-1) ...\n",
            "Setting up node-chalk (4.1.2-1) ...\n",
            "Setting up node-spdx-expression-parse (3.0.1+~3.0.1-1) ...\n",
            "Setting up node-which (2.0.2+~cs1.3.2-2) ...\n",
            "Setting up nodejs-doc (12.22.9~dfsg-1ubuntu3.6) ...\n",
            "Setting up node-punycode (2.1.1-5) ...\n",
            "Setting up node-defaults (1.0.3+~1.0.3-1) ...\n",
            "Setting up node-is-typedarray (1.0.0-4) ...\n",
            "Setting up node-graceful-fs (4.2.4+repack-1) ...\n",
            "Setting up node-inflight (1.0.6-2) ...\n",
            "Setting up node-hosted-git-info (4.0.2-1) ...\n",
            "Setting up node-aproba (2.0.0-2) ...\n",
            "Setting up node-esprima (4.0.1+ds+~4.0.3-2) ...\n",
            "Setting up node-mkdirp (1.0.4+~1.0.2-1) ...\n",
            "Setting up node-run-queue (2.0.0-2) ...\n",
            "Setting up node-opener (1.5.2+~1.4.0-1) ...\n",
            "Setting up node-archy (1.0.0-4) ...\n",
            "Setting up node-encoding (0.1.13-2) ...\n",
            "Setting up node-js-yaml (4.1.0+dfsg+~4.0.5-6) ...\n",
            "Setting up node-nopt (5.0.0-2) ...\n",
            "Setting up node-slice-ansi (5.0.0+~cs9.0.0-4) ...\n",
            "Setting up node-ms (2.1.3+~cs0.7.31-2) ...\n",
            "Setting up node-semver (7.3.5+~7.3.8-1) ...\n",
            "Setting up node-fs-write-stream-atomic (1.0.10-5) ...\n",
            "Setting up node-builtins (4.0.0-1) ...\n",
            "Setting up node-colors (1.4.0-3) ...\n",
            "Setting up node-log-driver (1.2.7+git+20180219+bba1761737-7) ...\n",
            "Setting up node-ssri (8.0.1-2) ...\n",
            "Setting up node-object-assign (4.1.1-6) ...\n",
            "Setting up node-end-of-stream (1.4.4+~1.4.1-1) ...\n",
            "Setting up node-pump (3.0.0-5) ...\n",
            "Setting up node-psl (1.8.0+ds-6) ...\n",
            "Setting up node-stack-utils (2.0.5+~2.0.1-1) ...\n",
            "Setting up node-json-buffer (3.0.1-1) ...\n",
            "Setting up node-console-control-strings (1.1.0-2) ...\n",
            "Setting up node-debug (4.3.2+~cs4.1.7-1) ...\n",
            "Setting up node-events (3.3.0+~3.0.0-2) ...\n",
            "Setting up node-agent-base (6.0.2+~cs5.4.2-1) ...\n",
            "Setting up node-validate-npm-package-name (3.0.0-4) ...\n",
            "Setting up node-wcwidth.js (1.0.2-1) ...\n",
            "Setting up node-cssstyle (2.3.0-2) ...\n",
            "Setting up node-spdx-correct (3.1.1-2) ...\n",
            "Setting up node-glob (7.2.1+~cs7.6.15-1) ...\n",
            "Setting up node-get-stream (6.0.1-1) ...\n",
            "Setting up node-got (11.8.3+~cs58.7.37-1) ...\n",
            "Setting up node-typedarray-to-buffer (4.0.0-2) ...\n",
            "Setting up node-tap-parser (7.0.0+ds1-6) ...\n",
            "Setting up node-minipass (3.1.6+~cs8.7.18-1) ...\n",
            "Setting up node-tough-cookie (4.0.0-2) ...\n",
            "Setting up node-npm-package-arg (8.1.5-1) ...\n",
            "Setting up node-https-proxy-agent (5.0.0+~cs8.0.0-3) ...\n",
            "Setting up node-rimraf (3.0.2-1) ...\n",
            "Setting up node-string-width (4.2.3+~cs13.2.3-1) ...\n",
            "Setting up node-validate-npm-package-license (3.0.4-2) ...\n",
            "Setting up node-write-file-atomic (3.0.3+~3.0.2-1) ...\n",
            "Setting up node-columnify (1.5.4+~1.5.1-1) ...\n",
            "Setting up node-copy-concurrently (1.0.5-8) ...\n",
            "Setting up node-move-concurrently (1.0.1-4) ...\n",
            "Setting up node-tap-mocha-reporter (3.0.7+ds-2) ...\n",
            "Setting up node-normalize-package-data (3.0.3+~2.4.1-1) ...\n",
            "Setting up node-ws (8.5.0+~cs13.3.3-2) ...\n",
            "Setting up node-cli-table (0.3.11+~cs0.13.3-1) ...\n",
            "Setting up node-jsdom (19.0.0+~cs90.11.27-1) ...\n",
            "Setting up node-tar (6.1.11+ds1+~cs6.0.6-1) ...\n",
            "Setting up node-wide-align (1.1.3-4) ...\n",
            "Setting up node-tap (12.0.1+ds-4) ...\n",
            "Setting up node-cacache (15.0.5+~cs13.9.21-3) ...\n",
            "Setting up node-read-package-json (4.1.1-1) ...\n",
            "Setting up node-fetch (2.6.7+~2.5.12-1) ...\n",
            "Setting up node-gauge (4.0.2-1) ...\n",
            "Setting up node-npmlog (6.0.1+~4.1.4-1) ...\n",
            "Setting up node-coveralls (3.1.1-1) ...\n",
            "Setting up node-gyp (8.4.1-1) ...\n",
            "Setting up npm (8.5.1~ds-1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "Collecting yt-dlp\n",
            "  Downloading yt_dlp-2025.12.8-py3-none-any.whl.metadata (180 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.3/180.3 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yt_dlp-2025.12.8-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m94.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: yt-dlp\n",
            "Successfully installed yt-dlp-2025.12.8\n",
            "Collecting ffmpeg-python\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.12/dist-packages (from ffmpeg-python) (1.0.0)\n",
            "Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: ffmpeg-python\n",
            "Successfully installed ffmpeg-python-0.2.0\n",
            "Collecting silero-vad\n",
            "  Downloading silero_vad-6.2.0-py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting onnxruntime>=1.16.1 (from silero-vad)\n",
            "  Downloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from silero-vad) (25.0)\n",
            "Requirement already satisfied: torch>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from silero-vad) (2.5.1)\n",
            "Requirement already satisfied: torchaudio>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from silero-vad) (2.5.1)\n",
            "Collecting coloredlogs (from onnxruntime>=1.16.1->silero-vad)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.16.1->silero-vad) (25.12.19)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.16.1->silero-vad) (2.0.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.16.1->silero-vad) (4.25.8)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.16.1->silero-vad) (1.13.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->silero-vad) (3.20.2)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->silero-vad) (4.15.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->silero-vad) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->silero-vad) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->silero-vad) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->silero-vad) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->silero-vad) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->silero-vad) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->silero-vad) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->silero-vad) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->silero-vad) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->silero-vad) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->silero-vad) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->silero-vad) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->silero-vad) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->silero-vad) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->silero-vad) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->silero-vad) (3.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->silero-vad) (75.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.16.1->silero-vad) (1.3.0)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.16.1->silero-vad)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.12.0->silero-vad) (3.0.3)\n",
            "Downloading silero_vad-6.2.0-py3-none-any.whl (6.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m73.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m126.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: humanfriendly, coloredlogs, onnxruntime, silero-vad\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.23.2 silero-vad-6.2.0\n"
          ]
        }
      ],
      "source": [
        "!apt-get install -y nodejs npm\n",
        "!pip install -U yt-dlp\n",
        "!pip install -U ffmpeg-python\n",
        "!pip install silero-vad"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Procuring and Preparing Data"
      ],
      "metadata": {
        "id": "qKqJevSXm1-k"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryXznY3mQYq5"
      },
      "source": [
        "We download the highest-quality audio-only stream using yt-dlp to minimize file size and avoid unnecessary video processing. The audio is converted to 16 kHz mono PCM WAV using ffmpeg, as this matches the training conditions of Whisper and Silero VAD, leading to more stable transcription and timestamp alignment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "62gEawhNRDJG",
        "outputId": "6e395692-f3a3-4a8d-c42b-dfd72f319e54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=Sby1uJ_NFIY\n",
            "[youtube] Sby1uJ_NFIY: Downloading webpage\n",
            "\u001b[0;33mWARNING:\u001b[0m [youtube] No supported JavaScript runtime could be found. Only deno is enabled by default; to use another runtime add  --js-runtimes RUNTIME[:PATH]  to your command/config. YouTube extraction without a JS runtime has been deprecated, and some formats may be missing. See  https://github.com/yt-dlp/yt-dlp/wiki/EJS  for details on installing one\n",
            "[youtube] Sby1uJ_NFIY: Downloading android sdkless player API JSON\n",
            "[youtube] Sby1uJ_NFIY: Downloading web safari player API JSON\n",
            "\u001b[0;33mWARNING:\u001b[0m [youtube] Sby1uJ_NFIY: Some web_safari client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n",
            "[youtube] Sby1uJ_NFIY: Downloading m3u8 information\n",
            "\u001b[0;33mWARNING:\u001b[0m [youtube] Sby1uJ_NFIY: Some web client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n",
            "[info] Sby1uJ_NFIY: Downloading 1 format(s): 251-9\n",
            "[download] input_audio.webm has already been downloaded\n",
            "\u001b[K[download] 100% of   29.57MiB\n"
          ]
        }
      ],
      "source": [
        "!yt-dlp \\\n",
        "  -f bestaudio \\\n",
        "  -o \"input_audio.%(ext)s\" \\\n",
        "  \"https://www.youtube.com/watch?v=Sby1uJ_NFIY\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFqXjIu9TRGV"
      },
      "source": [
        "The audio stream downloaded from YouTube is encoded in Opus format at 48 kHz stereo. We convert it to a 16 kHz mono PCM WAV file using ffmpeg, as this matches the expected input format of Whisper-based ASR and voice activity detection models. This conversion ensures stable transcription quality and accurate timestamp alignment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "VuliXuNYRyNj",
        "outputId": "302753bb-5e45-47e7-ca69-9e8fe76fb5cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "Input #0, matroska,webm, from 'input_audio.webm':\n",
            "  Metadata:\n",
            "    encoder         : google/video-file\n",
            "  Duration: 00:26:15.08, start: -0.007000, bitrate: 157 kb/s\n",
            "  Stream #0:0(eng): Audio: opus, 48000 Hz, stereo, fltp (default)\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (opus (native) -> pcm_s16le (native))\n",
            "Press [q] to stop, [?] for help\n",
            "Output #0, wav, to 'input_audio.wav':\n",
            "  Metadata:\n",
            "    ISFT            : Lavf58.76.100\n",
            "  Stream #0:0(eng): Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s (default)\n",
            "    Metadata:\n",
            "      encoder         : Lavc58.134.100 pcm_s16le\n",
            "size=   49221kB time=00:26:15.06 bitrate= 256.0kbits/s speed= 207x    \n",
            "video:0kB audio:49220kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.000155%\n"
          ]
        }
      ],
      "source": [
        "!ffmpeg -y -i input_audio.webm -ac 1 -ar 16000 input_audio.wav"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchaudio\n",
        "\n",
        "AUDIO_PATH = \"input_audio.wav\"  # your extracted audio\n",
        "\n",
        "waveform, sample_rate = torchaudio.load(AUDIO_PATH)\n",
        "\n",
        "# Convert to mono if needed\n",
        "if waveform.shape[0] > 1:\n",
        "    waveform = waveform.mean(dim=0, keepdim=True)\n",
        "\n",
        "# Resample to 16 kHz if needed\n",
        "if sample_rate != 16000:\n",
        "    resampler = torchaudio.transforms.Resample(\n",
        "        orig_freq=sample_rate,\n",
        "        new_freq=16000\n",
        "    )\n",
        "    waveform = resampler(waveform)\n",
        "    sample_rate = 16000\n",
        "\n",
        "# Silero expects 1D tensor\n",
        "audio = waveform.squeeze()"
      ],
      "metadata": {
        "id": "aC5ue99YDPu5"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Identifying Candidates for Chunk Split"
      ],
      "metadata": {
        "id": "dkL9Hcx6m_Pq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Speaker diarization allows us to map chunks of audio to speakers. When we run this cell, we will need to use an HF token, as well as accept terms and provide some details to HF using the 2 links in the code below"
      ],
      "metadata": {
        "id": "mx0gFEXzNN09"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from getpass import getpass\n",
        "from pyannote.audio import Pipeline\n",
        "\n",
        "# 1. Configuration\n",
        "AUDIO_PATH = \"input_audio.wav\"\n",
        "\n",
        "# 2. Authentication\n",
        "# Note: Ensure you accepted terms at:\n",
        "# https://hf.co/pyannote/speaker-diarization-3.1\n",
        "# https://hf.co/pyannote/segmentation-3.0\n",
        "HF_TOKEN = getpass(\"Enter Hugging Face token: \").strip()\n",
        "\n",
        "# 3. Load Pipeline\n",
        "print(\"Loading pipeline...\")\n",
        "pipeline = Pipeline.from_pretrained(\n",
        "    \"pyannote/speaker-diarization-3.1\",\n",
        "    use_auth_token=HF_TOKEN\n",
        ")\n",
        "\n",
        "# 4. Enable CUDA (GPU)\n",
        "device = torch.device(\"cuda\")\n",
        "if pipeline is not None:\n",
        "    pipeline.to(device)\n",
        "    print(f\"Pipeline loaded and running on: {device}\")\n",
        "\n",
        "    # 5. Run Diarization\n",
        "    print(\"Processing audio (this may take a few minutes)...\")\n",
        "    diarization = pipeline(AUDIO_PATH)\n",
        "\n",
        "    # 6. Format and Print Results\n",
        "    diar_segments = []\n",
        "    for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
        "        diar_segments.append({\n",
        "            \"start\": round(float(turn.start)),\n",
        "            \"end\": round(float(turn.end)),\n",
        "            \"speaker\": speaker\n",
        "        })\n",
        "\n",
        "    # Sort and display\n",
        "    diar_segments.sort(key=lambda x: x[\"start\"])\n",
        "    print(f\"\\n✅ Done! Found {len(diar_segments)} segments.\")\n",
        "\n",
        "    # Print first 10 segments as a preview\n",
        "    for seg in diar_segments[:10]:\n",
        "        print(f\"[{seg['start']}s - {seg['end']}s] {seg['speaker']}\")\n",
        "else:\n",
        "    print(\"Error: Pipeline could not be loaded. Check your token/permissions.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "SuK-QU29thfm",
        "outputId": "29b98345-a587-446a-abc7-9814c9a27540"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter Hugging Face token: ··········\n",
            "Loading pipeline...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/lightning_fabric/utilities/cloud_io.py:73: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pipeline loaded and running on: cuda\n",
            "Processing audio (this may take a few minutes)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pyannote/audio/models/blocks/pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1823.)\n",
            "  std = sequences.std(dim=-1, correction=1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Done! Found 115 segments.\n",
            "[0s - 4s] SPEAKER_03\n",
            "[4s - 4s] SPEAKER_04\n",
            "[4s - 4s] SPEAKER_03\n",
            "[9s - 10s] SPEAKER_04\n",
            "[12s - 17s] SPEAKER_04\n",
            "[18s - 19s] SPEAKER_04\n",
            "[20s - 21s] SPEAKER_04\n",
            "[22s - 22s] SPEAKER_04\n",
            "[23s - 25s] SPEAKER_04\n",
            "[25s - 27s] SPEAKER_04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running silero vad to identify silences. Therefore, we won't have to run vad again during whisper transcription. The silero vad arguments have NOT been tweaked from their default values. As I explored some other minimum silence duration values, I realised tweaking it was not necessary."
      ],
      "metadata": {
        "id": "_GYcrXh2RFfz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from silero_vad import get_speech_timestamps, load_silero_vad\n",
        "\n",
        "# Load model\n",
        "vad_model = load_silero_vad()\n",
        "\n",
        "# Run VAD\n",
        "speech_timestamps = get_speech_timestamps(\n",
        "    audio,\n",
        "    vad_model,\n",
        "    sampling_rate=16000,\n",
        "    min_speech_duration_ms=300,\n",
        "    min_silence_duration_ms=100,\n",
        ")"
      ],
      "metadata": {
        "id": "l6DiDosHDwbT"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "speech_segments = [\n",
        "    {\n",
        "        \"start\": ts[\"start\"] / 16000,\n",
        "        \"end\": ts[\"end\"] / 16000,\n",
        "        \"duration\": (ts[\"end\"] - ts[\"start\"]) / 16000,\n",
        "    }\n",
        "    for ts in speech_timestamps\n",
        "]"
      ],
      "metadata": {
        "id": "7Db1mIpfDzrj"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "speech_segments = sorted(speech_segments, key=lambda x: x[\"start\"])"
      ],
      "metadata": {
        "id": "znF3wXkI1xN7"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a list of all silences detected by silero vad. We make sure that the minimum silence that is enforced is 100 milliseconds which coinicides with that given for vad."
      ],
      "metadata": {
        "id": "xTblbJxqRiDI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vad_silences = []\n",
        "\n",
        "MIN_SILENCE = 0.1  # seconds (100 ms)\n",
        "\n",
        "for i in range(len(speech_segments) - 1):\n",
        "    silence_start = speech_segments[i][\"end\"]\n",
        "    silence_end = speech_segments[i + 1][\"start\"]\n",
        "\n",
        "    silence_duration = silence_end - silence_start\n",
        "\n",
        "    if silence_duration >= MIN_SILENCE:\n",
        "        vad_silences.append({\n",
        "            \"start\": silence_start,\n",
        "            \"end\": silence_end,\n",
        "            \"duration\": silence_duration\n",
        "        })\n"
      ],
      "metadata": {
        "id": "_biaOM6M1yvI"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "faster-whisper allows us to run whisper but using a much more efficient CTranslate2 engine. It drastically speeds up inference without actually losing out on accuracy."
      ],
      "metadata": {
        "id": "hKHdIzUbSJjD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faster-whisper soundfile"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "l1ENk-GJGJ8Z",
        "outputId": "72471514-84ec-4274-ae2e-b34a2c4b8513"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faster-whisper in /usr/local/lib/python3.12/dist-packages (1.2.1)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.12/dist-packages (0.13.1)\n",
            "Requirement already satisfied: ctranslate2<5,>=4.0 in /usr/local/lib/python3.12/dist-packages (from faster-whisper) (4.6.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.21 in /usr/local/lib/python3.12/dist-packages (from faster-whisper) (0.36.0)\n",
            "Requirement already satisfied: tokenizers<1,>=0.13 in /usr/local/lib/python3.12/dist-packages (from faster-whisper) (0.22.2)\n",
            "Requirement already satisfied: onnxruntime<2,>=1.14 in /usr/local/lib/python3.12/dist-packages (from faster-whisper) (1.23.2)\n",
            "Requirement already satisfied: av>=11 in /usr/local/lib/python3.12/dist-packages (from faster-whisper) (16.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from faster-whisper) (4.67.1)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile) (2.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from soundfile) (2.0.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile) (2.23)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from ctranslate2<5,>=4.0->faster-whisper) (75.2.0)\n",
            "Requirement already satisfied: pyyaml<7,>=5.3 in /usr/local/lib/python3.12/dist-packages (from ctranslate2<5,>=4.0->faster-whisper) (6.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.21->faster-whisper) (3.20.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.21->faster-whisper) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.21->faster-whisper) (25.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.21->faster-whisper) (2.32.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.21->faster-whisper) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.21->faster-whisper) (1.2.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.12/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (25.12.19)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (4.25.8)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (1.13.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.12/dist-packages (from coloredlogs->onnxruntime<2,>=1.14->faster-whisper) (10.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.21->faster-whisper) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.21->faster-whisper) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.21->faster-whisper) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.21->faster-whisper) (2026.1.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime<2,>=1.14->faster-whisper) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from faster_whisper import WhisperModel\n",
        "\n",
        "model = WhisperModel(\n",
        "    \"large-v3\",\n",
        "    device=\"cuda\",        # \"cuda\" if available or \"cpu\"\n",
        "    compute_type=\"float16\"  # int8 for CPU, float16 for GPU\n",
        ")\n"
      ],
      "metadata": {
        "id": "tiBdsJlmGc0Z"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Embedder is required to find the embeddings of any given text. This is the best free one I could find."
      ],
      "metadata": {
        "id": "1qniLvvZScMO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "\n",
        "_embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "def embed(text: str) -> np.ndarray:\n",
        "    if not text.strip():\n",
        "        # handle empty text safely\n",
        "        return np.zeros(_embedder.get_sentence_embedding_dimension())\n",
        "    return _embedder.encode(text, normalize_embeddings=True)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ac3BYgya5GX_"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "segments, info = model.transcribe(\n",
        "    \"input_audio.wav\",               # path to your audio\n",
        "    beam_size=5,\n",
        "    word_timestamps=True,      # <-- THIS IS THE KEY\n",
        "    vad_filter=False           # you already ran your own VAD\n",
        ")"
      ],
      "metadata": {
        "id": "_4gR6eEzGpUt"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We start with words as our atomic blocks, retaining ALL information about every word including start, end and the speaker. The reason I worked with words was to get maximum control and finer granularity over where I can create the next chunk (chunking at arbitrary time points instead of whisper segment boundaries)."
      ],
      "metadata": {
        "id": "USJGHI23S07D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = []\n",
        "\n",
        "for seg in segments:\n",
        "    if seg.words is None:\n",
        "        continue\n",
        "\n",
        "    for w in seg.words:\n",
        "        # w.word already includes leading space sometimes → strip it\n",
        "        words.append({\n",
        "            \"start\": float(w.start),\n",
        "            \"end\": float(w.end),\n",
        "            \"text\": w.word.strip()\n",
        "        })\n"
      ],
      "metadata": {
        "id": "SdakkEum0eug"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These 2 functions enable word level diarization and speaker based chunk scoring. We only believe the diarization when there is at least 0.2 seconds of overlap between words and speaker."
      ],
      "metadata": {
        "id": "_DcOY-HWWSTx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "def assign_speakers_to_words(\n",
        "    words,\n",
        "    diar_segments,\n",
        "    default_speaker=\"UNK\",\n",
        "    min_overlap=0.2,      # seconds of overlap required to trust a label\n",
        "    max_snap=0.25          # seconds: if no overlap, snap to nearest segment if close\n",
        "):\n",
        "    \"\"\"\n",
        "    Assign speaker label to each word by maximizing overlap between:\n",
        "      word interval [w.start, w.end] and diarization segment [seg.start, seg.end].\n",
        "    Falls back to nearest segment if within max_snap.\n",
        "    \"\"\"\n",
        "    diar_segments = sorted(diar_segments, key=lambda x: x[\"start\"])\n",
        "\n",
        "    for w in words:\n",
        "        ws = float(w[\"start\"])\n",
        "        we = float(w[\"end\"])\n",
        "        if we <= ws:\n",
        "            w[\"speaker\"] = default_speaker\n",
        "            continue\n",
        "\n",
        "        best_spk = default_speaker\n",
        "        best_ov = 0.0\n",
        "\n",
        "        # 1) Max-overlap match\n",
        "        for seg in diar_segments:\n",
        "            ss = float(seg[\"start\"])\n",
        "            se = float(seg[\"end\"])\n",
        "            ov = max(0.0, min(we, se) - max(ws, ss))\n",
        "            if ov > best_ov:\n",
        "                best_ov = ov\n",
        "                best_spk = seg[\"speaker\"]\n",
        "\n",
        "        if best_ov >= min_overlap:\n",
        "            w[\"speaker\"] = best_spk\n",
        "            continue\n",
        "\n",
        "        # 2) No overlap: snap to nearest diar segment if close\n",
        "        mid = 0.5 * (ws + we)\n",
        "        nearest_spk = default_speaker\n",
        "        nearest_dist = float(\"inf\")\n",
        "        for seg in diar_segments:\n",
        "            ss = float(seg[\"start\"])\n",
        "            se = float(seg[\"end\"])\n",
        "            # distance from mid to segment (0 if inside)\n",
        "            dist = 0.0 if (ss <= mid <= se) else min(abs(mid - ss), abs(mid - se))\n",
        "            if dist < nearest_dist:\n",
        "                nearest_dist = dist\n",
        "                nearest_spk = seg[\"speaker\"]\n",
        "\n",
        "        w[\"speaker\"] = nearest_spk if nearest_dist <= max_snap else default_speaker\n",
        "\n",
        "    return words\n",
        "\n",
        "def speaker_stats_between(words, start, end, default_speaker=\"UNK\"):\n",
        "    spks = []\n",
        "    for w in words:\n",
        "        mid = 0.5 * (w[\"start\"] + w[\"end\"])\n",
        "        if start <= mid < end:\n",
        "            spks.append(w.get(\"speaker\", default_speaker))\n",
        "\n",
        "    if not spks:\n",
        "        return {\"dominant\": default_speaker, \"purity\": 0.0, \"counts\": Counter()}\n",
        "\n",
        "    counts = Counter(spks)\n",
        "    dominant, dom_n = counts.most_common(1)[0]\n",
        "    return {\"dominant\": dominant, \"purity\": dom_n / len(spks), \"counts\": counts}\n",
        "\n",
        "words = assign_speakers_to_words(words, diar_segments)\n",
        "print(\"First labeled words:\", words[:20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4juBhu6O6y_s",
        "outputId": "c8c562ca-d451-448c-efc3-0740f204ef57"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First labeled words: [{'start': 0.0, 'end': 0.44, 'text': 'Congratulations', 'speaker': 'SPEAKER_03'}, {'start': 0.44, 'end': 0.84, 'text': 'to', 'speaker': 'SPEAKER_03'}, {'start': 0.84, 'end': 0.96, 'text': 'you', 'speaker': 'SPEAKER_03'}, {'start': 0.96, 'end': 1.2, 'text': 'Mr.', 'speaker': 'SPEAKER_03'}, {'start': 1.22, 'end': 1.56, 'text': 'Raghavan', 'speaker': 'SPEAKER_03'}, {'start': 1.56, 'end': 1.74, 'text': 'for', 'speaker': 'SPEAKER_03'}, {'start': 1.74, 'end': 1.94, 'text': 'that.', 'speaker': 'SPEAKER_03'}, {'start': 2.08, 'end': 2.38, 'text': 'Thank', 'speaker': 'SPEAKER_03'}, {'start': 2.38, 'end': 2.48, 'text': 'you', 'speaker': 'SPEAKER_03'}, {'start': 2.48, 'end': 2.56, 'text': 'so', 'speaker': 'SPEAKER_03'}, {'start': 2.56, 'end': 2.76, 'text': 'much', 'speaker': 'SPEAKER_03'}, {'start': 2.76, 'end': 2.86, 'text': 'for', 'speaker': 'SPEAKER_03'}, {'start': 2.86, 'end': 3.1, 'text': 'joining', 'speaker': 'SPEAKER_03'}, {'start': 3.1, 'end': 3.36, 'text': 'us.', 'speaker': 'SPEAKER_03'}, {'start': 3.46, 'end': 3.84, 'text': 'Over', 'speaker': 'SPEAKER_03'}, {'start': 3.84, 'end': 3.96, 'text': 'to', 'speaker': 'SPEAKER_03'}, {'start': 3.96, 'end': 4.12, 'text': 'you.', 'speaker': 'SPEAKER_03'}, {'start': 8.240000000000002, 'end': 8.72, 'text': 'Hi', 'speaker': 'UNK'}, {'start': 8.72, 'end': 9.06, 'text': 'everybody.', 'speaker': 'SPEAKER_04'}, {'start': 9.32, 'end': 9.7, 'text': 'How', 'speaker': 'SPEAKER_04'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This checks whether or not speaker has changed based on a minimum timing gap and minimum amount of words on either side of speaker. Since we anyways have a minimum of 3 seconds of audio per chunk (I enforce this later on), we dont need to tamper with this at all. Any speaker will naturally speak at least 3-4 words in a duration of 3 seconds."
      ],
      "metadata": {
        "id": "ZalPXDiHXIV6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def speaker_change_candidates(\n",
        "    words,\n",
        "    segment,\n",
        "    ignore_speakers={\"UNK\"},\n",
        "    min_gap=0.2,          # seconds; optionally require a small timing gap\n",
        "    min_run_words=1       # require this many words on each side (reduces jitter)\n",
        "):\n",
        "    \"\"\"\n",
        "    Candidate cut times whenever the speaker label changes between adjacent words.\n",
        "    Returns times in seconds, inside (segment.start, segment.end).\n",
        "    \"\"\"\n",
        "    seg_start, seg_end = segment[\"start\"], segment[\"end\"]\n",
        "\n",
        "    # Select words that belong to this segment (midpoint assignment = stable at boundaries)\n",
        "    seg_words = []\n",
        "    for w in words:\n",
        "        mid = 0.5 * (float(w[\"start\"]) + float(w[\"end\"]))\n",
        "        if seg_start <= mid < seg_end:\n",
        "            seg_words.append(w)\n",
        "\n",
        "    if len(seg_words) < (2 * min_run_words + 1):\n",
        "        return []\n",
        "\n",
        "    cands = []\n",
        "    for i in range(min_run_words, len(seg_words) - min_run_words):\n",
        "        w1 = seg_words[i - 1]\n",
        "        w2 = seg_words[i]\n",
        "\n",
        "        spk1 = w1.get(\"speaker\", \"UNK\")\n",
        "        spk2 = w2.get(\"speaker\", \"UNK\")\n",
        "\n",
        "        if spk1 in ignore_speakers or spk2 in ignore_speakers:\n",
        "            continue\n",
        "        if spk1 == spk2:\n",
        "            continue\n",
        "\n",
        "        gap = float(w2[\"start\"]) - float(w1[\"end\"])\n",
        "        if gap < min_gap:\n",
        "            continue\n",
        "\n",
        "        # cut between words (midpoint between w1 end and w2 start is robust)\n",
        "        t = 0.5 * (float(w1[\"end\"]) + float(w2[\"start\"]))\n",
        "        if seg_start < t < seg_end:\n",
        "            cands.append(t)\n",
        "\n",
        "    # de-dup + sort\n",
        "    return sorted(set(round(t, 3) for t in cands))"
      ],
      "metadata": {
        "id": "uC3D3U43B3Od"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert all(words[i][\"start\"] <= words[i+1][\"start\"] for i in range(len(words)-1))\n"
      ],
      "metadata": {
        "id": "h42m0jwN0fM0"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_text = \" \".join(w[\"text\"] for w in words)"
      ],
      "metadata": {
        "id": "mbDLCmHt0tPH"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a list of mid points of any given silence detected by silero vad. It makes it eaiser to check whether a silence falls in one specific time interval or not."
      ],
      "metadata": {
        "id": "aMGOXDzlX3A9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vad_silence_times = [\n",
        "    0.5 * (s[\"start\"] + s[\"end\"])\n",
        "    for s in vad_silences\n",
        "]"
      ],
      "metadata": {
        "id": "kcYRw74s1ESl"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now check for *potential* points of split using VAD outputs, speaker changes and punctuation. This does not include semantics. We use semantics only to decide whether or not we actually want to use this potential point to split."
      ],
      "metadata": {
        "id": "pFRDt0uRY2jn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "FILLER_WORDS = {\n",
        "    \"um\", \"uh\", \"umm\", \"uhh\"\n",
        "}\n",
        "\n",
        "PUNCTUATION = {\".\", \",\", \"?\", \"!\", \"...\"}"
      ],
      "metadata": {
        "id": "I_KK9_wvtNJA"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def word_boundary_candidates(words, segment, min_gap=0.05):\n",
        "    \"\"\"\n",
        "    Returns candidate cut times based on linguistic + speaker cues.\n",
        "    Used ONLY when no VAD silence exists.\n",
        "    \"\"\"\n",
        "    candidates = []\n",
        "\n",
        "    seg_words = [\n",
        "        w for w in words\n",
        "        if segment[\"start\"] < w[\"start\"] < segment[\"end\"]\n",
        "    ]\n",
        "\n",
        "    for i in range(len(seg_words) - 1):\n",
        "        w1 = seg_words[i]\n",
        "        w2 = seg_words[i + 1]\n",
        "\n",
        "        gap = w2[\"start\"] - w1[\"end\"]\n",
        "\n",
        "        # Small acoustic gap (even < VAD threshold)\n",
        "        if gap >= min_gap:\n",
        "            candidates.append(0.5 * (w1[\"end\"] + w2[\"start\"]))\n",
        "\n",
        "        # Filler words\n",
        "        if w1[\"text\"].lower() in FILLER_WORDS:\n",
        "            candidates.append(w1[\"end\"])\n",
        "\n",
        "        # Punctuation cues\n",
        "        if any(p in w1[\"text\"] for p in PUNCTUATION):\n",
        "            candidates.append(w1[\"end\"])\n",
        "\n",
        "    # NEW: speaker-change cues\n",
        "    candidates += speaker_change_candidates(\n",
        "        words,\n",
        "        segment,\n",
        "        ignore_speakers={\"UNK\"},\n",
        "        min_gap=0.0, #create more potential avenues for chunking\n",
        "        min_run_words=1\n",
        "    )\n",
        "\n",
        "    return sorted(set(round(t, 3) for t in candidates))"
      ],
      "metadata": {
        "id": "oWo4AM8PtWk9"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These helper functions reconstruct transcript text from a word-level, time-aligned ASR output. They are designed for use in top-down semantic chunking pipelines, where audio is recursively split into non-overlapping time intervals and each word must belong to exactly one chunk."
      ],
      "metadata": {
        "id": "w3LxI8UFZxWp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def text_between(words, start, end):\n",
        "    # Assign each word to exactly one interval using midpoint-in-span.\n",
        "    span_words = []\n",
        "    for w in words:\n",
        "        mid = 0.5 * (w[\"start\"] + w[\"end\"])\n",
        "        if start <= mid < end:   # half-open to avoid boundary duplication\n",
        "            span_words.append(w[\"text\"])\n",
        "    return \" \".join(\" \".join(span_words).split())\n",
        "\n",
        "def text_for_chunks(words, chunk_list):\n",
        "    return \" \".join(\n",
        "        text_between(words, ch[\"start\"], ch[\"end\"])\n",
        "        for ch in chunk_list\n",
        "    ).strip()"
      ],
      "metadata": {
        "id": "qrkryesF5-Rx"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "def cosine_similarity(a, b):\n",
        "    \"\"\"\n",
        "    Compute cosine similarity between two vectors a and b.\n",
        "    Both a and b must be the same length.\n",
        "    \"\"\"\n",
        "    # Dot product\n",
        "    dot = sum(x * y for x, y in zip(a, b))\n",
        "    # Norms\n",
        "    norm_a = math.sqrt(sum(x * x for x in a))\n",
        "    norm_b = math.sqrt(sum(y * y for y in b))\n",
        "    if norm_a == 0 or norm_b == 0:\n",
        "        return 0.0\n",
        "    return dot / (norm_a * norm_b)"
      ],
      "metadata": {
        "id": "UqN9BFS_8WlD"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Semantic Scoring + Chunking**\n",
        "\n",
        "*   Candidate split scoring with semantic, balance, and speaker aware constraints.\n",
        "This function scores all viable candidate split points inside a given chunk and returns them ranked by quality. It is designed for top-down semantic chunking, where oversized chunks are recursively split until duration constraints are satisfied. As mentioned before, a candidate for a split is selected either via VAD, speaker change or text-based ruling (punctuation and filler words)\n",
        "*   Aside from just using semantic scores from neighbouring chunks, we also maintain a context window that helps retain context over larger durations.\n",
        "\n",
        "*   Apart from that, we also have a minimum of 3 seconds per chunk being enforced in any case.\n",
        "\n",
        "\n",
        "A good semantic boundary should satisfy these properties:\n",
        "\n",
        "\n",
        "1.   Local discontinuity: The text immediately to the left and right of the split should be semantically different.\n",
        "2.   Contextual discontinuity\n",
        "The surrounding context on the left and right should also differ, not just the immediate split regions.\n",
        "3. Internal coherence\n",
        "Each side of the split should be semantically consistent with its own broader context.\n",
        "This function explicitly scores all three.\n",
        "\n",
        "\n",
        "\n",
        "Additionally, I also add speaker diarization based rewards and penalties:\n",
        "\n",
        "  \n",
        "\n",
        "1.   Reward for splitting when speaker changes.\n",
        "2.   Penalty for interrupting or chunking when a speaker is explaining something uninterrupted.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "op4P_goR_UoM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2) Add guards so the splitter doesn’t create tiny slivers / very imbalanced halves.\n",
        "MIN_SIDE = 3.0          # seconds: disallow splits creating < 3s chunks\n",
        "BALANCE_LAMBDA = 0.25   # soft penalty weight; increase if you still see tiny chunks\n",
        "\n",
        "# Speaker-aware scoring knobs (tune these)\n",
        "SPEAKER_PURITY_MIN = 0.90   # require each side to be mostly one speaker\n",
        "SPEAKER_BONUS      = 1.00   # added when the split separates different speakers cleanly\n",
        "SPEAKER_PENALTY    = 0.35   # optional: subtract when both sides are confidently same speaker\n",
        "\n",
        "def imbalance_penalty(left_dur, right_dur):\n",
        "    total = left_dur + right_dur\n",
        "    if total <= 0:\n",
        "        return 0.0\n",
        "    return abs(left_dur - right_dur) / total  # 0 (balanced) .. ~1 (very imbalanced)\n",
        "\n",
        "\n",
        "# 3) Patch score_all_splits to apply the min-size constraint + penalty.\n",
        "def score_all_splits(\n",
        "    current_chunk,\n",
        "    all_chunks,\n",
        "    words,\n",
        "    silence_times,\n",
        "    embed,\n",
        "    left_context_size=1,\n",
        "    right_context_size=1,\n",
        "    include_speaker_candidates=True,\n",
        "    ignore_speakers={\"UNK\"},\n",
        "):\n",
        "    \"\"\"\n",
        "    Scores candidate cut times inside current_chunk.\n",
        "\n",
        "    Enhancements:\n",
        "      1) Optionally adds speaker-change times as additional candidates.\n",
        "      2) Adds a speaker-aware term to reward cuts that separate different dominant speakers.\n",
        "    \"\"\"\n",
        "    scored = []\n",
        "\n",
        "    # --- build candidate times ---\n",
        "    candidate_times = list(silence_times) if silence_times is not None else []\n",
        "\n",
        "    if include_speaker_candidates:\n",
        "        candidate_times += speaker_change_candidates(\n",
        "            words,\n",
        "            current_chunk,\n",
        "            ignore_speakers=ignore_speakers,\n",
        "            min_gap=0.0,\n",
        "            min_run_words=1,\n",
        "        )\n",
        "\n",
        "    # de-dup + sort\n",
        "    candidate_times = sorted(set(round(float(t), 3) for t in candidate_times))\n",
        "\n",
        "    # find index for context windows\n",
        "    try:\n",
        "        idx = all_chunks.index(current_chunk)\n",
        "    except ValueError:\n",
        "        idx = [\n",
        "            i for i, ch in enumerate(all_chunks)\n",
        "            if ch[\"start\"] == current_chunk[\"start\"] and ch[\"end\"] == current_chunk[\"end\"]\n",
        "        ][0]\n",
        "\n",
        "    for t in candidate_times:\n",
        "        if not (current_chunk[\"start\"] < t < current_chunk[\"end\"]):\n",
        "            continue\n",
        "\n",
        "        left_dur = t - current_chunk[\"start\"]\n",
        "        right_dur = current_chunk[\"end\"] - t\n",
        "\n",
        "        # hard constraint to prevent tiny chunks\n",
        "        if left_dur < MIN_SIDE or right_dur < MIN_SIDE:\n",
        "            continue\n",
        "\n",
        "        left_chunk  = {\"start\": current_chunk[\"start\"], \"end\": t}\n",
        "        right_chunk = {\"start\": t, \"end\": current_chunk[\"end\"]}\n",
        "\n",
        "        left_text  = text_between(words, left_chunk[\"start\"], left_chunk[\"end\"])\n",
        "        right_text = text_between(words, right_chunk[\"start\"], right_chunk[\"end\"])\n",
        "        if not left_text.strip() or not right_text.strip():\n",
        "            continue\n",
        "\n",
        "        # --- semantic score (your existing logic) ---\n",
        "        E_left  = embed(left_text)\n",
        "        E_right = embed(right_text)\n",
        "\n",
        "        left_neighbors = all_chunks[max(0, idx - left_context_size): idx]\n",
        "        extended_left = left_neighbors + [left_chunk]\n",
        "        ext_left_text = text_for_chunks(words, extended_left)\n",
        "        if not ext_left_text.strip():\n",
        "            continue\n",
        "        E_ext_left = embed(ext_left_text)\n",
        "\n",
        "        right_neighbors = all_chunks[idx + 1: idx + 1 + right_context_size]\n",
        "        extended_right = [right_chunk] + right_neighbors\n",
        "        ext_right_text = text_for_chunks(words, extended_right)\n",
        "        if not ext_right_text.strip():\n",
        "            continue\n",
        "        E_ext_right = embed(ext_right_text)\n",
        "\n",
        "        S_local = 1.0 - cosine_similarity(E_left, E_right)\n",
        "        S_ext   = 1.0 - cosine_similarity(E_ext_left, E_ext_right)\n",
        "        C_left  = cosine_similarity(E_left, E_ext_left)\n",
        "        C_right = cosine_similarity(E_right, E_ext_right)\n",
        "        C_int   = C_left + C_right\n",
        "\n",
        "        score = 1.0 * S_local + 0.5 * S_ext + 0.2 * C_int\n",
        "\n",
        "        # soft penalty for very uneven splits (your existing knob)\n",
        "        score -= BALANCE_LAMBDA * imbalance_penalty(left_dur, right_dur)\n",
        "\n",
        "        # --- NEW: speaker-aware term ---\n",
        "        sL = speaker_stats_between(words, left_chunk[\"start\"], left_chunk[\"end\"])\n",
        "        sR = speaker_stats_between(words, right_chunk[\"start\"], right_chunk[\"end\"])\n",
        "\n",
        "        domL, purL = sL[\"dominant\"], float(sL[\"purity\"])\n",
        "        domR, purR = sR[\"dominant\"], float(sR[\"purity\"])\n",
        "\n",
        "        if (domL not in ignore_speakers) and (domR not in ignore_speakers):\n",
        "            min_pur = min(purL, purR)\n",
        "\n",
        "            # reward clean separation into different dominant speakers\n",
        "            if (domL != domR) and (purL >= SPEAKER_PURITY_MIN) and (purR >= SPEAKER_PURITY_MIN):\n",
        "                score += SPEAKER_BONUS * min_pur\n",
        "\n",
        "            # optional: penalize cuts that *don’t* align with a speaker boundary\n",
        "            #if (domL == domR) and (purL >= SPEAKER_PURITY_MIN) and (purR >= SPEAKER_PURITY_MIN):\n",
        "                #score -= SPEAKER_PENALTY * min_pur\n",
        "\n",
        "        scored.append((t, score))\n",
        "\n",
        "    scored.sort(key=lambda x: x[1], reverse=True)\n",
        "    return scored\n"
      ],
      "metadata": {
        "id": "YxsPCZO72iLu"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is an auxilliary function that is used when there are no candidates for splitting from the VAD and speaker diarization alone."
      ],
      "metadata": {
        "id": "5dIPBjT0io3B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def best_fallback_split(segment, all_chunks, words, embed,\n",
        "                        left_context_size=1, right_context_size=1,\n",
        "                        ignore_speakers={\"UNK\"}):\n",
        "    \"\"\"\n",
        "    Fallback split: generate word/punctuation-based candidate times, then score them\n",
        "    using the same scoring function as the main path (score_all_splits).\n",
        "    \"\"\"\n",
        "    fallback_times = word_boundary_candidates(words, segment)\n",
        "    if not fallback_times:\n",
        "        return None\n",
        "\n",
        "    scored = score_all_splits(\n",
        "        current_chunk=segment,\n",
        "        all_chunks=all_chunks,\n",
        "        words=words,\n",
        "        silence_times=fallback_times,          # reuse the same parameter for candidate cut times\n",
        "        embed=embed,\n",
        "        left_context_size=left_context_size,\n",
        "        right_context_size=right_context_size,\n",
        "        include_speaker_candidates=False,      # IMPORTANT: word_boundary_candidates already adds these\n",
        "        ignore_speakers=ignore_speakers,\n",
        "    )\n",
        "\n",
        "    return float(scored[0][0]) if scored else None"
      ],
      "metadata": {
        "id": "SHn-PxvPubI4"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function actually calls the score_all_splits function and segments each chunk into smaller chunks. We then run this iteratively until we are sure that there are no more chunks >15 seconds left. We run this only on VAD and speaker based potential candidates first. If it doesnt work out (not enough silences or speaker changes in the right area), only then do we look for punctuation, etc. We call the auxilliary function - best_fallback_split for this."
      ],
      "metadata": {
        "id": "tRvkmgQ6hgYw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 15\n",
        "\n",
        "def run_segmentation(\n",
        "    words,\n",
        "    silence_times,\n",
        "    embed,\n",
        "    local_context=1,\n",
        "    right_context=1,\n",
        "    include_speaker_candidates=True,\n",
        "    ignore_speakers={\"UNK\"},\n",
        "):\n",
        "    \"\"\"\n",
        "    Enforces that all chunks in global `current_chunks` have duration <= MAX_LEN.\n",
        "\n",
        "    Change vs your current version:\n",
        "      - Builds per-segment candidate times (VAD silences within the segment)\n",
        "      - Optionally adds speaker-change times within the segment\n",
        "      - Passes the combined candidate list into score_all_splits\n",
        "        (and disables internal speaker-candidate addition to avoid double-counting)\n",
        "    \"\"\"\n",
        "    global current_chunks\n",
        "\n",
        "    i = 0\n",
        "    while i < len(current_chunks):\n",
        "        segment = current_chunks[i]\n",
        "        start, end = float(segment[\"start\"]), float(segment[\"end\"])\n",
        "        duration = end - start\n",
        "\n",
        "        # already valid\n",
        "        if duration <= MAX_LEN:\n",
        "            i += 1\n",
        "            continue\n",
        "\n",
        "        # if too short to split safely, skip\n",
        "        if duration < 2 * MIN_SIDE:\n",
        "            i += 1\n",
        "            continue\n",
        "\n",
        "        # --- build per-segment candidate times ---\n",
        "        seg_candidate_times = []\n",
        "\n",
        "        # VAD silence midpoints (restricted to this segment)\n",
        "        if silence_times is not None:\n",
        "            seg_candidate_times.extend(\n",
        "                float(t) for t in silence_times\n",
        "                if start < float(t) < end\n",
        "            )\n",
        "\n",
        "        # Speaker-change times (restricted by speaker_change_candidates itself)\n",
        "        if include_speaker_candidates:\n",
        "            seg_candidate_times.extend(\n",
        "                speaker_change_candidates(\n",
        "                    words,\n",
        "                    segment,\n",
        "                    ignore_speakers=ignore_speakers,\n",
        "                    min_gap=0.0,\n",
        "                    min_run_words=1,\n",
        "                )\n",
        "            )\n",
        "\n",
        "        # de-dup + sort\n",
        "        seg_candidate_times = sorted(set(round(float(t), 3) for t in seg_candidate_times))\n",
        "\n",
        "        # --- score splits using the combined candidates ---\n",
        "        scored = score_all_splits(\n",
        "            current_chunk=segment,\n",
        "            all_chunks=current_chunks,\n",
        "            words=words,\n",
        "            silence_times=seg_candidate_times,          # combined candidates\n",
        "            embed=embed,\n",
        "            left_context_size=local_context,\n",
        "            right_context_size=right_context,\n",
        "            include_speaker_candidates=False,           # IMPORTANT: avoid double-adding\n",
        "            ignore_speakers=ignore_speakers,\n",
        "        )\n",
        "\n",
        "        if scored:\n",
        "            cut_time = float(scored[0][0])\n",
        "        else:\n",
        "            # --- Fallback: word-based semantic split ---\n",
        "            cut_time = best_fallback_split(\n",
        "                segment,\n",
        "                all_chunks=current_chunks,\n",
        "                words=words,\n",
        "                embed=embed,\n",
        "                left_context_size=local_context,\n",
        "                right_context_size=right_context,\n",
        "            )\n",
        "\n",
        "        # --- absolute last resort ---\n",
        "        if cut_time is None or not (start < float(cut_time) < end):\n",
        "            cut_time = 0.5 * (start + end)\n",
        "\n",
        "        # clamp to respect MIN_SIDE\n",
        "        cut_time = float(cut_time)\n",
        "        cut_time = max(start + MIN_SIDE, min(cut_time, end - MIN_SIDE))\n",
        "\n",
        "        # if still cannot split (numerical edge), skip\n",
        "        if not (start + MIN_SIDE < cut_time < end - MIN_SIDE):\n",
        "            i += 1\n",
        "            continue\n",
        "\n",
        "        # --- split ---\n",
        "        left_chunk = {\"start\": start, \"end\": cut_time}\n",
        "        right_chunk = {\"start\": cut_time, \"end\": end}\n",
        "\n",
        "        # replace current chunk with two\n",
        "        current_chunks[i:i + 1] = [left_chunk, right_chunk]\n",
        "\n",
        "        # Do NOT increment i: re-check the new left chunk first"
      ],
      "metadata": {
        "id": "oiC59daW2lYU"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ...existing code...\n",
        "\n",
        "def preview_chunks(words, chunks):\n",
        "    for i, c in enumerate(sorted(chunks, key=lambda x: x[\"start\"])):\n",
        "        # speaker summary for this chunk\n",
        "        s = speaker_stats_between(words, c[\"start\"], c[\"end\"])\n",
        "        dom = s[\"dominant\"]\n",
        "        pur = float(s[\"purity\"])\n",
        "\n",
        "        text = text_between(words, c[\"start\"], c[\"end\"])\n",
        "        text = text.replace(\"\\n\", \" \").strip()\n",
        "\n",
        "        dur = c[\"end\"] - c[\"start\"]\n",
        "        print(f\"[{i:02d}] {c['start']:.2f}–{c['end']:.2f} ({dur:.2f}s) | speaker={dom} (purity={pur:.2f})\")\n",
        "        print(f\"     {text}\\n\")\n",
        "\n",
        "# ...existing code..."
      ],
      "metadata": {
        "id": "X9L7iJcH9-6j"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ...existing code...\n",
        "\n",
        "# 0) Ensure these already exist from earlier cells:\n",
        "# - words (list of dicts with start/end/text[/speaker])\n",
        "# - vad_silence_times (list[float])  OR pass None\n",
        "# - embed (function: str -> np.ndarray)\n",
        "# - run_segmentation, MIN_SIDE, MAX_LEN, score_all_splits, etc.\n",
        "\n",
        "# 1) Initialize the global chunk list (one big chunk, or any starting chunks you want)\n",
        "current_chunks = [{\"start\": 0.0, \"end\": float(words[-1][\"end\"])}]  # or your known end time (e.g., 1575.0)\n",
        "\n",
        "# 2) Run segmentation (this mutates current_chunks in-place)\n",
        "run_segmentation(\n",
        "    words=words,\n",
        "    silence_times=vad_silence_times,  # can be None if you want purely fallback/word-based\n",
        "    embed=embed,\n",
        "    local_context=5,\n",
        "    right_context=5,\n",
        "    include_speaker_candidates=True,\n",
        "    ignore_speakers={\"UNK\"},\n",
        ")\n",
        "\n",
        "# 3) Inspect results\n",
        "durations = [c[\"end\"] - c[\"start\"] for c in current_chunks]\n",
        "print(\"chunks:\", len(current_chunks), \"min:\", min(durations), \"max:\", max(durations))\n",
        "\n",
        "preview_chunks(words, current_chunks)\n",
        "# ...existing code..."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "sUQBOcqf6l__",
        "outputId": "701ca7e1-6471-4258-f28e-6c884725d93c"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chunks: 175 min: 3.088000000000079 max: 14.82400000000007\n",
            "[00] 0.00–6.54 (6.54s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     Congratulations to you Mr. Raghavan for that. Thank you so much for joining us. Over to you.\n",
            "\n",
            "[01] 6.54–11.15 (4.61s) | speaker=SPEAKER_04 (purity=0.80)\n",
            "     Hi everybody. How are you?\n",
            "\n",
            "[02] 11.15–24.93 (13.78s) | speaker=SPEAKER_04 (purity=0.97)\n",
            "     I am not hearing this at all. It's like a post lunch energy downer or something. Let's hear it. Are you guys awake? Alright. You better be because we\n",
            "\n",
            "[03] 24.93–33.07 (8.14s) | speaker=SPEAKER_04 (purity=1.00)\n",
            "     have a superstar guest here. You heard the $41 million and I didn't hear honestly anything she said after that.\n",
            "\n",
            "[04] 33.07–40.93 (7.86s) | speaker=SPEAKER_04 (purity=1.00)\n",
            "     So we are going to ask for about $40 million from him by the end of this conversation. But let's get started.\n",
            "\n",
            "[05] 40.93–52.85 (11.92s) | speaker=SPEAKER_04 (purity=1.00)\n",
            "     I want to introduce Vivek and Pratyush, his co -founder who is not here. We wanted to start with playing a video of what OpenHearty does. I encourage all of you to go to\n",
            "\n",
            "[06] 52.85–60.21 (7.36s) | speaker=SPEAKER_04 (purity=0.88)\n",
            "     the website serverum .ai and check it out. So let's get started. But let me start by introducing Vivek. Vivek is a dear friend and\n",
            "\n",
            "[07] 60.21–64.62 (4.42s) | speaker=SPEAKER_04 (purity=1.00)\n",
            "     he is very very modest. One of the most modest guys that I know. But\n",
            "\n",
            "[08] 64.62–75.31 (10.69s) | speaker=SPEAKER_04 (purity=1.00)\n",
            "     his personal journey Vivek, you got a PhD from Carnegie Mellon. You started and sold a company to Magma. And Vivek and I moved back to India from, we were both in the valley on\n",
            "\n",
            "[09] 75.31–82.48 (7.17s) | speaker=SPEAKER_04 (purity=1.00)\n",
            "     the same day actually. And you have been in India for the last 16 years. And what most people don't know is\n",
            "\n",
            "[10] 82.48–95.44 (12.96s) | speaker=SPEAKER_04 (purity=0.87)\n",
            "     your journey at Aadhaar. He spent 13 years. He was a selfless leader, selflessly at Aadhaar. Nobody would have heard of him. But he was a pioneering technology visionary behind Aadhaar\n",
            "\n",
            "[11] 95.44–107.50 (12.06s) | speaker=SPEAKER_04 (purity=1.00)\n",
            "     which we all take for granted today. So please give it out. So honestly when people, when I think of selfless service, truly selfless service, I always think of Vivek.\n",
            "\n",
            "[12] 107.50–112.61 (5.10s) | speaker=SPEAKER_04 (purity=1.00)\n",
            "     And since then he also was at AI for Bharat which we are going to touch on where\n",
            "\n",
            "[13] 112.61–126.32 (13.71s) | speaker=SPEAKER_04 (purity=1.00)\n",
            "     he met Pratyush's other co -founder. Pratyush had a PhD from ETH at Zurich, he was at IBM Research, he was at Microsoft Research playing a key role and a faculty at IIT Madras and at AI for Bharat.\n",
            "\n",
            "[14] 126.32–133.60 (7.28s) | speaker=SPEAKER_04 (purity=1.00)\n",
            "     So that's a little brief introduction about them. These guys are modest, modest engineers so they don't toot their own horn.\n",
            "\n",
            "[15] 133.60–140.11 (6.51s) | speaker=SPEAKER_04 (purity=1.00)\n",
            "     So forgive me for tooting their horn in this case. But let's jump right in about\n",
            "\n",
            "[16] 140.11–152.16 (12.05s) | speaker=SPEAKER_04 (purity=0.97)\n",
            "     the money, funding. 41 million bucks man. That's a lot of money, right? Every entrepreneur here is saying, what the hell did these guys do? What did the investors see to write such a big cheque?\n",
            "\n",
            "[17] 152.16–160.27 (8.11s) | speaker=SPEAKER_03 (purity=0.96)\n",
            "     I think it's a trend, a new trend of what's going on in India. I think that for the very first time, I\n",
            "\n",
            "[18] 160.27–172.16 (11.89s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     think the investors have looked at, you know, let's try and build something deep tech out of the country. And let's try to figure out how to build something as a foundational technology out of the country. And that's really what's really\n",
            "\n",
            "[19] 172.16–179.38 (7.22s) | speaker=SPEAKER_03 (purity=0.90)\n",
            "     exciting. And I think that about, you know, as Bala\n",
            "\n",
            "[20] 179.38–189.12 (9.74s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     was mentioning for the past 15 years, I've been kind of working in kind of, you know, both digital public infrastructure and kind of nonprofit\n",
            "\n",
            "[21] 189.12–199.81 (10.69s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     kind of things. But when this whole thing of generative AI came about, you know, we said, okay, how can I actually make a difference in this space? And I said, maybe\n",
            "\n",
            "[22] 199.81–209.60 (9.79s) | speaker=SPEAKER_03 (purity=0.89)\n",
            "     this is the opportunity to actually come out. And I think that's what's really exciting. And really build something, you know, and the only way that we realize that you can do it is actually in\n",
            "\n",
            "[23] 209.60–220.40 (10.80s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     the private sector. And I think that's, and then when we went out there and we said we want to build something which is a continuation, right? I mean, and fundamentally the question is,\n",
            "\n",
            "[24] 220.40–226.11 (5.71s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     the reason of what we want to do at Sarvam AI is we want to basically make generative AI available\n",
            "\n",
            "[25] 226.11–240.13 (14.02s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     and accessible to the people in the country. And that's the intent. And when we said that we want to do this. There was a resonance in the investment community. And I think it's a responsibility to really to show that\n",
            "\n",
            "[26] 240.13–246.37 (6.24s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     something like this can be built out of India. So we see that as confidence and a responsibility.\n",
            "\n",
            "[27] 246.37–256.18 (9.81s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     And I also hope it's a trend that, you know, that there are many more people like us who are backed. Because if you look at it, maybe it's a large number in a,\n",
            "\n",
            "[28] 256.18–265.19 (9.01s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     you know, in the Indian context. But in the global context, I think there is just, there should be many, many more entrepreneurs who are backed. To do things in India.\n",
            "\n",
            "[29] 265.19–274.90 (9.71s) | speaker=SPEAKER_04 (purity=1.00)\n",
            "     I'm going to come back to the many more entrepreneurs. I'm obviously going to ask you about Bhavesh's Krutrim. So we're going to come back to that question. But again,\n",
            "\n",
            "[30] 274.90–286.96 (12.06s) | speaker=SPEAKER_04 (purity=1.00)\n",
            "     $41 million. I mean, all of what you said, you know, $2 million, you know, that's a good amount of money for a startup which, you know, which has not yet built anything. What are you going to do with all this money?\n",
            "\n",
            "[31] 286.96–291.94 (4.98s) | speaker=SPEAKER_04 (purity=0.93)\n",
            "     I can solve the problem. I can have a perfect solution for the problem.\n",
            "\n",
            "[32] 291.94–302.29 (10.35s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     I think in the last week, I've got lots of calls from lots of people telling me how I can do it. I know you first, okay. I'll be landed in the country the same day. I'm in front of the queue.\n",
            "\n",
            "[33] 302.29–307.54 (5.25s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     No, but honestly, I think the key thing in this is to\n",
            "\n",
            "[34] 307.54–317.93 (10.39s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     putting together an amazing team. And we actually have an amazing team. But we believe that it is talent that will drive this kind of thing. And so it is to get key talent.\n",
            "\n",
            "[35] 317.93–330.56 (12.63s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     And of course, the other thing is compute. This is extremely expensive compute -wise to actually do these kinds of things. And I think that those are the two primary things that, you know, we would use this for.\n",
            "\n",
            "[36] 330.56–339.19 (8.63s) | speaker=SPEAKER_04 (purity=0.96)\n",
            "     Okay. I'm computing in my own head as an entrepreneur. Talent, okay, you have like 20, 15 people. How much are you paying these guys? But okay,\n",
            "\n",
            "[37] 339.19–349.07 (9.88s) | speaker=SPEAKER_04 (purity=0.94)\n",
            "     we won't touch on that. But let's talk about what you guys actually built. What is Open Hathi? How would you explain Open Hathi to many people here who might not have known about it? So\n",
            "\n",
            "[38] 349.07–356.19 (7.12s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     I think Open Hathi is, so first of all, right, we come from, I personally come from the open source ecosystem.\n",
            "\n",
            "[39] 356.19–368.74 (12.54s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     And also from the DPI ecosystem. So we believe that for this to work, we need the ecosystem to be successful. And as a result of that, one of the first things we did was, hey,\n",
            "\n",
            "[40] 368.74–383.46 (14.72s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     there are these open source large language models that exist, right? I mean, everybody knows about the Lama family from Meta. There are others like Mistral. There are a bunch of open source, you know, large language models. And\n",
            "\n",
            "[41] 383.46–397.39 (13.94s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     then we said, is there any way that take an existing open source model and teach it language skills, right? I mean, and that is really the, you know, what we decide, what we said that can we do something like that? And\n",
            "\n",
            "[42] 397.39–405.10 (7.71s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     is this a, you know, relatively frugal way of actually, you know, making models, you know,\n",
            "\n",
            "[43] 405.10–411.97 (6.86s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     work in diverse languages? Because the truth is still today. I mean, if you look at the amount of data\n",
            "\n",
            "[44] 411.97–418.43 (6.46s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     and knowledge, it is still English dominates these things. And I think that how do you actually take and make it\n",
            "\n",
            "[45] 418.43–429.73 (11.30s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     understand Indian language, understand Indian context, and all of those things in actually a, in an efficient way. And therefore, this was an attempt to do that. And Open Hathi is, you\n",
            "\n",
            "[46] 429.73–440.38 (10.66s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     know, is currently based on the Lama 7 billion model. But we'll be releasing many more models in different languages, different sizes. And things like that as part of this, as\n",
            "\n",
            "[47] 440.38–452.04 (11.66s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     part of this series. And of course, you know, we will be building further models on those and doing other things to actually, and we'll also have endpoints that people can use. So therefore, it's not, it's definitely, you know,\n",
            "\n",
            "[48] 452.04–455.98 (3.94s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     something that people can use to things. And\n",
            "\n",
            "[49] 455.98–460.09 (4.11s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     that's the essence of what this Open Hathi is.\n",
            "\n",
            "[50] 460.09–465.33 (5.24s) | speaker=SPEAKER_04 (purity=1.00)\n",
            "     So what does it mean to people in the audience here who are either doing their own startups or a business or\n",
            "\n",
            "[51] 465.33–469.96 (4.63s) | speaker=SPEAKER_04 (purity=1.00)\n",
            "     developers? How should they look at Open AI? Sorry,\n",
            "\n",
            "[52] 469.96–480.93 (10.97s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     start one. Not Open AI. No, yeah, no, no. I think the way you look at it is that we, one of the important things that we are doing is we're not just building models.\n",
            "\n",
            "[53] 480.93–487.84 (6.91s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     We are also going to be building a platform, a platform for developers where you can actually use a\n",
            "\n",
            "[54] 487.84–491.10 (3.26s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     combination of various different kinds of models. Some which\n",
            "\n",
            "[55] 491.10–499.58 (8.48s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     are from us, some which are open source, some which may not be open source. And actually to actually pull together and figure out. How to deploy, you know,\n",
            "\n",
            "[56] 499.58–510.75 (11.17s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     generative AI applications at scale and understand and evaluate their performance in an efficient manner. And that's something that we are planning to do. And this platform is, you\n",
            "\n",
            "[57] 510.75–518.64 (7.89s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     know, in the next couple of months will be coming out there. It will be available to developers. But of course, those who want to start with the open source things\n",
            "\n",
            "[58] 518.64–521.88 (3.24s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     and hack for that, of course, please go ahead and do that as well.\n",
            "\n",
            "[59] 521.88–527.41 (5.53s) | speaker=SPEAKER_04 (purity=1.00)\n",
            "     That's phenomenal. But how does it compare to Open AI itself? Or\n",
            "\n",
            "[60] 527.41–534.30 (6.90s) | speaker=SPEAKER_03 (purity=0.95)\n",
            "     Google? See, at least the things that we are doing now, right? I mean, one of the things that when\n",
            "\n",
            "[61] 534.30–548.46 (14.16s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     we thought about building Sarvam, we said we want to build a full stack generative AI company. And different people have, and our understanding of the stack is that we need to know how to train models from scratch. We\n",
            "\n",
            "[62] 548.46–556.56 (8.10s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     need to know how to kind of figure out how to deploy models to solve real world use cases. And we need to play in the ecosystem. To\n",
            "\n",
            "[63] 556.56–560.93 (4.37s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     make sure that we can actually deploy population scale\n",
            "\n",
            "[64] 560.93–565.15 (4.22s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     applications, right? So we were thinking about all of these things. But\n",
            "\n",
            "[65] 565.15–579.86 (14.71s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     still the models we were talking about are, you know, fairly small models. They are fairly small models, right? The seven to maybe up to 70 billion kind of range we're talking about. While these models like Open AI and Google are obviously much bigger models, right?\n",
            "\n",
            "[66] 579.86–591.20 (11.34s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     But we want to, you know, we want to understand the techniques and be able to build that muscle. To do all of these things. To make it available to people. Now those models are,\n",
            "\n",
            "[67] 591.20–599.28 (8.08s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     I mean, as I said, you know, I think that there is space for all of those things. And I think as even Sridhar was talking about\n",
            "\n",
            "[68] 599.28–609.07 (9.79s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     earlier in the day. We believe that these smaller models can do very, I mean, many, many kind of domain specific tasks extremely\n",
            "\n",
            "[69] 609.07–620.90 (11.82s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     well. Probably even better than the larger models. And that is really one of the key areas. And so therefore the value of these kinds of things, right? We are not aiming in these set of models to build\n",
            "\n",
            "[70] 620.90–629.31 (8.42s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     any AGI, right? That's not our goal here. Our goal is to make things that work extremely well for domain specific use cases. Or\n",
            "\n",
            "[71] 629.31–632.92 (3.61s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     increase accessibility through language and all of those kinds of\n",
            "\n",
            "[72] 632.92–647.74 (14.82s) | speaker=SPEAKER_04 (purity=0.98)\n",
            "     things. And obviously all of this unique to India. But what is unique about India? I mean, like what is, is there anything special in our ecosystem that makes small models focused with Indian language? Better for, more suited for our problems?\n",
            "\n",
            "[73] 647.74–660.21 (12.46s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     So I think that, I mean, there are quite a few things that are unique about India, right? The first thing is I think that we are a voice first nation. So therefore I think voice has to be the core\n",
            "\n",
            "[74] 660.21–664.70 (4.50s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     to doing things. The other thing, of course, India is\n",
            "\n",
            "[75] 664.70–674.59 (9.89s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     extremely, it's a cost conscious country from a cost perspective. Now there, I would say that there are lots of interesting use cases where you can use.\n",
            "\n",
            "[76] 674.59–685.04 (10.45s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     Open AI and the cost structure works that when, depending on your application. But when you want to scale things to a massive level and make it work. Then you have to figure out how small models work.\n",
            "\n",
            "[77] 685.04–693.07 (8.03s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     So that's something that is also specific to India. The third thing which is specific to India is really the success that India has had in\n",
            "\n",
            "[78] 693.07–698.66 (5.58s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     building all this digital public infrastructure. When you add the AI layer on top of it, then\n",
            "\n",
            "[79] 698.66–708.02 (9.36s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     you can actually get dramatic, you know, dramatic, I think, multiplicative. Combinatorial effects based on doing things like that. That's a\n",
            "\n",
            "[80] 708.02–712.13 (4.11s) | speaker=SPEAKER_04 (purity=1.00)\n",
            "     phenomenal point. Like, you know, it's like DPI to the power of AI almost in some ways. And\n",
            "\n",
            "[81] 712.13–725.97 (13.84s) | speaker=SPEAKER_04 (purity=0.97)\n",
            "     as a part of Aadhaar, building Aadhaar, no better person than you. So in summary, what I'm hearing is small models specialized with, trained with Indic specific language data. Suited for Indian problems at\n",
            "\n",
            "[82] 725.97–732.60 (6.63s) | speaker=SPEAKER_04 (purity=1.00)\n",
            "     a compelling cost point will be suited for us. We're not solving some world autonomous vehicles or some complex problem.\n",
            "\n",
            "[83] 732.60–741.01 (8.41s) | speaker=SPEAKER_04 (purity=1.00)\n",
            "     We're solving some basic problems specifically focused on voice with multiple languages. That is what you see as the future. Am I paraphrasing this correctly?\n",
            "\n",
            "[84] 741.01–749.01 (8.00s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     No, yeah. So I think that certainly, I mean, voice and Indian languages are an important part of our strategy. But we will be building, you\n",
            "\n",
            "[85] 749.01–760.72 (11.71s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     know, custom models to solve various other kinds of problems as well, right? It's not just limited to, I think, in different domains, working in different domains, making, building things based on unique\n",
            "\n",
            "[86] 760.72–767.47 (6.75s) | speaker=SPEAKER_03 (purity=0.70)\n",
            "     data that enterprises have. And things like that. So that's something that we'll also look at. Fair enough. So coming back to the\n",
            "\n",
            "[87] 767.47–774.27 (6.80s) | speaker=SPEAKER_04 (purity=1.00)\n",
            "     elephant in the room, no fun intended with open Hathi. What about Bhavesh Agarwal and Krutrim?\n",
            "\n",
            "[88] 774.27–778.34 (4.07s) | speaker=SPEAKER_03 (purity=0.76)\n",
            "     What is your take on that? I think it's great. I think it's wonderful, right? I mean,\n",
            "\n",
            "[89] 778.34–791.89 (13.55s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     the fact that the technology AI is so important that we need multiple people working on it. The fact that there are other people thinking is actually validates that this is an important problem to be solved. And\n",
            "\n",
            "[90] 791.89–806.45 (14.56s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     I think that we need everybody to come together and do that. So I really welcome that. I think it's great. And I think that there will be different people who will have different takes as to how to solve this kind of problem. And\n",
            "\n",
            "[91] 806.45–810.78 (4.34s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     hopefully as a result of that, the entire ecosystem benefits.\n",
            "\n",
            "[92] 810.78–817.01 (6.22s) | speaker=SPEAKER_04 (purity=0.95)\n",
            "     I have one more question and then I want to talk about some of the predictions that you've boldly made. So Vivek,\n",
            "\n",
            "[93] 817.01–830.19 (13.18s) | speaker=SPEAKER_04 (purity=1.00)\n",
            "     I usually ask people about what do you think the future will be and everybody usually hedges. I asked Vivek, what do you think is going to happen by December 2024? What do you think sitting in this room one year later we can expect? And he made three bold predictions.\n",
            "\n",
            "[94] 830.19–837.68 (7.49s) | speaker=SPEAKER_04 (purity=1.00)\n",
            "     So I want to talk about that. Before that, I have one last question. What are the top three applications that you think are relevant for India?\n",
            "\n",
            "[95] 837.68–845.20 (7.52s) | speaker=SPEAKER_04 (purity=1.00)\n",
            "     You heard Sridhar talk about medical. Quick summary, what do you think the top three apps are for India for AI? So\n",
            "\n",
            "[96] 845.20–858.10 (12.90s) | speaker=SPEAKER_03 (purity=0.94)\n",
            "     I mean, I think that, as you said, things like education and medical education. These are clearly areas where I think that things can be leveraged. The whole idea of all these kind of the\n",
            "\n",
            "[97] 858.10–864.58 (6.48s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     DPI aspect of it is another major application where things can happen. And here I'm talking about country specific work.\n",
            "\n",
            "[98] 864.58–879.04 (14.46s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     And I think the whole idea which Sridhar also talked about was the concept of software, right? And I think that and clearly we have a very large software industry and how to reimagine those things in this context is also something that's going to be.\n",
            "\n",
            "[99] 879.04–884.24 (5.20s) | speaker=SPEAKER_04 (purity=0.91)\n",
            "     Fair enough. Are you guys ready for Vivek Raghavan's bold predictions?\n",
            "\n",
            "[100] 884.24–896.90 (12.66s) | speaker=SPEAKER_04 (purity=0.98)\n",
            "     Yes? No? I'm not hearing any yes. This is like a big deal. He's like one of the smartest guys that I know. He wants to make three predictions. You don't want to hear it? All right. So I asked him, what do you think, you\n",
            "\n",
            "[101] 896.90–905.54 (8.64s) | speaker=SPEAKER_04 (purity=1.00)\n",
            "     know, a year later, what do you think we can expect? And he came up with three things. And usually people give very blah answers when you ask a question like this because they don't want to be caught wrong.\n",
            "\n",
            "[102] 905.54–913.41 (7.87s) | speaker=SPEAKER_04 (purity=1.00)\n",
            "     Not Vivek. Vivek is bold. So he basically said three things, and I'm going to list out the three things and then ask him about it.\n",
            "\n",
            "[103] 913.41–919.55 (6.14s) | speaker=SPEAKER_04 (purity=1.00)\n",
            "     So number one, he says, I would prefer to talk to an automated customer service than a real person because\n",
            "\n",
            "[104] 919.55–929.39 (9.84s) | speaker=SPEAKER_04 (purity=1.00)\n",
            "     they'll give me a better answer. So that is Vivek Raghavan's prediction, number one. So number two is that when everybody is talking about a GPU shortage,\n",
            "\n",
            "[105] 929.39–934.80 (5.41s) | speaker=SPEAKER_04 (purity=1.00)\n",
            "     Vivek predicts that there will be a GPU glut in India. He thinks there will be too much GPU. So\n",
            "\n",
            "[106] 934.80–937.89 (3.09s) | speaker=SPEAKER_04 (purity=1.00)\n",
            "     if you want a short NVIDIA stock, this is a good time.\n",
            "\n",
            "[107] 937.89–944.75 (6.86s) | speaker=SPEAKER_04 (purity=1.00)\n",
            "     And number three, which was extremely unexpected, he said some companies will suddenly die.\n",
            "\n",
            "[108] 944.75–956.94 (12.19s) | speaker=SPEAKER_04 (purity=0.95)\n",
            "     So, Vivek, these are not what I expected. So do you want to quickly talk about each of them, why you just came up with these, and then we'll throw the open to audience questions. Vivek Raghavan So I\n",
            "\n",
            "[109] 956.94–968.69 (11.75s) | speaker=SPEAKER_03 (purity=0.94)\n",
            "     don't think I quite said it the way that Bala is kind of saying it. Vivek Raghavan But it's interesting. But I think the first thing that we said is I think that,\n",
            "\n",
            "[110] 968.69–972.66 (3.97s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     and I don't think that this is, I think there will come a time when,\n",
            "\n",
            "[111] 972.66–984.99 (12.34s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     you know, in areas of customer service, etc., when you want to do something very specific. Today, you know, when you call some kind of a bot, you actually end up, you\n",
            "\n",
            "[112] 984.99–990.78 (5.79s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     mostly try to disconnect the call or, you know, you're extremely upset that you're talking to a bot.\n",
            "\n",
            "[113] 990.78–1001.44 (10.66s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     But I think that there will come a time, and I'm predicting it is sooner than later, that you will actually get better responses from the bot than what the human representative,\n",
            "\n",
            "[114] 1001.44–1005.86 (4.42s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     that at least the average human representative that you could talk to could give. And\n",
            "\n",
            "[115] 1005.86–1017.70 (11.84s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     I think that that's just a, so I just said that there will come a time where, you know, it's not a human you're talking to, but it's probably more likely to solve your intent than the human person.\n",
            "\n",
            "[116] 1017.70–1021.84 (4.14s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     That's just something that… That I think that\n",
            "\n",
            "[117] 1021.84–1028.30 (6.46s) | speaker=SPEAKER_04 (purity=0.87)\n",
            "     could happen. Okay, definitely controversial, but we'll let it go. What about the GPU glut?\n",
            "\n",
            "[118] 1028.30–1039.66 (11.36s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     No, no, yeah, so I don't think that, so I think that the fact that there is a tremendous shortage right now, I think that shortage will ease because that is how the cycles of things go, right?\n",
            "\n",
            "[119] 1039.66–1045.30 (5.64s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     When, you know, I think the fact that there was such a severe shortage last year, you know,\n",
            "\n",
            "[120] 1045.30–1059.80 (14.50s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     basically caused a number of different players to ramp up in various kinds of forms. And I think that that will always go in a cycle. But you may, we may find out that there are many, many more interesting problems that people will be able to solve.\n",
            "\n",
            "[121] 1059.80–1073.49 (13.69s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     I still remember, you know, we were at a GenAI event in Bangalore and we were talking to people and we said, you know, how many people have access to, you\n",
            "\n",
            "[122] 1073.49–1083.34 (9.85s) | speaker=SPEAKER_03 (purity=0.95)\n",
            "     know, 4 A100s, this was the question that I'd asked, and nobody in the room. And these are all extremely enthusiastic GenAI people. And nobody in the room. Nobody had access. And I think that thing is going to change.\n",
            "\n",
            "[123] 1083.34–1094.64 (11.30s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     You will be able to get these kinds of things. And people who want to hack and do things will have access to these things without, you know, having to write a, you know, a major check.\n",
            "\n",
            "[124] 1094.64–1101.14 (6.50s) | speaker=SPEAKER_04 (purity=1.00)\n",
            "     Vivek is also a semiconductor guy before he went into Aadhaar. So I would take his predictions very seriously. So I don't know what I,\n",
            "\n",
            "[125] 1101.14–1110.74 (9.60s) | speaker=SPEAKER_04 (purity=0.97)\n",
            "     I'm going to sell my media stock. I would not do that. But that's not what I said. I want to blame you for this if it goes up.\n",
            "\n",
            "[126] 1110.74–1118.76 (8.02s) | speaker=SPEAKER_04 (purity=1.00)\n",
            "     But the third one is pretty strange. You know, companies are born, companies die. But you said some companies will suddenly die. What does that mean?\n",
            "\n",
            "[127] 1118.76–1130.66 (11.90s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     No, I think, see, I think the interesting thing is, and I think that it comes back to the fundamental nature of AI. AI is a tool, right? And you have to use that. And\n",
            "\n",
            "[128] 1130.66–1138.56 (7.90s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     you have to use that within your business process. Right? And how AI is being used. And so, and what's going to happen is that,\n",
            "\n",
            "[129] 1138.56–1147.54 (8.98s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     I mean, I think this is true with, you know, when someone said in terms of, you know, people, they said that the people who leverage AI will\n",
            "\n",
            "[130] 1147.54–1157.38 (9.84s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     be more effective than those who don't leverage AI. And that is true for organizations also. Organizations that leverage AI in\n",
            "\n",
            "[131] 1157.38–1162.46 (5.09s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     fundamentally in their core business processes will be more effective than those who don't. Right?\n",
            "\n",
            "[132] 1162.46–1174.35 (11.89s) | speaker=SPEAKER_03 (purity=0.97)\n",
            "     And I think that's the thing. And you won't know the difference. Until one day it becomes too obvious. And it will be too late. And I think that's the reason why everybody needs to think about what\n",
            "\n",
            "[133] 1174.35–1177.68 (3.33s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     it means for your business. Because you\n",
            "\n",
            "[134] 1177.68–1191.10 (13.42s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     will, everything will be fine. Everything will be fine. And one day somebody in your, either your competitor in your space or somebody brand new coming into your space will be reimagining your business process completely. And\n",
            "\n",
            "[135] 1191.10–1200.99 (9.89s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     at that stage you will find that it's, you know, it's a very big, very tall thing. You know, a mountain to climb. And that's why I think it's important for\n",
            "\n",
            "[136] 1200.99–1211.08 (10.09s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     both people and entities to think about how they will, you know, they will upgrade themselves or they will modify their business processes. That's\n",
            "\n",
            "[137] 1211.08–1221.02 (9.94s) | speaker=SPEAKER_04 (purity=1.00)\n",
            "     a very nuanced answer. And everybody here who is running a business should really think about it. Because life will be the same. And then suddenly, suddenly something will, you know, then there will be a step change.\n",
            "\n",
            "[138] 1221.02–1232.88 (11.86s) | speaker=SPEAKER_04 (purity=1.00)\n",
            "     Vivek, I have a few more questions. But I'm sure the audience has a lot of questions for you. So how are we doing on time? Okay. So does, okay, a lot of questions. So love to,\n",
            "\n",
            "[139] 1232.88–1246.56 (13.68s) | speaker=SPEAKER_00 (purity=0.48)\n",
            "     is there a mic that we can pass around? Thank you. My name is Karthik. I work for IT service industry.\n",
            "\n",
            "[140] 1246.56–1260.91 (14.35s) | speaker=SPEAKER_00 (purity=1.00)\n",
            "     So you're saying that you're working on LLM, sorry, it's a fine tuned LLM on top of Lama. My basic question, fundamental question is we don't have a foundational model for India. Most of the models are basically\n",
            "\n",
            "[141] 1260.91–1273.94 (13.02s) | speaker=SPEAKER_00 (purity=0.97)\n",
            "     using English or those kind of things. For example, even Andrew was talking about the tokenizers and things like that. So are you working on anything like that? Or do you want to use mostly\n",
            "\n",
            "[142] 1273.94–1278.18 (4.24s) | speaker=SPEAKER_00 (purity=0.92)\n",
            "     the existing models and run on top of it? You asked a good\n",
            "\n",
            "[143] 1278.18–1286.62 (8.44s) | speaker=SPEAKER_03 (purity=0.62)\n",
            "     question. You asked a cherry question for himself. No, I think the interesting thing is that if you look at, you know, we have a website and then we have actually a blog on\n",
            "\n",
            "[144] 1286.62–1298.05 (11.43s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     this, on our website. I think one of the things that we've built is we've actually built a customized tokenizer which actually fundamentally changes the cost of some of these generations in Indian languages.\n",
            "\n",
            "[145] 1298.05–1310.08 (12.03s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     And I think that we're not just fine tuning. We're actually, we are leveraging the existing pre -training, but we are doing what's known as continual pre -training, which actually, but having said that, you know,\n",
            "\n",
            "[146] 1310.08–1319.22 (9.14s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     I think that when we have to figure out where is the data to train an extremely large model from scratch, and some of those things are things which will happen\n",
            "\n",
            "[147] 1319.22–1328.74 (9.52s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     over time. But I think that, yes, I think that we will be doing various kinds of things. But the interesting thing is that if\n",
            "\n",
            "[148] 1328.74–1341.02 (12.28s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     I want to change the accessibility problem with an existing open source model, how do I do that? And that's the problem that we have, that we think we have solved and is going to be the heart of this OpenAthi series. Extremely\n",
            "\n",
            "[149] 1341.02–1344.67 (3.65s) | speaker=SPEAKER_04 (purity=1.00)\n",
            "     well explained in the blog. Even I could understand it, so.\n",
            "\n",
            "[150] 1344.67–1355.71 (11.04s) | speaker=SPEAKER_02 (purity=1.00)\n",
            "     Hi, I'm Prashant. I work for a Fintech company. My question is like, unlike China, we never had a consumer facing application coming out from India and in\n",
            "\n",
            "[151] 1355.71–1363.42 (7.71s) | speaker=SPEAKER_02 (purity=1.00)\n",
            "     Web 1, Web 2, Crypto and all. Why do you think it will be different this time in like AI?\n",
            "\n",
            "[152] 1363.42–1377.84 (14.42s) | speaker=SPEAKER_02 (purity=1.00)\n",
            "     Because will the DPI and other things will serve the same purpose what the Great Firewall did in China? Or do you think like in, because AI is a strategic sector, no\n",
            "\n",
            "[153] 1377.84–1389.94 (12.10s) | speaker=SPEAKER_02 (purity=1.00)\n",
            "     outside country can work in NASA projects. Maybe all government contract will go to them. What exactly is the moat here for an Indian company?\n",
            "\n",
            "[154] 1389.94–1396.34 (6.40s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     So I don't, I think the question is, I\n",
            "\n",
            "[155] 1396.34–1404.75 (8.41s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     don't know the answer to these questions, right? I mean, and I think that it's difficult to predict. But I do believe, and as I'm repeating,\n",
            "\n",
            "[156] 1404.75–1418.10 (13.35s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     that the combinatorial effect of using Gen AI at a large scale in addition along with the DPI work that we've done in India will have people. And I think that in the end it is, the\n",
            "\n",
            "[157] 1418.10–1426.39 (8.29s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     intent is that people need to be able to use it and they will vote by things that are useful for them. And if that doesn't happen, you're right.\n",
            "\n",
            "[158] 1426.39–1437.00 (10.61s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     And I think that we have to figure out what is the mechanism of delivery of apps, right? I mean, how, where do Indians consume content? That's the question.\n",
            "\n",
            "[159] 1437.00–1440.85 (3.85s) | speaker=SPEAKER_04 (purity=1.00)\n",
            "     I'm so sorry, but we are out of time. Vivek will be outside. So\n",
            "\n",
            "[160] 1440.85–1446.86 (6.02s) | speaker=SPEAKER_04 (purity=0.70)\n",
            "     he would be able to answer the question. Do we have time for one last question? Can I just take one last? Yeah.\n",
            "\n",
            "[161] 1446.86–1453.26 (6.40s) | speaker=SPEAKER_01 (purity=1.00)\n",
            "     Thank you. Thank you. I'm Manish Kothari. I'm from ISBR Business School. Good that I got a chance to ask you this question.\n",
            "\n",
            "[162] 1453.26–1462.59 (9.33s) | speaker=SPEAKER_01 (purity=1.00)\n",
            "     During lunch time, there were a few of our educationists whom we were talking about and we were, there was one from school and we are from the MBA institutions. We were thinking of these\n",
            "\n",
            "[163] 1462.59–1467.20 (4.61s) | speaker=SPEAKER_01 (purity=1.00)\n",
            "     present generations. How do we get them into what you are doing?\n",
            "\n",
            "[164] 1467.20–1480.18 (12.98s) | speaker=SPEAKER_01 (purity=0.96)\n",
            "     There is one thing that they have been regularly that the concentrations that they are working on, but artificial intelligence and getting into this, getting them into their academics and making them a part of it is very important, including the trainers who train them.\n",
            "\n",
            "[165] 1480.18–1494.83 (14.66s) | speaker=SPEAKER_01 (purity=1.00)\n",
            "     Making them future ready into what you are doing is amazing. And the speed that with which it is growing, it is calling for a lot of training that needs to be done. Can you, from your angle, throw some light on how we could make them future ready? How\n",
            "\n",
            "[166] 1494.83–1500.53 (5.70s) | speaker=SPEAKER_01 (purity=1.00)\n",
            "     these people who are management graduates and from schools who are coming out, how\n",
            "\n",
            "[167] 1500.53–1504.29 (3.76s) | speaker=SPEAKER_01 (purity=1.00)\n",
            "     do we get into this part of technology that you spoke about?\n",
            "\n",
            "[168] 1504.29–1511.42 (7.14s) | speaker=SPEAKER_03 (purity=0.94)\n",
            "     So this is really a challenge because I think everyone will need to understand at some level what\n",
            "\n",
            "[169] 1511.42–1522.82 (11.39s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     this technology does. And I think that we have to rethink how we get everyone into this. And this kind of education has to be at many different levels, right? There are,\n",
            "\n",
            "[170] 1522.82–1534.56 (11.74s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     from a core set of having people who are extremely good at some, and there you don't need as many, but then there are basically vast numbers of people who can actually leverage these tools. By the way,\n",
            "\n",
            "[171] 1534.56–1540.83 (6.27s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     the most important thing about, and maybe that is part of what makes an LLM interesting, is that how you use it,\n",
            "\n",
            "[172] 1540.83–1550.50 (9.67s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     your mileage varies by that. And to understand how to actually leverage this in an interesting way, is something that we have to widely\n",
            "\n",
            "[173] 1550.50–1563.77 (13.27s) | speaker=SPEAKER_03 (purity=1.00)\n",
            "     teach many, many people. And because asking the things in the right way and having the right kind of applications will make a huge difference to how people can leverage these tools. Awesome. Thank you.\n",
            "\n",
            "[174] 1563.77–1574.60 (10.83s) | speaker=SPEAKER_04 (purity=0.85)\n",
            "     Thank you very much, Vivek. Very good luck to Sarvam and good luck to India. I think it's going to be a lot right on your shoulders. Thanks, Bala. Thank you, Mr. Raghavan.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final Output"
      ],
      "metadata": {
        "id": "lQ9ZUvNXoDGy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the assignment-required output format\n",
        "chunks_sorted = sorted(current_chunks, key=lambda c: float(c[\"start\"]))\n",
        "\n",
        "output_chunks = []\n",
        "for i, c in enumerate(chunks_sorted, start=1):\n",
        "    start = float(c[\"start\"])\n",
        "    end = float(c[\"end\"])\n",
        "    text = text_between(words, start, end).strip()\n",
        "\n",
        "    output_chunks.append({\n",
        "        \"chunk_id\": i,\n",
        "        \"chunk_length\": float(end - start),\n",
        "        \"text\": text,\n",
        "        \"start_time\": start,\n",
        "        \"end_time\": end,\n",
        "    })"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Kjv9UHihMal2"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(output_chunks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_H99e7YMhFM",
        "outputId": "350b051b-51c9-4426-8a29-f498185afed2"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'chunk_id': 1, 'chunk_length': 6.544, 'text': 'Congratulations to you Mr. Raghavan for that. Thank you so much for joining us. Over to you.', 'start_time': 0.0, 'end_time': 6.544}, {'chunk_id': 2, 'chunk_length': 4.608, 'text': 'Hi everybody. How are you?', 'start_time': 6.544, 'end_time': 11.152}, {'chunk_id': 3, 'chunk_length': 13.776000000000002, 'text': \"I am not hearing this at all. It's like a post lunch energy downer or something. Let's hear it. Are you guys awake? Alright. You better be because we\", 'start_time': 11.152, 'end_time': 24.928}, {'chunk_id': 4, 'chunk_length': 8.144000000000002, 'text': \"have a superstar guest here. You heard the $41 million and I didn't hear honestly anything she said after that.\", 'start_time': 24.928, 'end_time': 33.072}, {'chunk_id': 5, 'chunk_length': 7.8559999999999945, 'text': \"So we are going to ask for about $40 million from him by the end of this conversation. But let's get started.\", 'start_time': 33.072, 'end_time': 40.928}, {'chunk_id': 6, 'chunk_length': 11.920000000000002, 'text': 'I want to introduce Vivek and Pratyush, his co -founder who is not here. We wanted to start with playing a video of what OpenHearty does. I encourage all of you to go to', 'start_time': 40.928, 'end_time': 52.848}, {'chunk_id': 7, 'chunk_length': 7.359999999999999, 'text': \"the website serverum .ai and check it out. So let's get started. But let me start by introducing Vivek. Vivek is a dear friend and\", 'start_time': 52.848, 'end_time': 60.208}, {'chunk_id': 8, 'chunk_length': 4.415999999999997, 'text': 'he is very very modest. One of the most modest guys that I know. But', 'start_time': 60.208, 'end_time': 64.624}, {'chunk_id': 9, 'chunk_length': 10.688000000000002, 'text': 'his personal journey Vivek, you got a PhD from Carnegie Mellon. You started and sold a company to Magma. And Vivek and I moved back to India from, we were both in the valley on', 'start_time': 64.624, 'end_time': 75.312}, {'chunk_id': 10, 'chunk_length': 7.168000000000006, 'text': \"the same day actually. And you have been in India for the last 16 years. And what most people don't know is\", 'start_time': 75.312, 'end_time': 82.48}, {'chunk_id': 11, 'chunk_length': 12.959999999999994, 'text': 'your journey at Aadhaar. He spent 13 years. He was a selfless leader, selflessly at Aadhaar. Nobody would have heard of him. But he was a pioneering technology visionary behind Aadhaar', 'start_time': 82.48, 'end_time': 95.44}, {'chunk_id': 12, 'chunk_length': 12.064000000000007, 'text': 'which we all take for granted today. So please give it out. So honestly when people, when I think of selfless service, truly selfless service, I always think of Vivek.', 'start_time': 95.44, 'end_time': 107.504}, {'chunk_id': 13, 'chunk_length': 5.103999999999999, 'text': 'And since then he also was at AI for Bharat which we are going to touch on where', 'start_time': 107.504, 'end_time': 112.608}, {'chunk_id': 14, 'chunk_length': 13.711999999999989, 'text': \"he met Pratyush's other co -founder. Pratyush had a PhD from ETH at Zurich, he was at IBM Research, he was at Microsoft Research playing a key role and a faculty at IIT Madras and at AI for Bharat.\", 'start_time': 112.608, 'end_time': 126.32}, {'chunk_id': 15, 'chunk_length': 7.280000000000001, 'text': \"So that's a little brief introduction about them. These guys are modest, modest engineers so they don't toot their own horn.\", 'start_time': 126.32, 'end_time': 133.6}, {'chunk_id': 16, 'chunk_length': 6.5120000000000005, 'text': \"So forgive me for tooting their horn in this case. But let's jump right in about\", 'start_time': 133.6, 'end_time': 140.112}, {'chunk_id': 17, 'chunk_length': 12.048000000000002, 'text': \"the money, funding. 41 million bucks man. That's a lot of money, right? Every entrepreneur here is saying, what the hell did these guys do? What did the investors see to write such a big cheque?\", 'start_time': 140.112, 'end_time': 152.16}, {'chunk_id': 18, 'chunk_length': 8.111999999999995, 'text': \"I think it's a trend, a new trend of what's going on in India. I think that for the very first time, I\", 'start_time': 152.16, 'end_time': 160.272}, {'chunk_id': 19, 'chunk_length': 11.888000000000005, 'text': \"think the investors have looked at, you know, let's try and build something deep tech out of the country. And let's try to figure out how to build something as a foundational technology out of the country. And that's really what's really\", 'start_time': 160.272, 'end_time': 172.16}, {'chunk_id': 20, 'chunk_length': 7.216000000000008, 'text': 'exciting. And I think that about, you know, as Bala', 'start_time': 172.16, 'end_time': 179.376}, {'chunk_id': 21, 'chunk_length': 9.744, 'text': \"was mentioning for the past 15 years, I've been kind of working in kind of, you know, both digital public infrastructure and kind of nonprofit\", 'start_time': 179.376, 'end_time': 189.12}, {'chunk_id': 22, 'chunk_length': 10.687999999999988, 'text': 'kind of things. But when this whole thing of generative AI came about, you know, we said, okay, how can I actually make a difference in this space? And I said, maybe', 'start_time': 189.12, 'end_time': 199.808}, {'chunk_id': 23, 'chunk_length': 9.792000000000002, 'text': \"this is the opportunity to actually come out. And I think that's what's really exciting. And really build something, you know, and the only way that we realize that you can do it is actually in\", 'start_time': 199.808, 'end_time': 209.6}, {'chunk_id': 24, 'chunk_length': 10.800000000000011, 'text': \"the private sector. And I think that's, and then when we went out there and we said we want to build something which is a continuation, right? I mean, and fundamentally the question is,\", 'start_time': 209.6, 'end_time': 220.4}, {'chunk_id': 25, 'chunk_length': 5.711999999999989, 'text': 'the reason of what we want to do at Sarvam AI is we want to basically make generative AI available', 'start_time': 220.4, 'end_time': 226.112}, {'chunk_id': 26, 'chunk_length': 14.015999999999991, 'text': \"and accessible to the people in the country. And that's the intent. And when we said that we want to do this. There was a resonance in the investment community. And I think it's a responsibility to really to show that\", 'start_time': 226.112, 'end_time': 240.128}, {'chunk_id': 27, 'chunk_length': 6.242000000000019, 'text': 'something like this can be built out of India. So we see that as confidence and a responsibility.', 'start_time': 240.128, 'end_time': 246.37}, {'chunk_id': 28, 'chunk_length': 9.805999999999983, 'text': \"And I also hope it's a trend that, you know, that there are many more people like us who are backed. Because if you look at it, maybe it's a large number in a,\", 'start_time': 246.37, 'end_time': 256.176}, {'chunk_id': 29, 'chunk_length': 9.01400000000001, 'text': 'you know, in the Indian context. But in the global context, I think there is just, there should be many, many more entrepreneurs who are backed. To do things in India.', 'start_time': 256.176, 'end_time': 265.19}, {'chunk_id': 30, 'chunk_length': 9.706000000000017, 'text': \"I'm going to come back to the many more entrepreneurs. I'm obviously going to ask you about Bhavesh's Krutrim. So we're going to come back to that question. But again,\", 'start_time': 265.19, 'end_time': 274.896}, {'chunk_id': 31, 'chunk_length': 12.063999999999965, 'text': \"$41 million. I mean, all of what you said, you know, $2 million, you know, that's a good amount of money for a startup which, you know, which has not yet built anything. What are you going to do with all this money?\", 'start_time': 274.896, 'end_time': 286.96}, {'chunk_id': 32, 'chunk_length': 4.980000000000018, 'text': 'I can solve the problem. I can have a perfect solution for the problem.', 'start_time': 286.96, 'end_time': 291.94}, {'chunk_id': 33, 'chunk_length': 10.348000000000013, 'text': \"I think in the last week, I've got lots of calls from lots of people telling me how I can do it. I know you first, okay. I'll be landed in the country the same day. I'm in front of the queue.\", 'start_time': 291.94, 'end_time': 302.288}, {'chunk_id': 34, 'chunk_length': 5.2479999999999905, 'text': 'No, but honestly, I think the key thing in this is to', 'start_time': 302.288, 'end_time': 307.536}, {'chunk_id': 35, 'chunk_length': 10.394000000000005, 'text': 'putting together an amazing team. And we actually have an amazing team. But we believe that it is talent that will drive this kind of thing. And so it is to get key talent.', 'start_time': 307.536, 'end_time': 317.93}, {'chunk_id': 36, 'chunk_length': 12.629999999999995, 'text': 'And of course, the other thing is compute. This is extremely expensive compute -wise to actually do these kinds of things. And I think that those are the two primary things that, you know, we would use this for.', 'start_time': 317.93, 'end_time': 330.56}, {'chunk_id': 37, 'chunk_length': 8.629999999999995, 'text': \"Okay. I'm computing in my own head as an entrepreneur. Talent, okay, you have like 20, 15 people. How much are you paying these guys? But okay,\", 'start_time': 330.56, 'end_time': 339.19}, {'chunk_id': 38, 'chunk_length': 9.882000000000005, 'text': \"we won't touch on that. But let's talk about what you guys actually built. What is Open Hathi? How would you explain Open Hathi to many people here who might not have known about it? So\", 'start_time': 339.19, 'end_time': 349.072}, {'chunk_id': 39, 'chunk_length': 7.1200000000000045, 'text': 'I think Open Hathi is, so first of all, right, we come from, I personally come from the open source ecosystem.', 'start_time': 349.072, 'end_time': 356.192}, {'chunk_id': 40, 'chunk_length': 12.543999999999983, 'text': 'And also from the DPI ecosystem. So we believe that for this to work, we need the ecosystem to be successful. And as a result of that, one of the first things we did was, hey,', 'start_time': 356.192, 'end_time': 368.736}, {'chunk_id': 41, 'chunk_length': 14.720000000000027, 'text': 'there are these open source large language models that exist, right? I mean, everybody knows about the Lama family from Meta. There are others like Mistral. There are a bunch of open source, you know, large language models. And', 'start_time': 368.736, 'end_time': 383.456}, {'chunk_id': 42, 'chunk_length': 13.935999999999979, 'text': 'then we said, is there any way that take an existing open source model and teach it language skills, right? I mean, and that is really the, you know, what we decide, what we said that can we do something like that? And', 'start_time': 383.456, 'end_time': 397.392}, {'chunk_id': 43, 'chunk_length': 7.711999999999989, 'text': 'is this a, you know, relatively frugal way of actually, you know, making models, you know,', 'start_time': 397.392, 'end_time': 405.104}, {'chunk_id': 44, 'chunk_length': 6.864000000000033, 'text': 'work in diverse languages? Because the truth is still today. I mean, if you look at the amount of data', 'start_time': 405.104, 'end_time': 411.968}, {'chunk_id': 45, 'chunk_length': 6.463999999999999, 'text': 'and knowledge, it is still English dominates these things. And I think that how do you actually take and make it', 'start_time': 411.968, 'end_time': 418.432}, {'chunk_id': 46, 'chunk_length': 11.295999999999992, 'text': 'understand Indian language, understand Indian context, and all of those things in actually a, in an efficient way. And therefore, this was an attempt to do that. And Open Hathi is, you', 'start_time': 418.432, 'end_time': 429.728}, {'chunk_id': 47, 'chunk_length': 10.656000000000006, 'text': \"know, is currently based on the Lama 7 billion model. But we'll be releasing many more models in different languages, different sizes. And things like that as part of this, as\", 'start_time': 429.728, 'end_time': 440.384}, {'chunk_id': 48, 'chunk_length': 11.656000000000006, 'text': \"part of this series. And of course, you know, we will be building further models on those and doing other things to actually, and we'll also have endpoints that people can use. So therefore, it's not, it's definitely, you know,\", 'start_time': 440.384, 'end_time': 452.04}, {'chunk_id': 49, 'chunk_length': 3.94399999999996, 'text': 'something that people can use to things. And', 'start_time': 452.04, 'end_time': 455.984}, {'chunk_id': 50, 'chunk_length': 4.1059999999999945, 'text': \"that's the essence of what this Open Hathi is.\", 'start_time': 455.984, 'end_time': 460.09}, {'chunk_id': 51, 'chunk_length': 5.2379999999999995, 'text': 'So what does it mean to people in the audience here who are either doing their own startups or a business or', 'start_time': 460.09, 'end_time': 465.328}, {'chunk_id': 52, 'chunk_length': 4.632000000000005, 'text': 'developers? How should they look at Open AI? Sorry,', 'start_time': 465.328, 'end_time': 469.96}, {'chunk_id': 53, 'chunk_length': 10.968000000000018, 'text': \"start one. Not Open AI. No, yeah, no, no. I think the way you look at it is that we, one of the important things that we are doing is we're not just building models.\", 'start_time': 469.96, 'end_time': 480.928}, {'chunk_id': 54, 'chunk_length': 6.911999999999978, 'text': 'We are also going to be building a platform, a platform for developers where you can actually use a', 'start_time': 480.928, 'end_time': 487.84}, {'chunk_id': 55, 'chunk_length': 3.26400000000001, 'text': 'combination of various different kinds of models. Some which', 'start_time': 487.84, 'end_time': 491.104}, {'chunk_id': 56, 'chunk_length': 8.475999999999999, 'text': 'are from us, some which are open source, some which may not be open source. And actually to actually pull together and figure out. How to deploy, you know,', 'start_time': 491.104, 'end_time': 499.58}, {'chunk_id': 57, 'chunk_length': 11.172000000000025, 'text': \"generative AI applications at scale and understand and evaluate their performance in an efficient manner. And that's something that we are planning to do. And this platform is, you\", 'start_time': 499.58, 'end_time': 510.752}, {'chunk_id': 58, 'chunk_length': 7.887999999999977, 'text': 'know, in the next couple of months will be coming out there. It will be available to developers. But of course, those who want to start with the open source things', 'start_time': 510.752, 'end_time': 518.64}, {'chunk_id': 59, 'chunk_length': 3.240000000000009, 'text': 'and hack for that, of course, please go ahead and do that as well.', 'start_time': 518.64, 'end_time': 521.88}, {'chunk_id': 60, 'chunk_length': 5.52800000000002, 'text': \"That's phenomenal. But how does it compare to Open AI itself? Or\", 'start_time': 521.88, 'end_time': 527.408}, {'chunk_id': 61, 'chunk_length': 6.895999999999958, 'text': 'Google? See, at least the things that we are doing now, right? I mean, one of the things that when', 'start_time': 527.408, 'end_time': 534.304}, {'chunk_id': 62, 'chunk_length': 14.160000000000082, 'text': 'we thought about building Sarvam, we said we want to build a full stack generative AI company. And different people have, and our understanding of the stack is that we need to know how to train models from scratch. We', 'start_time': 534.304, 'end_time': 548.464}, {'chunk_id': 63, 'chunk_length': 8.09599999999989, 'text': 'need to know how to kind of figure out how to deploy models to solve real world use cases. And we need to play in the ecosystem. To', 'start_time': 548.464, 'end_time': 556.56}, {'chunk_id': 64, 'chunk_length': 4.368000000000052, 'text': 'make sure that we can actually deploy population scale', 'start_time': 556.56, 'end_time': 560.928}, {'chunk_id': 65, 'chunk_length': 4.224000000000046, 'text': 'applications, right? So we were thinking about all of these things. But', 'start_time': 560.928, 'end_time': 565.152}, {'chunk_id': 66, 'chunk_length': 14.70799999999997, 'text': \"still the models we were talking about are, you know, fairly small models. They are fairly small models, right? The seven to maybe up to 70 billion kind of range we're talking about. While these models like Open AI and Google are obviously much bigger models, right?\", 'start_time': 565.152, 'end_time': 579.86}, {'chunk_id': 67, 'chunk_length': 11.340000000000032, 'text': 'But we want to, you know, we want to understand the techniques and be able to build that muscle. To do all of these things. To make it available to people. Now those models are,', 'start_time': 579.86, 'end_time': 591.2}, {'chunk_id': 68, 'chunk_length': 8.079999999999927, 'text': 'I mean, as I said, you know, I think that there is space for all of those things. And I think as even Sridhar was talking about', 'start_time': 591.2, 'end_time': 599.28}, {'chunk_id': 69, 'chunk_length': 9.79200000000003, 'text': 'earlier in the day. We believe that these smaller models can do very, I mean, many, many kind of domain specific tasks extremely', 'start_time': 599.28, 'end_time': 609.072}, {'chunk_id': 70, 'chunk_length': 11.823999999999955, 'text': 'well. Probably even better than the larger models. And that is really one of the key areas. And so therefore the value of these kinds of things, right? We are not aiming in these set of models to build', 'start_time': 609.072, 'end_time': 620.896}, {'chunk_id': 71, 'chunk_length': 8.416000000000054, 'text': \"any AGI, right? That's not our goal here. Our goal is to make things that work extremely well for domain specific use cases. Or\", 'start_time': 620.896, 'end_time': 629.312}, {'chunk_id': 72, 'chunk_length': 3.6079999999999472, 'text': 'increase accessibility through language and all of those kinds of', 'start_time': 629.312, 'end_time': 632.92}, {'chunk_id': 73, 'chunk_length': 14.82400000000007, 'text': 'things. And obviously all of this unique to India. But what is unique about India? I mean, like what is, is there anything special in our ecosystem that makes small models focused with Indian language? Better for, more suited for our problems?', 'start_time': 632.92, 'end_time': 647.744}, {'chunk_id': 74, 'chunk_length': 12.463999999999942, 'text': 'So I think that, I mean, there are quite a few things that are unique about India, right? The first thing is I think that we are a voice first nation. So therefore I think voice has to be the core', 'start_time': 647.744, 'end_time': 660.208}, {'chunk_id': 75, 'chunk_length': 4.495999999999981, 'text': 'to doing things. The other thing, of course, India is', 'start_time': 660.208, 'end_time': 664.704}, {'chunk_id': 76, 'chunk_length': 9.888000000000034, 'text': \"extremely, it's a cost conscious country from a cost perspective. Now there, I would say that there are lots of interesting use cases where you can use.\", 'start_time': 664.704, 'end_time': 674.592}, {'chunk_id': 77, 'chunk_length': 10.447999999999979, 'text': 'Open AI and the cost structure works that when, depending on your application. But when you want to scale things to a massive level and make it work. Then you have to figure out how small models work.', 'start_time': 674.592, 'end_time': 685.04}, {'chunk_id': 78, 'chunk_length': 8.032000000000039, 'text': \"So that's something that is also specific to India. The third thing which is specific to India is really the success that India has had in\", 'start_time': 685.04, 'end_time': 693.072}, {'chunk_id': 79, 'chunk_length': 5.583999999999946, 'text': 'building all this digital public infrastructure. When you add the AI layer on top of it, then', 'start_time': 693.072, 'end_time': 698.656}, {'chunk_id': 80, 'chunk_length': 9.364000000000033, 'text': \"you can actually get dramatic, you know, dramatic, I think, multiplicative. Combinatorial effects based on doing things like that. That's a\", 'start_time': 698.656, 'end_time': 708.02}, {'chunk_id': 81, 'chunk_length': 4.108000000000061, 'text': \"phenomenal point. Like, you know, it's like DPI to the power of AI almost in some ways. And\", 'start_time': 708.02, 'end_time': 712.128}, {'chunk_id': 82, 'chunk_length': 13.839999999999918, 'text': \"as a part of Aadhaar, building Aadhaar, no better person than you. So in summary, what I'm hearing is small models specialized with, trained with Indic specific language data. Suited for Indian problems at\", 'start_time': 712.128, 'end_time': 725.968}, {'chunk_id': 83, 'chunk_length': 6.632000000000062, 'text': \"a compelling cost point will be suited for us. We're not solving some world autonomous vehicles or some complex problem.\", 'start_time': 725.968, 'end_time': 732.6}, {'chunk_id': 84, 'chunk_length': 8.409999999999968, 'text': \"We're solving some basic problems specifically focused on voice with multiple languages. That is what you see as the future. Am I paraphrasing this correctly?\", 'start_time': 732.6, 'end_time': 741.01}, {'chunk_id': 85, 'chunk_length': 7.998000000000047, 'text': 'No, yeah. So I think that certainly, I mean, voice and Indian languages are an important part of our strategy. But we will be building, you', 'start_time': 741.01, 'end_time': 749.008}, {'chunk_id': 86, 'chunk_length': 11.711999999999989, 'text': \"know, custom models to solve various other kinds of problems as well, right? It's not just limited to, I think, in different domains, working in different domains, making, building things based on unique\", 'start_time': 749.008, 'end_time': 760.72}, {'chunk_id': 87, 'chunk_length': 6.751999999999953, 'text': \"data that enterprises have. And things like that. So that's something that we'll also look at. Fair enough. So coming back to the\", 'start_time': 760.72, 'end_time': 767.472}, {'chunk_id': 88, 'chunk_length': 6.800000000000068, 'text': 'elephant in the room, no fun intended with open Hathi. What about Bhavesh Agarwal and Krutrim?', 'start_time': 767.472, 'end_time': 774.272}, {'chunk_id': 89, 'chunk_length': 4.067999999999984, 'text': \"What is your take on that? I think it's great. I think it's wonderful, right? I mean,\", 'start_time': 774.272, 'end_time': 778.34}, {'chunk_id': 90, 'chunk_length': 13.548000000000002, 'text': 'the fact that the technology AI is so important that we need multiple people working on it. The fact that there are other people thinking is actually validates that this is an important problem to be solved. And', 'start_time': 778.34, 'end_time': 791.888}, {'chunk_id': 91, 'chunk_length': 14.559999999999945, 'text': \"I think that we need everybody to come together and do that. So I really welcome that. I think it's great. And I think that there will be different people who will have different takes as to how to solve this kind of problem. And\", 'start_time': 791.888, 'end_time': 806.448}, {'chunk_id': 92, 'chunk_length': 4.336000000000013, 'text': 'hopefully as a result of that, the entire ecosystem benefits.', 'start_time': 806.448, 'end_time': 810.784}, {'chunk_id': 93, 'chunk_length': 6.224000000000046, 'text': \"I have one more question and then I want to talk about some of the predictions that you've boldly made. So Vivek,\", 'start_time': 810.784, 'end_time': 817.008}, {'chunk_id': 94, 'chunk_length': 13.183999999999969, 'text': 'I usually ask people about what do you think the future will be and everybody usually hedges. I asked Vivek, what do you think is going to happen by December 2024? What do you think sitting in this room one year later we can expect? And he made three bold predictions.', 'start_time': 817.008, 'end_time': 830.192}, {'chunk_id': 95, 'chunk_length': 7.487999999999943, 'text': 'So I want to talk about that. Before that, I have one last question. What are the top three applications that you think are relevant for India?', 'start_time': 830.192, 'end_time': 837.68}, {'chunk_id': 96, 'chunk_length': 7.5200000000000955, 'text': 'You heard Sridhar talk about medical. Quick summary, what do you think the top three apps are for India for AI? So', 'start_time': 837.68, 'end_time': 845.2}, {'chunk_id': 97, 'chunk_length': 12.895999999999958, 'text': 'I mean, I think that, as you said, things like education and medical education. These are clearly areas where I think that things can be leveraged. The whole idea of all these kind of the', 'start_time': 845.2, 'end_time': 858.096}, {'chunk_id': 98, 'chunk_length': 6.484000000000037, 'text': \"DPI aspect of it is another major application where things can happen. And here I'm talking about country specific work.\", 'start_time': 858.096, 'end_time': 864.58}, {'chunk_id': 99, 'chunk_length': 14.459999999999923, 'text': \"And I think the whole idea which Sridhar also talked about was the concept of software, right? And I think that and clearly we have a very large software industry and how to reimagine those things in this context is also something that's going to be.\", 'start_time': 864.58, 'end_time': 879.04}, {'chunk_id': 100, 'chunk_length': 5.2000000000000455, 'text': \"Fair enough. Are you guys ready for Vivek Raghavan's bold predictions?\", 'start_time': 879.04, 'end_time': 884.24}, {'chunk_id': 101, 'chunk_length': 12.655999999999949, 'text': \"Yes? No? I'm not hearing any yes. This is like a big deal. He's like one of the smartest guys that I know. He wants to make three predictions. You don't want to hear it? All right. So I asked him, what do you think, you\", 'start_time': 884.24, 'end_time': 896.896}, {'chunk_id': 102, 'chunk_length': 8.644000000000005, 'text': \"know, a year later, what do you think we can expect? And he came up with three things. And usually people give very blah answers when you ask a question like this because they don't want to be caught wrong.\", 'start_time': 896.896, 'end_time': 905.54}, {'chunk_id': 103, 'chunk_length': 7.868000000000052, 'text': \"Not Vivek. Vivek is bold. So he basically said three things, and I'm going to list out the three things and then ask him about it.\", 'start_time': 905.54, 'end_time': 913.408}, {'chunk_id': 104, 'chunk_length': 6.1440000000000055, 'text': 'So number one, he says, I would prefer to talk to an automated customer service than a real person because', 'start_time': 913.408, 'end_time': 919.552}, {'chunk_id': 105, 'chunk_length': 9.840000000000032, 'text': \"they'll give me a better answer. So that is Vivek Raghavan's prediction, number one. So number two is that when everybody is talking about a GPU shortage,\", 'start_time': 919.552, 'end_time': 929.392}, {'chunk_id': 106, 'chunk_length': 5.407999999999902, 'text': 'Vivek predicts that there will be a GPU glut in India. He thinks there will be too much GPU. So', 'start_time': 929.392, 'end_time': 934.8}, {'chunk_id': 107, 'chunk_length': 3.088000000000079, 'text': 'if you want a short NVIDIA stock, this is a good time.', 'start_time': 934.8, 'end_time': 937.888}, {'chunk_id': 108, 'chunk_length': 6.863999999999919, 'text': 'And number three, which was extremely unexpected, he said some companies will suddenly die.', 'start_time': 937.888, 'end_time': 944.752}, {'chunk_id': 109, 'chunk_length': 12.188000000000102, 'text': \"So, Vivek, these are not what I expected. So do you want to quickly talk about each of them, why you just came up with these, and then we'll throw the open to audience questions. Vivek Raghavan So I\", 'start_time': 944.752, 'end_time': 956.94}, {'chunk_id': 110, 'chunk_length': 11.747999999999934, 'text': \"don't think I quite said it the way that Bala is kind of saying it. Vivek Raghavan But it's interesting. But I think the first thing that we said is I think that,\", 'start_time': 956.94, 'end_time': 968.688}, {'chunk_id': 111, 'chunk_length': 3.967999999999961, 'text': \"and I don't think that this is, I think there will come a time when,\", 'start_time': 968.688, 'end_time': 972.656}, {'chunk_id': 112, 'chunk_length': 12.336000000000013, 'text': 'you know, in areas of customer service, etc., when you want to do something very specific. Today, you know, when you call some kind of a bot, you actually end up, you', 'start_time': 972.656, 'end_time': 984.992}, {'chunk_id': 113, 'chunk_length': 5.788000000000011, 'text': \"mostly try to disconnect the call or, you know, you're extremely upset that you're talking to a bot.\", 'start_time': 984.992, 'end_time': 990.78}, {'chunk_id': 114, 'chunk_length': 10.660000000000082, 'text': \"But I think that there will come a time, and I'm predicting it is sooner than later, that you will actually get better responses from the bot than what the human representative,\", 'start_time': 990.78, 'end_time': 1001.44}, {'chunk_id': 115, 'chunk_length': 4.41599999999994, 'text': 'that at least the average human representative that you could talk to could give. And', 'start_time': 1001.44, 'end_time': 1005.856}, {'chunk_id': 116, 'chunk_length': 11.844000000000051, 'text': \"I think that that's just a, so I just said that there will come a time where, you know, it's not a human you're talking to, but it's probably more likely to solve your intent than the human person.\", 'start_time': 1005.856, 'end_time': 1017.7}, {'chunk_id': 117, 'chunk_length': 4.139999999999986, 'text': \"That's just something that… That I think that\", 'start_time': 1017.7, 'end_time': 1021.84}, {'chunk_id': 118, 'chunk_length': 6.4640000000000555, 'text': \"could happen. Okay, definitely controversial, but we'll let it go. What about the GPU glut?\", 'start_time': 1021.84, 'end_time': 1028.304}, {'chunk_id': 119, 'chunk_length': 11.355999999999995, 'text': \"No, no, yeah, so I don't think that, so I think that the fact that there is a tremendous shortage right now, I think that shortage will ease because that is how the cycles of things go, right?\", 'start_time': 1028.304, 'end_time': 1039.66}, {'chunk_id': 120, 'chunk_length': 5.639999999999873, 'text': 'When, you know, I think the fact that there was such a severe shortage last year, you know,', 'start_time': 1039.66, 'end_time': 1045.3}, {'chunk_id': 121, 'chunk_length': 14.5, 'text': 'basically caused a number of different players to ramp up in various kinds of forms. And I think that that will always go in a cycle. But you may, we may find out that there are many, many more interesting problems that people will be able to solve.', 'start_time': 1045.3, 'end_time': 1059.8}, {'chunk_id': 122, 'chunk_length': 13.688000000000102, 'text': 'I still remember, you know, we were at a GenAI event in Bangalore and we were talking to people and we said, you know, how many people have access to, you', 'start_time': 1059.8, 'end_time': 1073.488}, {'chunk_id': 123, 'chunk_length': 9.851999999999862, 'text': \"know, 4 A100s, this was the question that I'd asked, and nobody in the room. And these are all extremely enthusiastic GenAI people. And nobody in the room. Nobody had access. And I think that thing is going to change.\", 'start_time': 1073.488, 'end_time': 1083.34}, {'chunk_id': 124, 'chunk_length': 11.300000000000182, 'text': 'You will be able to get these kinds of things. And people who want to hack and do things will have access to these things without, you know, having to write a, you know, a major check.', 'start_time': 1083.34, 'end_time': 1094.64}, {'chunk_id': 125, 'chunk_length': 6.5, 'text': \"Vivek is also a semiconductor guy before he went into Aadhaar. So I would take his predictions very seriously. So I don't know what I,\", 'start_time': 1094.64, 'end_time': 1101.14}, {'chunk_id': 126, 'chunk_length': 9.596000000000004, 'text': \"I'm going to sell my media stock. I would not do that. But that's not what I said. I want to blame you for this if it goes up.\", 'start_time': 1101.14, 'end_time': 1110.736}, {'chunk_id': 127, 'chunk_length': 8.023999999999887, 'text': 'But the third one is pretty strange. You know, companies are born, companies die. But you said some companies will suddenly die. What does that mean?', 'start_time': 1110.736, 'end_time': 1118.76}, {'chunk_id': 128, 'chunk_length': 11.895999999999958, 'text': 'No, I think, see, I think the interesting thing is, and I think that it comes back to the fundamental nature of AI. AI is a tool, right? And you have to use that. And', 'start_time': 1118.76, 'end_time': 1130.656}, {'chunk_id': 129, 'chunk_length': 7.903999999999996, 'text': \"you have to use that within your business process. Right? And how AI is being used. And so, and what's going to happen is that,\", 'start_time': 1130.656, 'end_time': 1138.56}, {'chunk_id': 130, 'chunk_length': 8.976000000000113, 'text': 'I mean, I think this is true with, you know, when someone said in terms of, you know, people, they said that the people who leverage AI will', 'start_time': 1138.56, 'end_time': 1147.536}, {'chunk_id': 131, 'chunk_length': 9.839999999999918, 'text': \"be more effective than those who don't leverage AI. And that is true for organizations also. Organizations that leverage AI in\", 'start_time': 1147.536, 'end_time': 1157.376}, {'chunk_id': 132, 'chunk_length': 5.087999999999965, 'text': \"fundamentally in their core business processes will be more effective than those who don't. Right?\", 'start_time': 1157.376, 'end_time': 1162.464}, {'chunk_id': 133, 'chunk_length': 11.888000000000147, 'text': \"And I think that's the thing. And you won't know the difference. Until one day it becomes too obvious. And it will be too late. And I think that's the reason why everybody needs to think about what\", 'start_time': 1162.464, 'end_time': 1174.352}, {'chunk_id': 134, 'chunk_length': 3.3279999999999745, 'text': 'it means for your business. Because you', 'start_time': 1174.352, 'end_time': 1177.68}, {'chunk_id': 135, 'chunk_length': 13.423999999999978, 'text': 'will, everything will be fine. Everything will be fine. And one day somebody in your, either your competitor in your space or somebody brand new coming into your space will be reimagining your business process completely. And', 'start_time': 1177.68, 'end_time': 1191.104}, {'chunk_id': 136, 'chunk_length': 9.88799999999992, 'text': \"at that stage you will find that it's, you know, it's a very big, very tall thing. You know, a mountain to climb. And that's why I think it's important for\", 'start_time': 1191.104, 'end_time': 1200.992}, {'chunk_id': 137, 'chunk_length': 10.087999999999965, 'text': \"both people and entities to think about how they will, you know, they will upgrade themselves or they will modify their business processes. That's\", 'start_time': 1200.992, 'end_time': 1211.08}, {'chunk_id': 138, 'chunk_length': 9.94399999999996, 'text': 'a very nuanced answer. And everybody here who is running a business should really think about it. Because life will be the same. And then suddenly, suddenly something will, you know, then there will be a step change.', 'start_time': 1211.08, 'end_time': 1221.024}, {'chunk_id': 139, 'chunk_length': 11.856000000000222, 'text': \"Vivek, I have a few more questions. But I'm sure the audience has a lot of questions for you. So how are we doing on time? Okay. So does, okay, a lot of questions. So love to,\", 'start_time': 1221.024, 'end_time': 1232.88}, {'chunk_id': 140, 'chunk_length': 13.679999999999836, 'text': 'is there a mic that we can pass around? Thank you. My name is Karthik. I work for IT service industry.', 'start_time': 1232.88, 'end_time': 1246.56}, {'chunk_id': 141, 'chunk_length': 14.35200000000009, 'text': \"So you're saying that you're working on LLM, sorry, it's a fine tuned LLM on top of Lama. My basic question, fundamental question is we don't have a foundational model for India. Most of the models are basically\", 'start_time': 1246.56, 'end_time': 1260.912}, {'chunk_id': 142, 'chunk_length': 13.023999999999887, 'text': 'using English or those kind of things. For example, even Andrew was talking about the tokenizers and things like that. So are you working on anything like that? Or do you want to use mostly', 'start_time': 1260.912, 'end_time': 1273.936}, {'chunk_id': 143, 'chunk_length': 4.244000000000142, 'text': 'the existing models and run on top of it? You asked a good', 'start_time': 1273.936, 'end_time': 1278.18}, {'chunk_id': 144, 'chunk_length': 8.44399999999996, 'text': 'question. You asked a cherry question for himself. No, I think the interesting thing is that if you look at, you know, we have a website and then we have actually a blog on', 'start_time': 1278.18, 'end_time': 1286.624}, {'chunk_id': 145, 'chunk_length': 11.42599999999993, 'text': \"this, on our website. I think one of the things that we've built is we've actually built a customized tokenizer which actually fundamentally changes the cost of some of these generations in Indian languages.\", 'start_time': 1286.624, 'end_time': 1298.05}, {'chunk_id': 146, 'chunk_length': 12.029999999999973, 'text': \"And I think that we're not just fine tuning. We're actually, we are leveraging the existing pre -training, but we are doing what's known as continual pre -training, which actually, but having said that, you know,\", 'start_time': 1298.05, 'end_time': 1310.08}, {'chunk_id': 147, 'chunk_length': 9.135999999999967, 'text': 'I think that when we have to figure out where is the data to train an extremely large model from scratch, and some of those things are things which will happen', 'start_time': 1310.08, 'end_time': 1319.216}, {'chunk_id': 148, 'chunk_length': 9.52000000000021, 'text': 'over time. But I think that, yes, I think that we will be doing various kinds of things. But the interesting thing is that if', 'start_time': 1319.216, 'end_time': 1328.736}, {'chunk_id': 149, 'chunk_length': 12.283999999999878, 'text': \"I want to change the accessibility problem with an existing open source model, how do I do that? And that's the problem that we have, that we think we have solved and is going to be the heart of this OpenAthi series. Extremely\", 'start_time': 1328.736, 'end_time': 1341.02}, {'chunk_id': 150, 'chunk_length': 3.6520000000000437, 'text': 'well explained in the blog. Even I could understand it, so.', 'start_time': 1341.02, 'end_time': 1344.672}, {'chunk_id': 151, 'chunk_length': 11.039999999999964, 'text': \"Hi, I'm Prashant. I work for a Fintech company. My question is like, unlike China, we never had a consumer facing application coming out from India and in\", 'start_time': 1344.672, 'end_time': 1355.712}, {'chunk_id': 152, 'chunk_length': 7.711999999999989, 'text': 'Web 1, Web 2, Crypto and all. Why do you think it will be different this time in like AI?', 'start_time': 1355.712, 'end_time': 1363.424}, {'chunk_id': 153, 'chunk_length': 14.41599999999994, 'text': 'Because will the DPI and other things will serve the same purpose what the Great Firewall did in China? Or do you think like in, because AI is a strategic sector, no', 'start_time': 1363.424, 'end_time': 1377.84}, {'chunk_id': 154, 'chunk_length': 12.096000000000004, 'text': 'outside country can work in NASA projects. Maybe all government contract will go to them. What exactly is the moat here for an Indian company?', 'start_time': 1377.84, 'end_time': 1389.936}, {'chunk_id': 155, 'chunk_length': 6.400000000000091, 'text': \"So I don't, I think the question is, I\", 'start_time': 1389.936, 'end_time': 1396.336}, {'chunk_id': 156, 'chunk_length': 8.413999999999987, 'text': \"don't know the answer to these questions, right? I mean, and I think that it's difficult to predict. But I do believe, and as I'm repeating,\", 'start_time': 1396.336, 'end_time': 1404.75}, {'chunk_id': 157, 'chunk_length': 13.346000000000004, 'text': \"that the combinatorial effect of using Gen AI at a large scale in addition along with the DPI work that we've done in India will have people. And I think that in the end it is, the\", 'start_time': 1404.75, 'end_time': 1418.096}, {'chunk_id': 158, 'chunk_length': 8.294000000000096, 'text': \"intent is that people need to be able to use it and they will vote by things that are useful for them. And if that doesn't happen, you're right.\", 'start_time': 1418.096, 'end_time': 1426.39}, {'chunk_id': 159, 'chunk_length': 10.6099999999999, 'text': \"And I think that we have to figure out what is the mechanism of delivery of apps, right? I mean, how, where do Indians consume content? That's the question.\", 'start_time': 1426.39, 'end_time': 1437.0}, {'chunk_id': 160, 'chunk_length': 3.8479999999999563, 'text': \"I'm so sorry, but we are out of time. Vivek will be outside. So\", 'start_time': 1437.0, 'end_time': 1440.848}, {'chunk_id': 161, 'chunk_length': 6.016000000000076, 'text': 'he would be able to answer the question. Do we have time for one last question? Can I just take one last? Yeah.', 'start_time': 1440.848, 'end_time': 1446.864}, {'chunk_id': 162, 'chunk_length': 6.399999999999864, 'text': \"Thank you. Thank you. I'm Manish Kothari. I'm from ISBR Business School. Good that I got a chance to ask you this question.\", 'start_time': 1446.864, 'end_time': 1453.264}, {'chunk_id': 163, 'chunk_length': 9.328000000000202, 'text': 'During lunch time, there were a few of our educationists whom we were talking about and we were, there was one from school and we are from the MBA institutions. We were thinking of these', 'start_time': 1453.264, 'end_time': 1462.592}, {'chunk_id': 164, 'chunk_length': 4.607999999999947, 'text': 'present generations. How do we get them into what you are doing?', 'start_time': 1462.592, 'end_time': 1467.2}, {'chunk_id': 165, 'chunk_length': 12.975999999999885, 'text': 'There is one thing that they have been regularly that the concentrations that they are working on, but artificial intelligence and getting into this, getting them into their academics and making them a part of it is very important, including the trainers who train them.', 'start_time': 1467.2, 'end_time': 1480.176}, {'chunk_id': 166, 'chunk_length': 14.656000000000176, 'text': 'Making them future ready into what you are doing is amazing. And the speed that with which it is growing, it is calling for a lot of training that needs to be done. Can you, from your angle, throw some light on how we could make them future ready? How', 'start_time': 1480.176, 'end_time': 1494.832}, {'chunk_id': 167, 'chunk_length': 5.695999999999913, 'text': 'these people who are management graduates and from schools who are coming out, how', 'start_time': 1494.832, 'end_time': 1500.528}, {'chunk_id': 168, 'chunk_length': 3.759999999999991, 'text': 'do we get into this part of technology that you spoke about?', 'start_time': 1500.528, 'end_time': 1504.288}, {'chunk_id': 169, 'chunk_length': 7.135999999999967, 'text': 'So this is really a challenge because I think everyone will need to understand at some level what', 'start_time': 1504.288, 'end_time': 1511.424}, {'chunk_id': 170, 'chunk_length': 11.392000000000053, 'text': 'this technology does. And I think that we have to rethink how we get everyone into this. And this kind of education has to be at many different levels, right? There are,', 'start_time': 1511.424, 'end_time': 1522.816}, {'chunk_id': 171, 'chunk_length': 11.743999999999915, 'text': \"from a core set of having people who are extremely good at some, and there you don't need as many, but then there are basically vast numbers of people who can actually leverage these tools. By the way,\", 'start_time': 1522.816, 'end_time': 1534.56}, {'chunk_id': 172, 'chunk_length': 6.269999999999982, 'text': 'the most important thing about, and maybe that is part of what makes an LLM interesting, is that how you use it,', 'start_time': 1534.56, 'end_time': 1540.83}, {'chunk_id': 173, 'chunk_length': 9.666000000000167, 'text': 'your mileage varies by that. And to understand how to actually leverage this in an interesting way, is something that we have to widely', 'start_time': 1540.83, 'end_time': 1550.496}, {'chunk_id': 174, 'chunk_length': 13.273999999999887, 'text': 'teach many, many people. And because asking the things in the right way and having the right kind of applications will make a huge difference to how people can leverage these tools. Awesome. Thank you.', 'start_time': 1550.496, 'end_time': 1563.77}, {'chunk_id': 175, 'chunk_length': 10.829999999999927, 'text': \"Thank you very much, Vivek. Very good luck to Sarvam and good luck to India. I think it's going to be a lot right on your shoulders. Thanks, Bala. Thank you, Mr. Raghavan.\", 'start_time': 1563.77, 'end_time': 1574.6}]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}